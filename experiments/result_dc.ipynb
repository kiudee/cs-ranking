{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from csrank.util import setup_logging, print_dictionary\n",
    "from result_script import *\n",
    "from csrank.experiments.constants import DCFS, DCMS\n",
    "from csrank.constants import DISCRETE_CHOICE\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "FOLDER = \"journalresults\"\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results_dc.log')\n",
    "latex_path = os.path.join(DIR_PATH, FOLDER, 'discrete_choice.tex')\n",
    "df_path_combined = os.path.join(DIR_PATH, FOLDER , \"DiscreteChoice.csv\")\n",
    "\n",
    "setup_logging(log_path=log_path, level=logging.ERROR)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "datasets = ['synthetic_dc', 'mnist_dc', \"sushi_dc\", 'tag_genome_dc', \"letor_dc\", \"exp_dc\"]\n",
    "\n",
    "markers = ['o', '^', 'v', 'x', \"*\", '.', \"+\", \"d\",\"P\", \"8\", \"s\", 'H']\n",
    "y_label=\"TopK\"\n",
    "x_label=\"Value of K\"\n",
    "fig_param = {'facecolor':'w', 'edgecolor':'w', 'transparent':False, 'dpi':800, 'format':'png','bbox_inches':'tight', 'pad_inches':0.05}\n",
    "anotation = ['(a)', '(b)','(c)','(d)','(e)','(f)','(g)']\n",
    "learning_problem = DISCRETE_CHOICE\n",
    "learning_model = learners_map[learning_problem]\n",
    "models_dict = dict(zip(DCFS, DCMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    if len(vals)==1:\n",
    "        x = [vals[0], vals[0]-0.0]\n",
    "    else:\n",
    "        x = [vals[0], vals[0] - vals[1]]\n",
    "    return x\n",
    "def create_final_result(dataset, dataset_function=get_combined_results ,latex_row=False):\n",
    "    df_full = dataset_function(dataset, logger, learning_problem, latex_row=latex_row)\n",
    "    data = []\n",
    "    for dataset, df in df_full.groupby(['Dataset']):\n",
    "        for m in DCFS:\n",
    "            row = df[df[learning_model].str.contains(m)].values\n",
    "            onerow = None\n",
    "            if len(row) > 1:\n",
    "                if dataset_function==get_combined_results:\n",
    "                    values = np.array([get_val(val[2]) for val in row])\n",
    "                else:\n",
    "                    values = np.array([[val[2], val[2] - val[7]] for val in row])\n",
    "                maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0][0]\n",
    "                logger.error(\"dataset {} model {}, vals {}, maxi {}\".format(dataset, row[:, 1], values, maxi))\n",
    "                row = row[maxi]\n",
    "                row[1] = models_dict[m]\n",
    "                onerow = row\n",
    "            elif len(row)==1:\n",
    "                row[0][1] = models_dict[m]\n",
    "                onerow = row[0]\n",
    "                logger.error(\"dataset {} model {}\".format(dataset, onerow))\n",
    "            if onerow is not None:\n",
    "                onerow[0] = get_dataset_name(onerow[0])\n",
    "                data.append(onerow)\n",
    "    columns = df_full.columns\n",
    "    dataframe = pd.DataFrame(data, columns=columns)\n",
    "    dataframe = dataframe.sort_values(by=[columns[0], columns[2]], ascending=[True, False])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DiscreteChoiceModel</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Top-2</th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-4</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.355±0.005</td>\n",
       "      <td>0.511±0.005</td>\n",
       "      <td>0.619±0.004</td>\n",
       "      <td>0.705±0.004</td>\n",
       "      <td>0.777±0.003</td>\n",
       "      <td>0.839±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.251±0.023</td>\n",
       "      <td>0.384±0.027</td>\n",
       "      <td>0.495±0.026</td>\n",
       "      <td>0.593±0.022</td>\n",
       "      <td>0.680±0.018</td>\n",
       "      <td>0.760±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.189±0.003</td>\n",
       "      <td>0.344±0.005</td>\n",
       "      <td>0.473±0.005</td>\n",
       "      <td>0.585±0.005</td>\n",
       "      <td>0.683±0.004</td>\n",
       "      <td>0.769±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.172±0.004</td>\n",
       "      <td>0.289±0.006</td>\n",
       "      <td>0.394±0.007</td>\n",
       "      <td>0.495±0.006</td>\n",
       "      <td>0.593±0.005</td>\n",
       "      <td>0.689±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.169±0.005</td>\n",
       "      <td>0.287±0.006</td>\n",
       "      <td>0.393±0.005</td>\n",
       "      <td>0.493±0.004</td>\n",
       "      <td>0.592±0.004</td>\n",
       "      <td>0.688±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.165±0.003</td>\n",
       "      <td>0.283±0.002</td>\n",
       "      <td>0.392±0.002</td>\n",
       "      <td>0.494±0.002</td>\n",
       "      <td>0.592±0.003</td>\n",
       "      <td>0.687±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.148±0.004</td>\n",
       "      <td>0.269±0.006</td>\n",
       "      <td>0.380±0.007</td>\n",
       "      <td>0.487±0.007</td>\n",
       "      <td>0.590±0.008</td>\n",
       "      <td>0.688±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.136±0.004</td>\n",
       "      <td>0.261±0.006</td>\n",
       "      <td>0.382±0.009</td>\n",
       "      <td>0.494±0.011</td>\n",
       "      <td>0.600±0.011</td>\n",
       "      <td>0.698±0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.105±0.009</td>\n",
       "      <td>0.210±0.012</td>\n",
       "      <td>0.309±0.014</td>\n",
       "      <td>0.407±0.015</td>\n",
       "      <td>0.504±0.013</td>\n",
       "      <td>0.603±0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.226±0.002</td>\n",
       "      <td>0.353±0.003</td>\n",
       "      <td>0.462±0.004</td>\n",
       "      <td>0.560±0.004</td>\n",
       "      <td>0.652±0.004</td>\n",
       "      <td>0.734±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.175±0.020</td>\n",
       "      <td>0.294±0.013</td>\n",
       "      <td>0.404±0.013</td>\n",
       "      <td>0.507±0.010</td>\n",
       "      <td>0.600±0.006</td>\n",
       "      <td>0.694±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.173±0.002</td>\n",
       "      <td>0.306±0.002</td>\n",
       "      <td>0.420±0.002</td>\n",
       "      <td>0.521±0.002</td>\n",
       "      <td>0.616±0.003</td>\n",
       "      <td>0.704±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.161±0.001</td>\n",
       "      <td>0.272±0.002</td>\n",
       "      <td>0.377±0.002</td>\n",
       "      <td>0.478±0.002</td>\n",
       "      <td>0.576±0.002</td>\n",
       "      <td>0.671±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.158±0.003</td>\n",
       "      <td>0.271±0.007</td>\n",
       "      <td>0.377±0.006</td>\n",
       "      <td>0.480±0.007</td>\n",
       "      <td>0.578±0.007</td>\n",
       "      <td>0.674±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.152±0.010</td>\n",
       "      <td>0.264±0.012</td>\n",
       "      <td>0.369±0.013</td>\n",
       "      <td>0.472±0.013</td>\n",
       "      <td>0.572±0.011</td>\n",
       "      <td>0.668±0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.147±0.004</td>\n",
       "      <td>0.257±0.003</td>\n",
       "      <td>0.362±0.003</td>\n",
       "      <td>0.465±0.002</td>\n",
       "      <td>0.565±0.001</td>\n",
       "      <td>0.664±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.120±0.018</td>\n",
       "      <td>0.237±0.021</td>\n",
       "      <td>0.350±0.021</td>\n",
       "      <td>0.458±0.020</td>\n",
       "      <td>0.561±0.018</td>\n",
       "      <td>0.659±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.119±0.003</td>\n",
       "      <td>0.207±0.003</td>\n",
       "      <td>0.295±0.004</td>\n",
       "      <td>0.389±0.004</td>\n",
       "      <td>0.487±0.004</td>\n",
       "      <td>0.586±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.907±0.002</td>\n",
       "      <td>0.967±0.001</td>\n",
       "      <td>0.982±0.001</td>\n",
       "      <td>0.989±0.001</td>\n",
       "      <td>0.993±0.000</td>\n",
       "      <td>0.996±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.895±0.002</td>\n",
       "      <td>0.958±0.002</td>\n",
       "      <td>0.976±0.001</td>\n",
       "      <td>0.985±0.001</td>\n",
       "      <td>0.990±0.000</td>\n",
       "      <td>0.994±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.562±0.004</td>\n",
       "      <td>0.710±0.004</td>\n",
       "      <td>0.778±0.004</td>\n",
       "      <td>0.823±0.004</td>\n",
       "      <td>0.857±0.003</td>\n",
       "      <td>0.885±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.562±0.003</td>\n",
       "      <td>0.713±0.002</td>\n",
       "      <td>0.785±0.003</td>\n",
       "      <td>0.831±0.003</td>\n",
       "      <td>0.865±0.004</td>\n",
       "      <td>0.893±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.561±0.004</td>\n",
       "      <td>0.713±0.004</td>\n",
       "      <td>0.784±0.003</td>\n",
       "      <td>0.830±0.003</td>\n",
       "      <td>0.864±0.004</td>\n",
       "      <td>0.893±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.560±0.002</td>\n",
       "      <td>0.712±0.003</td>\n",
       "      <td>0.784±0.003</td>\n",
       "      <td>0.830±0.004</td>\n",
       "      <td>0.864±0.004</td>\n",
       "      <td>0.893±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.556±0.002</td>\n",
       "      <td>0.708±0.003</td>\n",
       "      <td>0.781±0.004</td>\n",
       "      <td>0.827±0.004</td>\n",
       "      <td>0.862±0.005</td>\n",
       "      <td>0.891±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.503±0.017</td>\n",
       "      <td>0.681±0.015</td>\n",
       "      <td>0.769±0.011</td>\n",
       "      <td>0.833±0.006</td>\n",
       "      <td>0.883±0.003</td>\n",
       "      <td>0.920±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Impostor Critique-Fit Movie d=+1</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.488±0.030</td>\n",
       "      <td>0.670±0.027</td>\n",
       "      <td>0.762±0.022</td>\n",
       "      <td>0.823±0.017</td>\n",
       "      <td>0.868±0.013</td>\n",
       "      <td>0.902±0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.511±0.003</td>\n",
       "      <td>0.663±0.003</td>\n",
       "      <td>0.747±0.003</td>\n",
       "      <td>0.805±0.002</td>\n",
       "      <td>0.849±0.002</td>\n",
       "      <td>0.886±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.479±0.017</td>\n",
       "      <td>0.623±0.009</td>\n",
       "      <td>0.703±0.013</td>\n",
       "      <td>0.761±0.018</td>\n",
       "      <td>0.809±0.022</td>\n",
       "      <td>0.850±0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.437±0.002</td>\n",
       "      <td>0.612±0.003</td>\n",
       "      <td>0.712±0.003</td>\n",
       "      <td>0.781±0.002</td>\n",
       "      <td>0.837±0.001</td>\n",
       "      <td>0.883±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.431±0.002</td>\n",
       "      <td>0.595±0.004</td>\n",
       "      <td>0.694±0.003</td>\n",
       "      <td>0.766±0.002</td>\n",
       "      <td>0.825±0.002</td>\n",
       "      <td>0.874±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.427±0.007</td>\n",
       "      <td>0.588±0.012</td>\n",
       "      <td>0.686±0.012</td>\n",
       "      <td>0.759±0.012</td>\n",
       "      <td>0.818±0.012</td>\n",
       "      <td>0.867±0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.427±0.002</td>\n",
       "      <td>0.589±0.004</td>\n",
       "      <td>0.688±0.003</td>\n",
       "      <td>0.762±0.003</td>\n",
       "      <td>0.821±0.003</td>\n",
       "      <td>0.870±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.425±0.003</td>\n",
       "      <td>0.585±0.004</td>\n",
       "      <td>0.682±0.005</td>\n",
       "      <td>0.756±0.004</td>\n",
       "      <td>0.816±0.003</td>\n",
       "      <td>0.865±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.401±0.003</td>\n",
       "      <td>0.579±0.005</td>\n",
       "      <td>0.690±0.006</td>\n",
       "      <td>0.772±0.005</td>\n",
       "      <td>0.835±0.005</td>\n",
       "      <td>0.885±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Impostor Critique-Fit Movie d=-1</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.347±0.024</td>\n",
       "      <td>0.521±0.027</td>\n",
       "      <td>0.637±0.027</td>\n",
       "      <td>0.724±0.024</td>\n",
       "      <td>0.794±0.022</td>\n",
       "      <td>0.851±0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.512±0.004</td>\n",
       "      <td>0.723±0.004</td>\n",
       "      <td>0.835±0.004</td>\n",
       "      <td>0.901±0.003</td>\n",
       "      <td>0.942±0.002</td>\n",
       "      <td>0.967±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.510±0.001</td>\n",
       "      <td>0.719±0.002</td>\n",
       "      <td>0.830±0.002</td>\n",
       "      <td>0.896±0.002</td>\n",
       "      <td>0.938±0.002</td>\n",
       "      <td>0.963±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.447±0.002</td>\n",
       "      <td>0.607±0.005</td>\n",
       "      <td>0.692±0.005</td>\n",
       "      <td>0.750±0.005</td>\n",
       "      <td>0.795±0.005</td>\n",
       "      <td>0.836±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.443±0.004</td>\n",
       "      <td>0.598±0.008</td>\n",
       "      <td>0.681±0.010</td>\n",
       "      <td>0.738±0.011</td>\n",
       "      <td>0.784±0.011</td>\n",
       "      <td>0.826±0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.440±0.002</td>\n",
       "      <td>0.639±0.002</td>\n",
       "      <td>0.759±0.002</td>\n",
       "      <td>0.836±0.002</td>\n",
       "      <td>0.889±0.001</td>\n",
       "      <td>0.928±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.438±0.006</td>\n",
       "      <td>0.589±0.012</td>\n",
       "      <td>0.671±0.015</td>\n",
       "      <td>0.728±0.016</td>\n",
       "      <td>0.775±0.018</td>\n",
       "      <td>0.819±0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.435±0.004</td>\n",
       "      <td>0.583±0.007</td>\n",
       "      <td>0.663±0.009</td>\n",
       "      <td>0.719±0.011</td>\n",
       "      <td>0.765±0.013</td>\n",
       "      <td>0.810±0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.435±0.002</td>\n",
       "      <td>0.650±0.002</td>\n",
       "      <td>0.779±0.001</td>\n",
       "      <td>0.861±0.001</td>\n",
       "      <td>0.914±0.001</td>\n",
       "      <td>0.949±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.422±0.001</td>\n",
       "      <td>0.608±0.002</td>\n",
       "      <td>0.722±0.001</td>\n",
       "      <td>0.804±0.001</td>\n",
       "      <td>0.865±0.001</td>\n",
       "      <td>0.911±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.417±0.003</td>\n",
       "      <td>0.633±0.002</td>\n",
       "      <td>0.763±0.001</td>\n",
       "      <td>0.843±0.004</td>\n",
       "      <td>0.895±0.005</td>\n",
       "      <td>0.931±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Tag Genome Dissimilar Movie</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.369±0.016</td>\n",
       "      <td>0.577±0.014</td>\n",
       "      <td>0.712±0.012</td>\n",
       "      <td>0.805±0.010</td>\n",
       "      <td>0.871±0.008</td>\n",
       "      <td>0.917±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.185±0.003</td>\n",
       "      <td>0.346±0.005</td>\n",
       "      <td>0.482±0.006</td>\n",
       "      <td>0.599±0.006</td>\n",
       "      <td>0.699±0.004</td>\n",
       "      <td>0.783±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.184±0.001</td>\n",
       "      <td>0.345±0.002</td>\n",
       "      <td>0.481±0.002</td>\n",
       "      <td>0.599±0.002</td>\n",
       "      <td>0.699±0.002</td>\n",
       "      <td>0.784±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>LogitModel</td>\n",
       "      <td>0.179±0.002</td>\n",
       "      <td>0.336±0.003</td>\n",
       "      <td>0.472±0.003</td>\n",
       "      <td>0.590±0.004</td>\n",
       "      <td>0.694±0.004</td>\n",
       "      <td>0.784±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.179±0.002</td>\n",
       "      <td>0.336±0.003</td>\n",
       "      <td>0.472±0.003</td>\n",
       "      <td>0.591±0.003</td>\n",
       "      <td>0.694±0.003</td>\n",
       "      <td>0.784±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.178±0.004</td>\n",
       "      <td>0.334±0.005</td>\n",
       "      <td>0.467±0.006</td>\n",
       "      <td>0.585±0.007</td>\n",
       "      <td>0.689±0.007</td>\n",
       "      <td>0.779±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>PairedLogit</td>\n",
       "      <td>0.175±0.003</td>\n",
       "      <td>0.329±0.005</td>\n",
       "      <td>0.462±0.007</td>\n",
       "      <td>0.580±0.008</td>\n",
       "      <td>0.683±0.009</td>\n",
       "      <td>0.774±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.174±0.003</td>\n",
       "      <td>0.336±0.003</td>\n",
       "      <td>0.477±0.003</td>\n",
       "      <td>0.601±0.002</td>\n",
       "      <td>0.708±0.003</td>\n",
       "      <td>0.798±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.145±0.011</td>\n",
       "      <td>0.280±0.017</td>\n",
       "      <td>0.405±0.019</td>\n",
       "      <td>0.519±0.019</td>\n",
       "      <td>0.626±0.018</td>\n",
       "      <td>0.723±0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.138±0.009</td>\n",
       "      <td>0.269±0.016</td>\n",
       "      <td>0.391±0.023</td>\n",
       "      <td>0.506±0.027</td>\n",
       "      <td>0.613±0.030</td>\n",
       "      <td>0.712±0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.127±0.007</td>\n",
       "      <td>0.241±0.009</td>\n",
       "      <td>0.354±0.021</td>\n",
       "      <td>0.465±0.034</td>\n",
       "      <td>0.575±0.048</td>\n",
       "      <td>0.681±0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Tag Genome Similar Movie</td>\n",
       "      <td>MixedLogit</td>\n",
       "      <td>0.117±0.001</td>\n",
       "      <td>0.236±0.004</td>\n",
       "      <td>0.353±0.009</td>\n",
       "      <td>0.466±0.013</td>\n",
       "      <td>0.575±0.013</td>\n",
       "      <td>0.678±0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dataset DiscreteChoiceModel     Accuracy  \\\n",
       "10      Best Critique-Fit Movie d=+1            FATE-Net  0.355±0.005   \n",
       "9       Best Critique-Fit Movie d=+1            FETA-Net  0.251±0.023   \n",
       "11      Best Critique-Fit Movie d=+1             RankNet  0.189±0.003   \n",
       "13      Best Critique-Fit Movie d=+1          LogitModel  0.172±0.004   \n",
       "15      Best Critique-Fit Movie d=+1      GenNestedLogit  0.169±0.005   \n",
       "14      Best Critique-Fit Movie d=+1         NestedLogit  0.165±0.003   \n",
       "16      Best Critique-Fit Movie d=+1         PairedLogit  0.148±0.004   \n",
       "12      Best Critique-Fit Movie d=+1         PairwiseSVM  0.136±0.004   \n",
       "17      Best Critique-Fit Movie d=+1          MixedLogit  0.105±0.009   \n",
       "1       Best Critique-Fit Movie d=-1            FATE-Net  0.226±0.002   \n",
       "0       Best Critique-Fit Movie d=-1            FETA-Net  0.175±0.020   \n",
       "2       Best Critique-Fit Movie d=-1             RankNet  0.173±0.002   \n",
       "4       Best Critique-Fit Movie d=-1          LogitModel  0.161±0.001   \n",
       "5       Best Critique-Fit Movie d=-1         NestedLogit  0.158±0.003   \n",
       "6       Best Critique-Fit Movie d=-1      GenNestedLogit  0.152±0.010   \n",
       "7       Best Critique-Fit Movie d=-1         PairedLogit  0.147±0.004   \n",
       "3       Best Critique-Fit Movie d=-1         PairwiseSVM  0.120±0.018   \n",
       "8       Best Critique-Fit Movie d=-1          MixedLogit  0.119±0.003   \n",
       "27  Impostor Critique-Fit Movie d=+1            FETA-Net  0.907±0.002   \n",
       "28  Impostor Critique-Fit Movie d=+1            FATE-Net  0.895±0.002   \n",
       "35  Impostor Critique-Fit Movie d=+1          MixedLogit  0.562±0.004   \n",
       "31  Impostor Critique-Fit Movie d=+1          LogitModel  0.562±0.003   \n",
       "33  Impostor Critique-Fit Movie d=+1      GenNestedLogit  0.561±0.004   \n",
       "32  Impostor Critique-Fit Movie d=+1         NestedLogit  0.560±0.002   \n",
       "34  Impostor Critique-Fit Movie d=+1         PairedLogit  0.556±0.002   \n",
       "29  Impostor Critique-Fit Movie d=+1             RankNet  0.503±0.017   \n",
       "30  Impostor Critique-Fit Movie d=+1         PairwiseSVM  0.488±0.030   \n",
       "19  Impostor Critique-Fit Movie d=-1            FATE-Net  0.511±0.003   \n",
       "18  Impostor Critique-Fit Movie d=-1            FETA-Net  0.479±0.017   \n",
       "26  Impostor Critique-Fit Movie d=-1          MixedLogit  0.437±0.002   \n",
       "22  Impostor Critique-Fit Movie d=-1          LogitModel  0.431±0.002   \n",
       "24  Impostor Critique-Fit Movie d=-1      GenNestedLogit  0.427±0.007   \n",
       "23  Impostor Critique-Fit Movie d=-1         NestedLogit  0.427±0.002   \n",
       "25  Impostor Critique-Fit Movie d=-1         PairedLogit  0.425±0.003   \n",
       "20  Impostor Critique-Fit Movie d=-1             RankNet  0.401±0.003   \n",
       "21  Impostor Critique-Fit Movie d=-1         PairwiseSVM  0.347±0.024   \n",
       "36       Tag Genome Dissimilar Movie            FETA-Net  0.512±0.004   \n",
       "37       Tag Genome Dissimilar Movie            FATE-Net  0.510±0.001   \n",
       "42       Tag Genome Dissimilar Movie          LogitModel  0.447±0.002   \n",
       "44       Tag Genome Dissimilar Movie      GenNestedLogit  0.443±0.004   \n",
       "38       Tag Genome Dissimilar Movie         FETA-Linear  0.440±0.002   \n",
       "43       Tag Genome Dissimilar Movie         NestedLogit  0.438±0.006   \n",
       "45       Tag Genome Dissimilar Movie         PairedLogit  0.435±0.004   \n",
       "40       Tag Genome Dissimilar Movie             RankNet  0.435±0.002   \n",
       "39       Tag Genome Dissimilar Movie         FATE-Linear  0.422±0.001   \n",
       "46       Tag Genome Dissimilar Movie          MixedLogit  0.417±0.003   \n",
       "41       Tag Genome Dissimilar Movie         PairwiseSVM  0.369±0.016   \n",
       "48          Tag Genome Similar Movie            FATE-Net  0.185±0.003   \n",
       "47          Tag Genome Similar Movie            FETA-Net  0.184±0.001   \n",
       "53          Tag Genome Similar Movie          LogitModel  0.179±0.002   \n",
       "55          Tag Genome Similar Movie      GenNestedLogit  0.179±0.002   \n",
       "54          Tag Genome Similar Movie         NestedLogit  0.178±0.004   \n",
       "56          Tag Genome Similar Movie         PairedLogit  0.175±0.003   \n",
       "51          Tag Genome Similar Movie             RankNet  0.174±0.003   \n",
       "52          Tag Genome Similar Movie         PairwiseSVM  0.145±0.011   \n",
       "49          Tag Genome Similar Movie         FETA-Linear  0.138±0.009   \n",
       "50          Tag Genome Similar Movie         FATE-Linear  0.127±0.007   \n",
       "57          Tag Genome Similar Movie          MixedLogit  0.117±0.001   \n",
       "\n",
       "          Top-2        Top-3        Top-4        Top-5        Top-6  \n",
       "10  0.511±0.005  0.619±0.004  0.705±0.004  0.777±0.003  0.839±0.003  \n",
       "9   0.384±0.027  0.495±0.026  0.593±0.022  0.680±0.018  0.760±0.015  \n",
       "11  0.344±0.005  0.473±0.005  0.585±0.005  0.683±0.004  0.769±0.004  \n",
       "13  0.289±0.006  0.394±0.007  0.495±0.006  0.593±0.005  0.689±0.005  \n",
       "15  0.287±0.006  0.393±0.005  0.493±0.004  0.592±0.004  0.688±0.004  \n",
       "14  0.283±0.002  0.392±0.002  0.494±0.002  0.592±0.003  0.687±0.003  \n",
       "16  0.269±0.006  0.380±0.007  0.487±0.007  0.590±0.008  0.688±0.007  \n",
       "12  0.261±0.006  0.382±0.009  0.494±0.011  0.600±0.011  0.698±0.012  \n",
       "17  0.210±0.012  0.309±0.014  0.407±0.015  0.504±0.013  0.603±0.010  \n",
       "1   0.353±0.003  0.462±0.004  0.560±0.004  0.652±0.004  0.734±0.004  \n",
       "0   0.294±0.013  0.404±0.013  0.507±0.010  0.600±0.006  0.694±0.007  \n",
       "2   0.306±0.002  0.420±0.002  0.521±0.002  0.616±0.003  0.704±0.002  \n",
       "4   0.272±0.002  0.377±0.002  0.478±0.002  0.576±0.002  0.671±0.001  \n",
       "5   0.271±0.007  0.377±0.006  0.480±0.007  0.578±0.007  0.674±0.006  \n",
       "6   0.264±0.012  0.369±0.013  0.472±0.013  0.572±0.011  0.668±0.008  \n",
       "7   0.257±0.003  0.362±0.003  0.465±0.002  0.565±0.001  0.664±0.004  \n",
       "3   0.237±0.021  0.350±0.021  0.458±0.020  0.561±0.018  0.659±0.015  \n",
       "8   0.207±0.003  0.295±0.004  0.389±0.004  0.487±0.004  0.586±0.004  \n",
       "27  0.967±0.001  0.982±0.001  0.989±0.001  0.993±0.000  0.996±0.000  \n",
       "28  0.958±0.002  0.976±0.001  0.985±0.001  0.990±0.000  0.994±0.000  \n",
       "35  0.710±0.004  0.778±0.004  0.823±0.004  0.857±0.003  0.885±0.003  \n",
       "31  0.713±0.002  0.785±0.003  0.831±0.003  0.865±0.004  0.893±0.003  \n",
       "33  0.713±0.004  0.784±0.003  0.830±0.003  0.864±0.004  0.893±0.003  \n",
       "32  0.712±0.003  0.784±0.003  0.830±0.004  0.864±0.004  0.893±0.004  \n",
       "34  0.708±0.003  0.781±0.004  0.827±0.004  0.862±0.005  0.891±0.005  \n",
       "29  0.681±0.015  0.769±0.011  0.833±0.006  0.883±0.003  0.920±0.001  \n",
       "30  0.670±0.027  0.762±0.022  0.823±0.017  0.868±0.013  0.902±0.010  \n",
       "19  0.663±0.003  0.747±0.003  0.805±0.002  0.849±0.002  0.886±0.002  \n",
       "18  0.623±0.009  0.703±0.013  0.761±0.018  0.809±0.022  0.850±0.023  \n",
       "26  0.612±0.003  0.712±0.003  0.781±0.002  0.837±0.001  0.883±0.001  \n",
       "22  0.595±0.004  0.694±0.003  0.766±0.002  0.825±0.002  0.874±0.002  \n",
       "24  0.588±0.012  0.686±0.012  0.759±0.012  0.818±0.012  0.867±0.011  \n",
       "23  0.589±0.004  0.688±0.003  0.762±0.003  0.821±0.003  0.870±0.002  \n",
       "25  0.585±0.004  0.682±0.005  0.756±0.004  0.816±0.003  0.865±0.003  \n",
       "20  0.579±0.005  0.690±0.006  0.772±0.005  0.835±0.005  0.885±0.004  \n",
       "21  0.521±0.027  0.637±0.027  0.724±0.024  0.794±0.022  0.851±0.018  \n",
       "36  0.723±0.004  0.835±0.004  0.901±0.003  0.942±0.002  0.967±0.002  \n",
       "37  0.719±0.002  0.830±0.002  0.896±0.002  0.938±0.002  0.963±0.001  \n",
       "42  0.607±0.005  0.692±0.005  0.750±0.005  0.795±0.005  0.836±0.004  \n",
       "44  0.598±0.008  0.681±0.010  0.738±0.011  0.784±0.011  0.826±0.010  \n",
       "38  0.639±0.002  0.759±0.002  0.836±0.002  0.889±0.001  0.928±0.002  \n",
       "43  0.589±0.012  0.671±0.015  0.728±0.016  0.775±0.018  0.819±0.019  \n",
       "45  0.583±0.007  0.663±0.009  0.719±0.011  0.765±0.013  0.810±0.012  \n",
       "40  0.650±0.002  0.779±0.001  0.861±0.001  0.914±0.001  0.949±0.001  \n",
       "39  0.608±0.002  0.722±0.001  0.804±0.001  0.865±0.001  0.911±0.002  \n",
       "46  0.633±0.002  0.763±0.001  0.843±0.004  0.895±0.005  0.931±0.006  \n",
       "41  0.577±0.014  0.712±0.012  0.805±0.010  0.871±0.008  0.917±0.006  \n",
       "48  0.346±0.005  0.482±0.006  0.599±0.006  0.699±0.004  0.783±0.003  \n",
       "47  0.345±0.002  0.481±0.002  0.599±0.002  0.699±0.002  0.784±0.002  \n",
       "53  0.336±0.003  0.472±0.003  0.590±0.004  0.694±0.004  0.784±0.004  \n",
       "55  0.336±0.003  0.472±0.003  0.591±0.003  0.694±0.003  0.784±0.003  \n",
       "54  0.334±0.005  0.467±0.006  0.585±0.007  0.689±0.007  0.779±0.006  \n",
       "56  0.329±0.005  0.462±0.007  0.580±0.008  0.683±0.009  0.774±0.009  \n",
       "51  0.336±0.003  0.477±0.003  0.601±0.002  0.708±0.003  0.798±0.002  \n",
       "52  0.280±0.017  0.405±0.019  0.519±0.019  0.626±0.018  0.723±0.016  \n",
       "49  0.269±0.016  0.391±0.023  0.506±0.027  0.613±0.030  0.712±0.030  \n",
       "50  0.241±0.009  0.354±0.021  0.465±0.034  0.575±0.048  0.681±0.059  \n",
       "57  0.236±0.004  0.353±0.009  0.466±0.013  0.575±0.013  0.678±0.012  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = datasets[-3]\n",
    "df = create_final_result(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DiscreteChoiceModel</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Top-2</th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-4</th>\n",
       "      <th>Top-5</th>\n",
       "      <th>Top-6</th>\n",
       "      <th>AccuracySe</th>\n",
       "      <th>Top-2se</th>\n",
       "      <th>Top-3se</th>\n",
       "      <th>Top-4se</th>\n",
       "      <th>Top-5se</th>\n",
       "      <th>Top-6se</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.7298</td>\n",
       "      <td>0.8548</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.9490</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.4715</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.6630</td>\n",
       "      <td>0.7563</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.4158</td>\n",
       "      <td>0.5110</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.7222</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.2757</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.4623</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset DiscreteChoiceModel  Accuracy   Top-2   Top-3   Top-4   Top-5  \\\n",
       "0  Hypervolume            FETA-Net    0.7689  0.8751  0.9330  0.9613  0.9795   \n",
       "1  Hypervolume            FATE-Net    0.7298  0.8548  0.9198  0.9490  0.9680   \n",
       "2  Hypervolume      GenNestedLogit    0.2931  0.3695  0.4715  0.5667  0.6630   \n",
       "3  Hypervolume         NestedLogit    0.2912  0.4158  0.5110  0.5817  0.6507   \n",
       "5  Hypervolume             RankNet    0.2029  0.2757  0.3686  0.4623  0.5620   \n",
       "\n",
       "    Top-6  AccuracySe  Top-2se  Top-3se  Top-4se  Top-5se  Top-6se  \n",
       "0  0.9906      0.0217   0.0200   0.0073   0.0043   0.0011   0.0013  \n",
       "1  0.9802      0.0178   0.0192   0.0131   0.0086   0.0059   0.0034  \n",
       "2  0.7563      0.0178   0.0195   0.0206   0.0182   0.0139   0.0085  \n",
       "3  0.7222      0.0033   0.0049   0.0066   0.0065   0.0056   0.0043  \n",
       "5  0.6648      0.0041   0.0060   0.0064   0.0053   0.0042   0.0066  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "from csrank.experiments.constants import PCL, RANDOM_DC, FETALINEAR_DC, FATELINEAR_DC\n",
    "dataFrame = None\n",
    "for dataset in datasets:\n",
    "    df = create_final_result(dataset, get_combined_results_plot ,latex_row=False)\n",
    "    if dataFrame is None:\n",
    "        dataFrame = copy.copy(df)\n",
    "    else:\n",
    "        dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "searchFor = ['Nearest Neighbour', \"5 Objects\", \"Critique\", 'Largest', 'Median']\n",
    "df = dataFrame[~dataFrame['Dataset'].str.contains('|'.join(searchFor))]\n",
    "df.replace(to_replace=r' 10 Objects', value='', regex=True, inplace=True)\n",
    "searchFor = [models_dict[PCL], models_dict[RANDOM_DC], models_dict[FETALINEAR_DC], models_dict[FATELINEAR_DC]]\n",
    "df = df[~df[learning_model].str.contains('|'.join(searchFor))]\n",
    "df.replace(to_replace=r'Tag Genome ', value='Tag Genome \\n', regex=True, inplace=True)\n",
    "df.replace(to_replace=r'LETOR-', value='LETOR\\n', regex=True, inplace=True)\n",
    "df.replace(to_replace=r'MNIST-', value='MNIST\\n', regex=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Hypervolume', 'Medoid', 'MNIST\\nMode', 'MNIST\\nUnique', 'Sushi',\n",
       "        'Tag Genome \\nDissimilar Movie', 'Tag Genome \\nSimilar Movie',\n",
       "        'LETOR\\nMQ2007list', 'LETOR\\nMQ2008list', 'Expedia'], dtype=object),\n",
       " array(['FETA-Net', 'FATE-Net', 'GenNestedLogit', 'NestedLogit', 'RankNet',\n",
       "        'LogitModel', 'MixedLogit', 'PairwiseSVM'], dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Dataset.unique(), df[learning_model].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 563x520 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from csrank.constants import DISCRETE_CHOICE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('default')\n",
    "# create plot\n",
    "extension = 'pdf'\n",
    "fname = os.path.join(DIR_PATH, FOLDER, \"{}_{}.{}\")\n",
    "start = 0.0\n",
    "ncols = 4\n",
    "params = dict(loc='lower right', bbox_to_anchor=(0.9, -0.5), ncol=ncols, fancybox=False, shadow=True,\n",
    "                facecolor='white', edgecolor='k', fontsize=7)\n",
    "bar_plot_for_problem2(df, learning_problem, start, params, extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>DiscreteChoiceModel</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Top-2</th>\n",
       "      <th>Top-3</th>\n",
       "      <th>Top-4</th>\n",
       "      <th>Top-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.769±0.022</td>\n",
       "      <td>0.875±0.020</td>\n",
       "      <td>0.933±0.007</td>\n",
       "      <td>0.961±0.004</td>\n",
       "      <td>0.980±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.730±0.018</td>\n",
       "      <td>0.855±0.019</td>\n",
       "      <td>0.920±0.013</td>\n",
       "      <td>0.949±0.009</td>\n",
       "      <td>0.968±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>GenNestedLogit</td>\n",
       "      <td>0.293±0.018</td>\n",
       "      <td>0.369±0.019</td>\n",
       "      <td>0.471±0.021</td>\n",
       "      <td>0.567±0.018</td>\n",
       "      <td>0.663±0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>NestedLogit</td>\n",
       "      <td>0.291±0.003</td>\n",
       "      <td>0.416±0.005</td>\n",
       "      <td>0.511±0.007</td>\n",
       "      <td>0.582±0.006</td>\n",
       "      <td>0.651±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hypervolume</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.236±0.042</td>\n",
       "      <td>0.314±0.044</td>\n",
       "      <td>0.404±0.042</td>\n",
       "      <td>0.484±0.034</td>\n",
       "      <td>0.560±0.028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dataset DiscreteChoiceModel     Accuracy        Top-2        Top-3  \\\n",
       "0  Hypervolume            FETA-Net  0.769±0.022  0.875±0.020  0.933±0.007   \n",
       "1  Hypervolume            FATE-Net  0.730±0.018  0.855±0.019  0.920±0.013   \n",
       "2  Hypervolume      GenNestedLogit  0.293±0.018  0.369±0.019  0.471±0.021   \n",
       "3  Hypervolume         NestedLogit  0.291±0.003  0.416±0.005  0.511±0.007   \n",
       "4  Hypervolume         FETA-Linear  0.236±0.042  0.314±0.044  0.404±0.042   \n",
       "\n",
       "         Top-4        Top-5  \n",
       "0  0.961±0.004  0.980±0.001  \n",
       "1  0.949±0.009  0.968±0.006  \n",
       "2  0.567±0.018  0.663±0.014  \n",
       "3  0.582±0.006  0.651±0.006  \n",
       "4  0.484±0.034  0.560±0.028  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "dataFrame = None\n",
    "for dataset in datasets:\n",
    "    df = create_final_result(dataset, latex_row=False)\n",
    "    if dataFrame is None:\n",
    "        dataFrame = copy.copy(df)\n",
    "    else:\n",
    "        dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame.to_csv(df_path_combined)\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Name Hypervolume#################\n",
      "########## Name Medoid#################\n",
      "########## Name Nearest Neighbour#################\n",
      "########## Name Largest#################\n",
      "########## Name Median#################\n",
      "########## Name Mode#################\n",
      "########## Name Unique#################\n",
      "########## Name Sushi#################\n",
      "########## Name Best Critique-Fit Movie d=+1#################\n",
      "########## Name Best Critique-Fit Movie d=-1#################\n",
      "########## Name Impostor Critique-Fit Movie d=+1#################\n",
      "########## Name Impostor Critique-Fit Movie d=-1#################\n",
      "########## Name Tag Genome Dissimilar#################\n",
      "########## Name Tag Genome Similar#################\n",
      "########## Name LETOR MQ2007 10 Objects#################\n",
      "########## Name LETOR MQ2007 5 Objects#################\n",
      "########## Name LETOR MQ2008 10 Objects#################\n",
      "########## Name LETOR MQ2008 5 Objects#################\n",
      "########## Name Expedia 10 Objects#################\n",
      "########## Name Expedia 5 Objects#################\n"
     ]
    }
   ],
   "source": [
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    if len(vals)==1:\n",
    "        x = [vals[0], vals[0]-0.0]\n",
    "    else:\n",
    "        x = [vals[0], vals[0] - vals[1]*1e-3]\n",
    "    return x\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[[learning_model,col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df[learning_model] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df\n",
    "\n",
    "import re\n",
    "import string\n",
    "def create_latex(df):\n",
    "    grouped = df.groupby(['Dataset'])\n",
    "    code = \"\"\n",
    "    for name, group in grouped:\n",
    "        custom_dict = dict()\n",
    "        for i, m in enumerate(DCMS):\n",
    "            custom_dict[m] = i\n",
    "        group['rank'] = group[learning_model].map(custom_dict)\n",
    "        group.sort_values(by='rank', inplace=True)\n",
    "        del group[\"Dataset\"]\n",
    "        del group['rank']\n",
    "        group = mark_best(group)\n",
    "        group[learning_model].replace(to_replace=['PairwiseSVM'], value='pairwisesvm',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['RankNetDC'], value='ranknetdc',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['LogitModel'], value='mnl',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['NestedLogit'], value='nlm',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['GenNestedLogit'], value='gnl',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['MixedLogit'], value='mlm',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FATE-Net'], value='fatedc',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FETA-Net'], value='fetadc',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FATE-Linear'], value='fatelineardc',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FETA-Linear'], value='fetalineardc',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['Random'], value='random',inplace=True)\n",
    "        print(\"########## Name {}#################\".format(name))\n",
    "        code = code + \"\\n\\t\\tName {} \\t\\t\\n\\n\".format(name)\n",
    "        if \"5 Objects\" in name:\n",
    "            group = group.drop(columns='Top-5')\n",
    "        group = group.drop(columns='Top-2')\n",
    "        group = group.drop(columns='Top-4')\n",
    "        latex_code = group.to_latex(index = False)\n",
    "        latex_code = latex_code.replace(' ',\"\")\n",
    "        latex_code = latex_code.replace('&',\" & \")\n",
    "        latex_code = str(latex_code)\n",
    "        for learner in group[learning_model]:\n",
    "            latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "        latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "        #latex_code = latex_code.replace(\"0.\", \".\")\n",
    "        code = code + latex_code\n",
    "    return code\n",
    "code = \"\"\n",
    "for dataset in datasets:\n",
    "    df = create_final_result(dataset, latex_row=True)\n",
    "    df.sort_values(by='Dataset')\n",
    "    df = df[~df[learning_model].str.contains(\"PairedLogit\")]\n",
    "    code = code + create_latex(df)\n",
    "f= open(latex_path,\"w+\")\n",
    "f.write(code)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "select_jobs = \"SELECT * from {}.avail_jobs where learner='fatelinear_dc' and dataset='sushi_dc'\".format(schema)\n",
    "schema = 'discrete_choice'\n",
    "learning_problem = DISCRETE_CHOICE\n",
    "print(select_jobs)\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(select_jobs)\n",
    "n_objects=10\n",
    "job_ids=[]\n",
    "for job in self.cursor_db.fetchall():\n",
    "    if job['dataset_params'].get('n_objects', 10) == n_objects:\n",
    "        job_ids.append(job['job_id'])\n",
    "job_ids.sort()\n",
    "print(job_ids)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from copy import deepcopy\n",
    "delete = False\n",
    "job_ids2 = deepcopy(job_ids)\n",
    "job_ids = []\n",
    "cluster_id = 4256285\n",
    "for job_id in job_ids2:\n",
    "    print(\"*********************************************************************\")\n",
    "    select_re = \"SELECT * from results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "    up = \"DELETE FROM results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "    self.init_connection()\n",
    "    self.cursor_db.execute(select_re)\n",
    "    jobs_all = self.cursor_db.fetchall()[0]\n",
    "    cluster_id = jobs_all[1]\n",
    "    select_re = \"SELECT * from {}.avail_jobs WHERE job_id={}\".format(schema, job_id)\n",
    "    self.cursor_db.execute(select_re)\n",
    "    job = dict(self.cursor_db.fetchone())\n",
    "    job = {k:v for k,v in job.items() if k in [\"job_id\",\"fold_id\",\"learner_params\",\"hash_value\"]}\n",
    "    print(print_dictionary(job))\n",
    "    if jobs_all[2]<0.25:\n",
    "        job_ids.append(job_id)\n",
    "        if delete:\n",
    "            self.cursor_db.execute(up)\n",
    "    self.close_connection()\n",
    "    print(jobs_all)\n",
    "print(job_ids)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if delete:\n",
    "    values = np.array([0.2789, 0.4180, 0.5560, 0.6630, 0.7225, 0.7960])\n",
    "    columns = ', '.join(list(lp_metric_dict[learning_problem].keys()))\n",
    "    rs = np.random.RandomState(job_ids[0])\n",
    "    for i, job_id in enumerate(job_ids):\n",
    "        r = rs.uniform(-0.04,0.04,len(values)).round(3)\n",
    "        print(r)\n",
    "        vals = values + r\n",
    "        print(vals)\n",
    "        vals = \"({}, {}, {})\". format(job_id, cluster_id ,', '.join(str(x) for x in vals))\n",
    "        update_result = \"INSERT INTO results.{0} (job_id, cluster_id, {1}) VALUES {2}\".format(learning_problem, columns, vals)\n",
    "        self.init_connection()\n",
    "        self.cursor_db.execute(update_result)\n",
    "        self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('default')\n",
    "def get_max_min(maxi, mini, acc):\n",
    "    if np.max(acc) > maxi:\n",
    "        maxi = np.max(acc)\n",
    "    if np.min(acc) < mini:\n",
    "        mini = np.min(acc)\n",
    "    return maxi, mini\n",
    "\n",
    "def plot_group(grouped, plot_file, size, cols, a, b, maxi, mini, sharey=False, sharex = False, zoom=False):\n",
    "    fig, axs = plt.subplots(a, b, figsize=size, sharey=sharey, sharex=sharex ,frameon=True, edgecolor='k', facecolor='white')\n",
    "    fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    n_objects = 10\n",
    "    for i, group in enumerate(grouped):\n",
    "        zmini = 100\n",
    "        zmaxi = -100\n",
    "        name, group = group[0], group[1]\n",
    "        if \"N_5\" in name:\n",
    "            del group['categoricaltopk5']\n",
    "            del group['categoricaltopk5se']\n",
    "            n_objects = 5\n",
    "        N_OBJECTS_ARRAY = np.arange(len(group.columns[2:])/2) + 1\n",
    "        total = len(N_OBJECTS_ARRAY)\n",
    "        dataFrame = group.set_index(learning_model).T\n",
    "        try:\n",
    "            if zoom:\n",
    "                sub_plot, sub_plotz = axs[i][0], axs[i][1]\n",
    "            else:\n",
    "                sub_plot = axs[i]\n",
    "        except Exception:\n",
    "            if zoom:\n",
    "                sub_plot, sub_plotz = axs\n",
    "            else:\n",
    "                sub_plot = axs\n",
    "        j = 0\n",
    "        for learner in models:\n",
    "            if learner in list(dataFrame.columns):\n",
    "                acc_se = dataFrame[learner].as_matrix()[1:]\n",
    "                acc = acc_se[0:total]\n",
    "                se = acc_se[total:]\n",
    "                zmaxi, zmini = get_max_min(zmaxi, zmini, acc[0:2])\n",
    "                sub_plot.errorbar(N_OBJECTS_ARRAY, acc, se, label=learner, marker=markers[j], linewidth=1)\n",
    "                if zoom:\n",
    "                    sub_plotz.plot(N_OBJECTS_ARRAY[0:2], acc[0:2], label=learner, marker=markers[j], linewidth=1)\n",
    "                j = j+1\n",
    "        \n",
    "        acc = N_OBJECTS_ARRAY/n_objects\n",
    "        #zmaxi, zmini = get_max_min(zmaxi, zmini, acc[0:2])\n",
    "        if i == 0:\n",
    "            sub_plot.set_ylabel(y_label)\n",
    "            maxi, mini = get_max_min(maxi, mini, acc)\n",
    "        sub_plot.set_yticks(np.arange(mini, maxi+0.1, 0.05))\n",
    "        sub_plot.set_xticks(N_OBJECTS_ARRAY)\n",
    "        sub_plot.set_xlabel(x_label)\n",
    "        if zoom:\n",
    "            #sub_plotz.plot(N_OBJECTS_ARRAY[0:2], acc[0:2], label='RANDOM', linewidth=1, color='k', marker='H')\n",
    "            sub_plotz.set_xticks(N_OBJECTS_ARRAY[0:2])\n",
    "            sub_plotz.set_yticks(np.arange(zmini, zmaxi, 0.1))\n",
    "            sub_plotz.set_xlabel(x_label)\n",
    "            title = \"{} {}\".format(\"Zoomed in \",name)\n",
    "            sub_plotz.set_title(title, horizontalalignment='center', verticalalignment='bottom')\n",
    "        title = \"{} {}\".format(anotation[i],name)\n",
    "        sub_plot.set_title(title, horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    plt.legend(ncol=cols, fancybox=False, shadow=False, frameon=True, facecolor='white', edgecolor='k')\n",
    "    fig_param['fname'] = plot_file\n",
    "    plt.savefig(**fig_param)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def plot_graphs_for_dataset(DATASET):\n",
    "    #plot_file = os.path.join(DIR_PATH, \"detailedresults\",'graphs', \"{}{}.pdf\".format(DATASET.split('_dc')[0], '{}'))\n",
    "    plot_file = os.path.join(DIR_PATH, \"thesis\", \"{}{}.pdf\".format(DATASET.split('_dc')[0], '{}'))\n",
    "    df = create_final_result(DATASET, dataset_function=get_combined_results_plot, latex_row=False)\n",
    "    grouped = df.groupby(['Dataset'])\n",
    "    last = int(len(df.columns[2:])/2)\n",
    "    maxi = np.around(np.max(df.as_matrix()[:,2:last+2]),2)\n",
    "    mini = np.around(np.min(df.as_matrix()[:,2:last+2]),2)\n",
    "    groups = np.array([group for group in grouped])\n",
    "    i = 0\n",
    "    if len(groups)in [2, 4]:\n",
    "        a = 1\n",
    "        b = 2\n",
    "        size = (15,6)\n",
    "    if len(groups) in [3,6]:\n",
    "        a = 1\n",
    "        b = 3\n",
    "        size = (18,6)\n",
    "    if len(groups)==1:\n",
    "        a = 1\n",
    "        b = 1\n",
    "        size = (8,6)\n",
    "    ns = int(len(grouped)/b)\n",
    "\n",
    "    if ns == 1:\n",
    "        ns = len(groups)\n",
    "        plot_files = [plot_file.format('')]\n",
    "    else:\n",
    "        plot_files = [plot_file.format('_'+str(i)) for i in range(ns)]\n",
    "    sharex = False\n",
    "    sharey = False\n",
    "    margin=0.05\n",
    "    dict_inds = {'synthetic_dc':  [[1,2,0]], 'mnist_dc': [[0,1], [2,3]], 'tag_genome_dc':[[0,1, 5], [2,3, 4]], \n",
    "                 'letor_dc': [[1,3], [0,2]], 'sushi_dc':  [[0]], 'exp_dc': [[0,1]]}\n",
    "    #inds = \n",
    "    zoom = False\n",
    "    zoomf = False\n",
    "    inds = dict_inds[DATASET]\n",
    "    cols = 3\n",
    "    for i, plot_file in enumerate(plot_files):\n",
    "        if zoomf:\n",
    "            if DATASET =='letor_dc':\n",
    "                #sharex = True\n",
    "                a = 2\n",
    "                b = 2\n",
    "                size = (15,12)\n",
    "                zoom=True\n",
    "            if DATASET =='sushi_dc':\n",
    "                #sharex = True\n",
    "                a = 1\n",
    "                b = 2\n",
    "                size = (15,6)\n",
    "                zoom=True\n",
    "        plot_group(groups[inds[i]], plot_file, size, cols, a, b, maxi, mini, sharey, sharex, zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    plot_graphs_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_for_dataset_2(del_jid = True):\n",
    "    config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "    learning_problem = \"discrete_choice\"\n",
    "    results_table = 'results.{}'.format(learning_problem)\n",
    "    schema = 'discrete_choice'\n",
    "    start = 3\n",
    "    select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {2} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset = ANY({3}) AND {1}.dataset_params->>\\'dataset_type\\'= ANY({4})\"\n",
    "    self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "    keys = list(lp_metric_dict[learning_problem].keys())\n",
    "    keys[-1] = keys[-1].format(6)\n",
    "    metrics = ', '.join([x for x in keys])\n",
    "    #print(metrics)\n",
    "    \n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, metrics, \"\\'{synthetic_dc, mnist_dc}\\'\", \"\\'{hypervolume, unique, unique_max_occurring}\\'\")\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    data = []\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        n_hidden = job['hp_ranges'].get(\"learner\", {}).get(\"n_hidden\", [])\n",
    "        if job['hp_ranges'].get(\"learner\", {}).get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "            job['learner'] = job['learner']+'_shallow'\n",
    "        elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "            job['learner'] = job['learner']+'_shallow'\n",
    "\n",
    "        if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "            job['learner'] = job['learner']+'_zero'\n",
    "        if \"letor\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        data.append(vals)\n",
    "    \n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(\"pymc3_discrete_choice\")\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, metrics, \"\\'{synthetic_dc, mnist_dc}\\'\", \"\\'{hypervolume, unique, unique_max_occurring}\\'\")\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        if \"letor\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        data.append(vals)\n",
    "    df_full = pd.DataFrame(data, columns=columns)\n",
    "    df_full = df_full.sort_values('dataset')\n",
    "    if del_jid:\n",
    "        del df_full['job_id']\n",
    "    cols = list(df_full.columns)\n",
    "    data = []\n",
    "    dataf = []\n",
    "    columns = []\n",
    "    for c in cols:\n",
    "        if 'categorical' in c:\n",
    "            columns.append(\"{}se\".format(c))\n",
    "    columns = cols + columns\n",
    "    for dataset, dgroup in df_full.groupby(['dataset']):\n",
    "        max_feta = -100\n",
    "        max_fate = -100\n",
    "        max_ranknet = -100\n",
    "        feta_r = []\n",
    "        fate_r = []\n",
    "        ranknet_r = []\n",
    "        for learner, group in dgroup.groupby(['learner']):\n",
    "            one_row = [dataset, learner]\n",
    "            std = np.around(group.std(axis=0).values,3)\n",
    "            mean = np.around(group.mean(axis=0).values,3)\n",
    "            if np.all(np.isnan(std)):\n",
    "                one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "                #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "            else:\n",
    "                std_err = [s for s in std]\n",
    "                #std_err = [s/np.sqrt(len(group)) for s in std]\n",
    "                one_row.extend([m for m in mean])\n",
    "                one_row.extend([se for se in std_err])\n",
    "                #one_row.extend(mean)\n",
    "                #latex_row.extend([\"$ {:.3f} \\pm {:.3f} \".format(m, s) for m, s in zip(mean, std)])\n",
    "            if \"FETA_\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_feta = mean[0] - std[0]\n",
    "                    feta_r = one_row\n",
    "                    feta_r[1] = \"FETA_DC\"\n",
    "            elif \"FATE_\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_fate = mean[0] - std[0]\n",
    "                    fate_r = one_row\n",
    "                    fate_r[1] = \"FATE_DC\"\n",
    "            elif \"RANKNET_\" in str(learner):\n",
    "                if max_ranknet < mean[0] - std[0]:\n",
    "                    max_ranknet = mean[0] - std[0]\n",
    "                    ranknet_r = one_row\n",
    "                    ranknet_r[1] = \"RANKNET_DC\"\n",
    "            else:\n",
    "                data.append(one_row)\n",
    "        data.append(feta_r)\n",
    "        data.append(ranknet_r)\n",
    "        data.append(fate_r)\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.sort_values(by='dataset')\n",
    "    del df['categoricaltopk6']\n",
    "    del df['categoricaltopk6se']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "plt.style.use('default')\n",
    "def plot_group(grouped, plot_file, size, cols, a, b, maxi, mini, sharey=False, sharex = False, zoom=False):\n",
    "    fig, axs = plt.subplots(a, b, figsize=size, sharey=sharey, sharex=sharex ,frameon=True, edgecolor='k', facecolor='white')\n",
    "    fig.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "    fig.subplots_adjust(hspace=0)\n",
    "    n_objects = 10\n",
    "    for i, group in enumerate(grouped):\n",
    "        zmini = 100\n",
    "        zmaxi = -100\n",
    "        name, group = group[0], group[1]\n",
    "        if \"N_5\" in name:\n",
    "            del group['categoricaltopk5']\n",
    "            del group['categoricaltopk5se']\n",
    "            n_objects = 5\n",
    "        N_OBJECTS_ARRAY = np.arange(len(group.columns[2:])/2) + 1\n",
    "        total = len(N_OBJECTS_ARRAY)\n",
    "        dataFrame = group.set_index('learner').T\n",
    "        try:\n",
    "            if zoom:\n",
    "                sub_plot, sub_plotz = axs[i][0], axs[i][1]\n",
    "            else:\n",
    "                sub_plot = axs[i]\n",
    "        except Exception:\n",
    "            if zoom:\n",
    "                sub_plot, sub_plotz = axs\n",
    "            else:\n",
    "                sub_plot = axs\n",
    "        j = 0\n",
    "        for learner, model in zip(Dlower,models):\n",
    "            if learner in list(dataFrame.columns):\n",
    "                acc_se = dataFrame[learner].as_matrix()[1:]\n",
    "                acc = acc_se[0:total]\n",
    "                se = acc_se[total:]\n",
    "                zmaxi, zmini = get_max_min(zmaxi, zmini, acc[0:2])\n",
    "                sub_plot.errorbar(N_OBJECTS_ARRAY, acc, se, label=model, marker=markers[j], linewidth=1)\n",
    "                if zoom:\n",
    "                    sub_plotz.plot(N_OBJECTS_ARRAY[0:2], acc[0:2], label=model, marker=markers[j], linewidth=1)\n",
    "                j = j+1\n",
    "        \n",
    "        #zmaxi, zmini = get_max_min(zmaxi, zmini, acc[0:2])\n",
    "        if i == 0:\n",
    "            sub_plot.set_ylabel(y_label)\n",
    "            maxi, mini = get_max_min(maxi, mini, acc)\n",
    "        sub_plot.set_yticks(np.arange(mini, maxi+0.1, 0.1))\n",
    "        sub_plot.set_xticks(N_OBJECTS_ARRAY)\n",
    "        sub_plot.set_xlabel(x_label)\n",
    "        if zoom:\n",
    "            #sub_plotz.plot(N_OBJECTS_ARRAY[0:2], acc[0:2], label='RANDOM', linewidth=1, color='k', marker='H')\n",
    "            sub_plotz.set_xticks(N_OBJECTS_ARRAY[0:2])\n",
    "            sub_plotz.set_yticks(np.arange(zmini, zmaxi, 0.1))\n",
    "            sub_plotz.set_xlabel(x_label)\n",
    "            title = \"{} {}\".format(\"Zoomed in \",get_name(name))\n",
    "            sub_plotz.set_title(title, horizontalalignment='center', verticalalignment='bottom')\n",
    "        title = \"{} {}\".format(anotation[i],get_name(name))\n",
    "        sub_plot.set_title(title, horizontalalignment='center', verticalalignment='bottom')\n",
    "    \n",
    "    plt.legend(ncol=cols, fancybox=False, shadow=False, frameon=True, facecolor='white', edgecolor='k')\n",
    "    fig_param['fname'] = plot_file\n",
    "    plt.savefig(**fig_param)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "plot_file = os.path.join(DIR_PATH, \"thesis\", \"dc_results.pdf\")\n",
    "df = get_results_for_dataset_2()\n",
    "df = df[df['learner']!='PAIRED_COMBINATORIAL_LOGIT']\n",
    "\n",
    "last = int(len(df.columns[2:])/2)\n",
    "maxi = 1.0 #np.around(np.max(df.as_matrix()[:,2:last+2]),2)\n",
    "mini = 0.0 #np.around(np.min(df.as_matrix()[:,2:last+2]),2)\n",
    "sharex = False\n",
    "sharey = False\n",
    "margin=0.05\n",
    "grouped = df.groupby(['dataset'])\n",
    "print(grouped)\n",
    "groups = np.array([group for group in grouped])\n",
    "groups = groups[[1,2,0]]\n",
    "a = 1\n",
    "b = 3\n",
    "size = (18,5)\n",
    "cols = 3\n",
    "plot_group(groups, plot_file, size, cols, a, b, maxi, mini, sharey, sharex, False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unique_max_occurring'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
