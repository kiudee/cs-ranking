{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from csrank.util import setup_logging, print_dictionary\n",
    "from experiments.util import lp_metric_dict\n",
    "import numpy as np\n",
    "from experiments.dbconnection import DBConnector\n",
    "from experiments.constants import CHOICE_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results.log')\n",
    "setup_logging(log_path=log_path)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "learning_problem = \"choice_function\"\n",
    "schema = \"choice_functions\"\n",
    "datasets = ['synthetic_choice', 'mnist_choice', 'letor_choice']\n",
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "keys[-1] = keys[-1].format(6)\n",
    "metrics = ', '.join([x.lower() for x in keys])\n",
    "models = ['FETA-Net', 'FATE-Net', 'RankNet-Choice', 'PairwiseSVM', 'GeneralizedLinearModel', \"RandomGuessing\"]\n",
    "Dlower = [d.upper() for d in CHOICE_FUNCTIONS]\n",
    "models_dict = dict(zip(Dlower, models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135 136 137 138 159 160 161 162 163 164 165 166 167 168 169 170 171 172\n",
      " 173 174]\n",
      "\n",
      "job_id => 135\n",
      "fold_id => 0\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 1150dc8aea62657cc19290f6658454b8d0e2704e\n",
      "job_allocated_time => 2019-03-14 07:14:26.438386\n",
      "\n",
      "\n",
      "job_id => 136\n",
      "fold_id => 0\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\n",
      "job_allocated_time => 2019-03-14 07:14:49.129721\n",
      "\n",
      "\n",
      "job_id => 137\n",
      "fold_id => 0\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 922a90e374988977d2ec8774c85ee78f889e9f6c\n",
      "job_allocated_time => 2019-03-14 06:38:09.128545\n",
      "\n",
      "\n",
      "job_id => 138\n",
      "fold_id => 0\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 224663af81b389fa90e1c4ae5f756b01bc35ed21\n",
      "job_allocated_time => 2019-03-14 06:38:09.219145\n",
      "\n",
      "\n",
      "job_id => 159\n",
      "fold_id => 1\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 1150dc8aea62657cc19290f6658454b8d0e2704e\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 160\n",
      "fold_id => 2\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 1150dc8aea62657cc19290f6658454b8d0e2704e\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 161\n",
      "fold_id => 3\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 1150dc8aea62657cc19290f6658454b8d0e2704e\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 162\n",
      "fold_id => 4\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 1150dc8aea62657cc19290f6658454b8d0e2704e\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 163\n",
      "fold_id => 1\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 164\n",
      "fold_id => 2\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 165\n",
      "fold_id => 3\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 166\n",
      "fold_id => 4\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2008, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 167\n",
      "fold_id => 1\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 922a90e374988977d2ec8774c85ee78f889e9f6c\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 168\n",
      "fold_id => 2\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 922a90e374988977d2ec8774c85ee78f889e9f6c\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 169\n",
      "fold_id => 3\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 922a90e374988977d2ec8774c85ee78f889e9f6c\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 170\n",
      "fold_id => 4\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 10}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 922a90e374988977d2ec8774c85ee78f889e9f6c\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 171\n",
      "fold_id => 1\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 224663af81b389fa90e1c4ae5f756b01bc35ed21\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 172\n",
      "fold_id => 2\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 224663af81b389fa90e1c4ae5f756b01bc35ed21\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 173\n",
      "fold_id => 3\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 224663af81b389fa90e1c4ae5f756b01bc35ed21\n",
      "job_allocated_time => None\n",
      "\n",
      "\n",
      "job_id => 174\n",
      "fold_id => 4\n",
      "dataset => letor_choice\n",
      "learner => feta_choice\n",
      "experiment_schema => results\n",
      "experiment_table => choice_function\n",
      "dataset_params => {'year': 2007, 'n_objects': 5}\n",
      "fit_params => {'epochs': 600, 'callbacks': {'DebugOutput': {'delta': 200}, 'LRScheduler': {'epochs_drop': 200, 'drop': 0.1}}}\n",
      "learner_params => {'add_zeroth_order_model': 'TRUE'}\n",
      "hp_ranges => {'feta_choice': {'n_hidden': [1, 5], 'n_units': [20, 64], 'learning_rate': [1e-05, 0.01, 'log-uniform'], 'reg_strength': [1e-05, 0.1, 'log-uniform'], 'batch_size': [32, 512]}, 'LRScheduler': {'epochs_drop': [50, 150], 'drop': [0.01, 0.5, 'log-uniform']}}\n",
      "hp_fit_params => {}\n",
      "hp_iters => 10\n",
      "is_gpu => True\n",
      "seed => 123\n",
      "inner_folds => 2\n",
      "duration => 1d\n",
      "learning_problem => choice_function\n",
      "validation_loss => None\n",
      "hash_value => 224663af81b389fa90e1c4ae5f756b01bc35ed21\n",
      "job_allocated_time => None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=True, schema=schema)\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "self.init_connection()\n",
    "learner = \"feta_choice\"\n",
    "select_job = \"SELECT job_id FROM {0} WHERE {0}.dataset = \\'{1}\\' AND {0}.learner = \\'{2}\\'\".format(avail_jobs, datasets[2], learner)\n",
    "self.cursor_db.execute(select_job)\n",
    "ids = np.sort(np.array(self.cursor_db.fetchall()).flatten())\n",
    "print(ids)\n",
    "for job_id in ids:\n",
    "    cluster_id = 12345\n",
    "    select_job = \"SELECT * FROM {0} WHERE {0}.job_id = {1}\".format(avail_jobs, job_id)\n",
    "    self.cursor_db.execute(select_job)\n",
    "    self.job_description = self.cursor_db.fetchone()\n",
    "    print(print_dictionary(self.job_description))\n",
    "    job_id = int(self.job_description[\"job_id\"])\n",
    "    #insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    #self.cursor_db.execute(insert_job)\n",
    "self.close_connection()\n",
    "self.mark_running_job_finished(92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_re = \"SELECT * from results.{} WHERE job_id=142\".format(learning_problem)\n",
    "#up = \"UPDATE {0} SET hash_value=%s WHERE job_id=%s\".format(avail_jobs)\n",
    "\n",
    "self.init_connection()\n",
    "#self.cursor_db.execute(up, (\"95d2595fd8f495b9e21a2b5ebe991b1acb0acb00\", \"136\"))\n",
    "self.cursor_db.execute(select_re)\n",
    "jobs_all = self.cursor_db.fetchall()\n",
    "self.close_connection()\n",
    "jobs_all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "update_result = \"INSERT INTO results.choice_function (job_id, cluster_id, F1Score, Precision, Recall, Subset01loss, HammingLoss, Informedness, AucScore, AveragePrecisionScore) VALUES (44, 6828037, 0.9594, 0.9567, 0.9743, 0.2086, 0.0316, 0.9387, 0.9910, 0.9878)\"\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(update_result)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>subset01accuracy</th>\n",
       "      <th>hammingaccuracy</th>\n",
       "      <th>informedness</th>\n",
       "      <th>aucscore</th>\n",
       "      <th>averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9379</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>0.7127</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKNET_CHOICE</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.0680</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>0.6640</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>0.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>RANKNET_CHOICE</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.5987</td>\n",
       "      <td>0.8153</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FATE_CHOICE</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>0.9788</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.9884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PARETO</td>\n",
       "      <td>FETA_CHOICE_ZERO</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.9597</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset           learner  f1score  precision  recall  subset01accuracy  \\\n",
       "0   PARETO  FETA_CHOICE_ZERO   0.9537     0.9379  0.9843            0.7127   \n",
       "27  PARETO    RANKNET_CHOICE   0.6147     0.6422  0.7513            0.0680   \n",
       "26  PARETO    RANKNET_CHOICE   0.6156     0.5987  0.8153            0.0539   \n",
       "25  PARETO       FATE_CHOICE   0.9250     0.9438  0.9241            0.5603   \n",
       "24  PARETO  FETA_CHOICE_ZERO   0.9448     0.9385  0.9699            0.6848   \n",
       "\n",
       "    hammingaccuracy  informedness  aucscore  averageprecisionscore  \n",
       "0            0.9880        0.9736    0.9994                 0.9965  \n",
       "27           0.8844        0.6640    0.9737                 0.8993  \n",
       "26           0.8664        0.6962    0.9739                 0.9000  \n",
       "25           0.9788        0.9135    0.9972                 0.9884  \n",
       "24           0.9861        0.9597    0.9992                 0.9958  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_letor_string(dp):\n",
    "    y =  str(dp['year']) \n",
    "    n = str(dp['n_objects'])\n",
    "    return \"y_{}_n_{}\".format(y,n)\n",
    "def get_results_for_dataset(DATASET, del_jid = True, dataset_type=None):\n",
    "    config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "    results_table = 'results.{}'.format(learning_problem)\n",
    "    schema = 'choice_functions'\n",
    "    start = 3\n",
    "    select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {3} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\"\n",
    "    self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(schema)\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    data = []\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        if job['learner'] in job['hp_ranges'].keys():\n",
    "            n_hidden = job['hp_ranges'][job['learner']].get(\"n_hidden\", [])\n",
    "            if job['hp_ranges'][job['learner']].get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "            elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "\n",
    "        if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "            job['learner'] = job['learner']+'_zero'\n",
    "        if \"letor\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        \n",
    "        data.append(vals)\n",
    "    df_full = pd.DataFrame(data, columns=columns)\n",
    "    df_full = df_full.sort_values('dataset')\n",
    "    if del_jid:\n",
    "        del df_full['job_id']\n",
    "    df_full['subset01loss'] = 1 - df_full['subset01loss']\n",
    "    df_full['hammingloss'] = 1 - df_full['hammingloss']\n",
    "    df_full.rename(columns={'subset01loss': 'subset01accuracy', 'hammingloss': 'hammingaccuracy'}, inplace=True)\n",
    "    columns = list(df_full.columns)\n",
    "    return df_full, columns\n",
    "df, cols = get_results_for_dataset(datasets[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_combined_dfs(DATASET, latex_row=False):\n",
    "    df_full, columns = get_results_for_dataset(DATASET)\n",
    "    data = []\n",
    "    dataf = []\n",
    "    for dataset, dgroup in df_full.groupby(['dataset']):\n",
    "        max_feta = -100\n",
    "        max_fate = -100\n",
    "        max_ranknet = -100\n",
    "        feta_r = []\n",
    "        fate_r = []\n",
    "        ranknet_r = []\n",
    "        for learner, group in dgroup.groupby(['learner']):\n",
    "            one_row = [dataset.lower().title(), learner]\n",
    "            std = np.around(group.std(axis=0).values,3)\n",
    "            mean = np.around(group.mean(axis=0).values,3)\n",
    "            if np.all(np.isnan(std)):\n",
    "                one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "                #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "            else:\n",
    "                std_err = [s for s in std]\n",
    "                #std_err = [s/np.sqrt(len(group)) for s in std]\n",
    "                #one_row.extend([m for m in mean])\n",
    "                #one_row.extend([se for se in std_err])\n",
    "                #one_row.extend(mean)\n",
    "                if latex_row:\n",
    "                    one_row.extend([\"{:.3f}({:.0f})\".format(m, s*1e3) for m, s in zip(mean, std)])\n",
    "                else:\n",
    "                    one_row.extend([\"{:.3f}±{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "            if \"FETA\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_feta = mean[0] - std[0]\n",
    "                    feta_r = one_row\n",
    "                    feta_r[1] = models_dict[\"FETA_CHOICE\"]\n",
    "            elif \"FATE\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_fate = mean[0] - std[0]\n",
    "                    fate_r = one_row\n",
    "                    fate_r[1] = models_dict[\"FATE_CHOICE\"]\n",
    "            elif \"RANKNET\" in str(learner):\n",
    "                if max_ranknet < mean[0] - std[0]:\n",
    "                    max_ranknet = mean[0] - std[0]\n",
    "                    ranknet_r = one_row\n",
    "                    ranknet_r[1] = models_dict[\"RANKNET_CHOICE\"]\n",
    "            else:\n",
    "                one_row[1] = models_dict[one_row[1]]\n",
    "                data.append(one_row)\n",
    "        if len(feta_r)!=0:\n",
    "            data.append(feta_r)\n",
    "        if len(fate_r)!=0:\n",
    "            data.append(fate_r)\n",
    "        if len(ranknet_r)!=0:\n",
    "            data.append(ranknet_r)\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i].title()\n",
    "        if columns[i] == 'Learner':\n",
    "            columns[i] = \"ChoiceModel\"\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.sort_values(by='Dataset')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ChoiceModel</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Subset01Accuracy</th>\n",
       "      <th>Hammingaccuracy</th>\n",
       "      <th>Informedness</th>\n",
       "      <th>Aucscore</th>\n",
       "      <th>Averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.565±0.041</td>\n",
       "      <td>0.579±0.045</td>\n",
       "      <td>0.721±0.049</td>\n",
       "      <td>0.038±0.012</td>\n",
       "      <td>0.859±0.018</td>\n",
       "      <td>0.609±0.057</td>\n",
       "      <td>0.935±0.038</td>\n",
       "      <td>0.834±0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.232±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.588±0.001</td>\n",
       "      <td>0.596±0.012</td>\n",
       "      <td>0.756±0.015</td>\n",
       "      <td>0.044±0.003</td>\n",
       "      <td>0.866±0.005</td>\n",
       "      <td>0.646±0.007</td>\n",
       "      <td>0.956±0.000</td>\n",
       "      <td>0.865±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.942±0.008</td>\n",
       "      <td>0.938±0.007</td>\n",
       "      <td>0.967±0.013</td>\n",
       "      <td>0.680±0.028</td>\n",
       "      <td>0.985±0.002</td>\n",
       "      <td>0.956±0.012</td>\n",
       "      <td>0.999±0.000</td>\n",
       "      <td>0.996±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.913±0.009</td>\n",
       "      <td>0.919±0.015</td>\n",
       "      <td>0.926±0.005</td>\n",
       "      <td>0.506±0.037</td>\n",
       "      <td>0.975±0.003</td>\n",
       "      <td>0.911±0.006</td>\n",
       "      <td>0.996±0.001</td>\n",
       "      <td>0.984±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.612±0.007</td>\n",
       "      <td>0.624±0.026</td>\n",
       "      <td>0.772±0.029</td>\n",
       "      <td>0.060±0.010</td>\n",
       "      <td>0.877±0.011</td>\n",
       "      <td>0.672±0.014</td>\n",
       "      <td>0.971±0.006</td>\n",
       "      <td>0.891±0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mode</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.001</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.443±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.497±0.004</td>\n",
       "      <td>0.561±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mode</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.002</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.443±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.509±0.006</td>\n",
       "      <td>0.569±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.809±0.005</td>\n",
       "      <td>0.742±0.003</td>\n",
       "      <td>0.962±0.009</td>\n",
       "      <td>0.311±0.032</td>\n",
       "      <td>0.809±0.004</td>\n",
       "      <td>0.695±0.009</td>\n",
       "      <td>0.981±0.006</td>\n",
       "      <td>0.980±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.976±0.001</td>\n",
       "      <td>0.980±0.002</td>\n",
       "      <td>0.979±0.004</td>\n",
       "      <td>0.883±0.010</td>\n",
       "      <td>0.978±0.001</td>\n",
       "      <td>0.961±0.002</td>\n",
       "      <td>0.992±0.001</td>\n",
       "      <td>0.991±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.503±0.002</td>\n",
       "      <td>0.563±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Unique</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.508±0.004</td>\n",
       "      <td>0.542±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Unique</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.562±0.001</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.998±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.001</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.511±0.006</td>\n",
       "      <td>0.553±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.963±0.003</td>\n",
       "      <td>0.962±0.006</td>\n",
       "      <td>0.975±0.004</td>\n",
       "      <td>0.814±0.020</td>\n",
       "      <td>0.972±0.003</td>\n",
       "      <td>0.945±0.005</td>\n",
       "      <td>0.992±0.001</td>\n",
       "      <td>0.989±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.973±0.004</td>\n",
       "      <td>0.975±0.002</td>\n",
       "      <td>0.977±0.007</td>\n",
       "      <td>0.848±0.021</td>\n",
       "      <td>0.980±0.003</td>\n",
       "      <td>0.960±0.006</td>\n",
       "      <td>0.995±0.001</td>\n",
       "      <td>0.992±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.504±0.001</td>\n",
       "      <td>0.538±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Y_2007_N_10</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.688±0.003</td>\n",
       "      <td>0.562±0.005</td>\n",
       "      <td>0.992±0.010</td>\n",
       "      <td>0.005±0.004</td>\n",
       "      <td>0.568±0.007</td>\n",
       "      <td>0.028±0.012</td>\n",
       "      <td>0.579±0.013</td>\n",
       "      <td>0.710±0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Y_2007_N_10</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.686±0.004</td>\n",
       "      <td>0.556±0.004</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.556±0.004</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.556±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Y_2007_N_5</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.739±0.002</td>\n",
       "      <td>0.605±0.002</td>\n",
       "      <td>0.997±0.004</td>\n",
       "      <td>0.008±0.003</td>\n",
       "      <td>0.608±0.003</td>\n",
       "      <td>0.021±0.004</td>\n",
       "      <td>0.607±0.010</td>\n",
       "      <td>0.788±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Y_2007_N_5</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.736±0.002</td>\n",
       "      <td>0.600±0.002</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.600±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.600±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Y_2008_N_10</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.751±0.012</td>\n",
       "      <td>0.663±0.011</td>\n",
       "      <td>0.940±0.035</td>\n",
       "      <td>0.055±0.022</td>\n",
       "      <td>0.692±0.014</td>\n",
       "      <td>0.263±0.047</td>\n",
       "      <td>0.728±0.020</td>\n",
       "      <td>0.814±0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Y_2008_N_10</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.721±0.011</td>\n",
       "      <td>0.595±0.012</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.595±0.012</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.595±0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Y_2008_N_5</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.768±0.022</td>\n",
       "      <td>0.682±0.027</td>\n",
       "      <td>0.931±0.037</td>\n",
       "      <td>0.153±0.045</td>\n",
       "      <td>0.699±0.026</td>\n",
       "      <td>0.289±0.065</td>\n",
       "      <td>0.743±0.032</td>\n",
       "      <td>0.857±0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Y_2008_N_5</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.730±0.004</td>\n",
       "      <td>0.592±0.005</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.592±0.005</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.592±0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset             ChoiceModel      F1Score    Precision  \\\n",
       "0        Pareto  GeneralizedLinearModel  0.565±0.041  0.579±0.045   \n",
       "1        Pareto          RandomGuessing  0.232±0.000  0.133±0.000   \n",
       "2        Pareto             PairwiseSVM  0.588±0.001  0.596±0.012   \n",
       "3        Pareto                FETA-Net  0.942±0.008  0.938±0.007   \n",
       "4        Pareto                FATE-Net  0.913±0.009  0.919±0.015   \n",
       "5        Pareto          RankNet-Choice  0.612±0.007  0.624±0.026   \n",
       "6          Mode  GeneralizedLinearModel  0.597±0.000  0.442±0.000   \n",
       "7          Mode          RandomGuessing  0.597±0.000  0.442±0.000   \n",
       "8          Mode             PairwiseSVM  0.597±0.000  0.442±0.000   \n",
       "9          Mode                FETA-Net  0.809±0.005  0.742±0.003   \n",
       "10         Mode                FATE-Net  0.976±0.001  0.980±0.002   \n",
       "11         Mode          RankNet-Choice  0.597±0.000  0.442±0.000   \n",
       "12       Unique  GeneralizedLinearModel  0.562±0.000  0.405±0.000   \n",
       "13       Unique          RandomGuessing  0.562±0.000  0.405±0.000   \n",
       "14       Unique             PairwiseSVM  0.562±0.001  0.405±0.000   \n",
       "15       Unique                FETA-Net  0.963±0.003  0.962±0.006   \n",
       "16       Unique                FATE-Net  0.973±0.004  0.975±0.002   \n",
       "17       Unique          RankNet-Choice  0.562±0.000  0.405±0.000   \n",
       "18  Y_2007_N_10  GeneralizedLinearModel  0.688±0.003  0.562±0.005   \n",
       "19  Y_2007_N_10          RandomGuessing  0.686±0.004  0.556±0.004   \n",
       "20   Y_2007_N_5  GeneralizedLinearModel  0.739±0.002  0.605±0.002   \n",
       "21   Y_2007_N_5          RandomGuessing  0.736±0.002  0.600±0.002   \n",
       "22  Y_2008_N_10  GeneralizedLinearModel  0.751±0.012  0.663±0.011   \n",
       "23  Y_2008_N_10          RandomGuessing  0.721±0.011  0.595±0.012   \n",
       "24   Y_2008_N_5  GeneralizedLinearModel  0.768±0.022  0.682±0.027   \n",
       "25   Y_2008_N_5          RandomGuessing  0.730±0.004  0.592±0.005   \n",
       "\n",
       "         Recall Subset01Accuracy Hammingaccuracy Informedness     Aucscore  \\\n",
       "0   0.721±0.049      0.038±0.012     0.859±0.018  0.609±0.057  0.935±0.038   \n",
       "1   1.000±0.000      0.000±0.000     0.133±0.000  0.000±0.000  0.500±0.000   \n",
       "2   0.756±0.015      0.044±0.003     0.866±0.005  0.646±0.007  0.956±0.000   \n",
       "3   0.967±0.013      0.680±0.028     0.985±0.002  0.956±0.012  0.999±0.000   \n",
       "4   0.926±0.005      0.506±0.037     0.975±0.003  0.911±0.006  0.996±0.001   \n",
       "5   0.772±0.029      0.060±0.010     0.877±0.011  0.672±0.014  0.971±0.006   \n",
       "6   0.999±0.001      0.003±0.000     0.443±0.000  0.000±0.000  0.497±0.004   \n",
       "7   1.000±0.000      0.003±0.000     0.442±0.000  0.000±0.000  0.500±0.000   \n",
       "8   0.999±0.002      0.003±0.000     0.443±0.000  0.000±0.000  0.509±0.006   \n",
       "9   0.962±0.009      0.311±0.032     0.809±0.004  0.695±0.009  0.981±0.006   \n",
       "10  0.979±0.004      0.883±0.010     0.978±0.001  0.961±0.002  0.992±0.001   \n",
       "11  1.000±0.000      0.003±0.000     0.442±0.000  0.000±0.000  0.503±0.002   \n",
       "12  1.000±0.000      0.000±0.000     0.405±0.000  0.000±0.000  0.508±0.004   \n",
       "13  1.000±0.000      0.000±0.000     0.405±0.000  0.000±0.000  0.500±0.000   \n",
       "14  0.998±0.002      0.000±0.000     0.405±0.001  0.000±0.000  0.511±0.006   \n",
       "15  0.975±0.004      0.814±0.020     0.972±0.003  0.945±0.005  0.992±0.001   \n",
       "16  0.977±0.007      0.848±0.021     0.980±0.003  0.960±0.006  0.995±0.001   \n",
       "17  1.000±0.000      0.000±0.000     0.405±0.000  0.000±0.000  0.504±0.001   \n",
       "18  0.992±0.010      0.005±0.004     0.568±0.007  0.028±0.012  0.579±0.013   \n",
       "19  1.000±0.000      0.000±0.000     0.556±0.004  0.000±0.000  0.500±0.000   \n",
       "20  0.997±0.004      0.008±0.003     0.608±0.003  0.021±0.004  0.607±0.010   \n",
       "21  1.000±0.000      0.000±0.000     0.600±0.002  0.000±0.000  0.500±0.000   \n",
       "22  0.940±0.035      0.055±0.022     0.692±0.014  0.263±0.047  0.728±0.020   \n",
       "23  1.000±0.000      0.000±0.000     0.595±0.012  0.000±0.000  0.500±0.000   \n",
       "24  0.931±0.037      0.153±0.045     0.699±0.026  0.289±0.065  0.743±0.032   \n",
       "25  1.000±0.000      0.000±0.000     0.592±0.005  0.000±0.000  0.500±0.000   \n",
       "\n",
       "   Averageprecisionscore  \n",
       "0            0.834±0.055  \n",
       "1            0.133±0.000  \n",
       "2            0.865±0.000  \n",
       "3            0.996±0.000  \n",
       "4            0.984±0.003  \n",
       "5            0.891±0.019  \n",
       "6            0.561±0.002  \n",
       "7            0.442±0.000  \n",
       "8            0.569±0.004  \n",
       "9            0.980±0.006  \n",
       "10           0.991±0.002  \n",
       "11           0.563±0.002  \n",
       "12           0.542±0.002  \n",
       "13           0.405±0.000  \n",
       "14           0.553±0.005  \n",
       "15           0.989±0.001  \n",
       "16           0.992±0.001  \n",
       "17           0.538±0.001  \n",
       "18           0.710±0.011  \n",
       "19           0.556±0.004  \n",
       "20           0.788±0.006  \n",
       "21           0.600±0.002  \n",
       "22           0.814±0.013  \n",
       "23           0.595±0.012  \n",
       "24           0.857±0.017  \n",
       "25           0.592±0.005  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "combined = os.path.join(DIR_PATH, 'detailedresults' , \"ChoiceFunctions.csv\")\n",
    "dataFrame = None\n",
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset)\n",
    "    df_path = os.path.join(DIR_PATH, 'detailedresults' , dataset.split('_choice')[0].title()+'Choice.csv')\n",
    "    df.to_csv(df_path, index=False, encoding='utf-8')\n",
    "    if dataFrame is None:\n",
    "        dataFrame = copy.copy(df)\n",
    "    else:\n",
    "        dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame.to_csv(combined)\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    return [vals[0], vals[0] - vals[1]*1e-3]\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[['ChoiceModel',col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df['ChoiceModel'] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name Pareto\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Precision & Recall & Subset$0/1$Accuracy & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & \\bfseries 0.942(8) & \\bfseries 0.938(7) & 0.967(13) & \\bfseries 0.680(28) & \\bfseries 0.999(0)\\\\\n",
      "\\fatenet & 0.913(9) & 0.919(15) & 0.926(5) & 0.506(37) & 0.996(1)\\\\\n",
      "\\ranknet & 0.612(7) & 0.624(26) & 0.772(29) & 0.060(10) & 0.971(6)\\\\\n",
      "\\pairwisesvm & 0.588(1) & 0.596(12) & 0.756(15) & 0.044(3) & 0.956(0)\\\\\n",
      "\\glm & 0.565(41) & 0.579(45) & 0.721(49) & 0.038(12) & 0.935(38)\\\\\n",
      "\\random & 0.232(0) & 0.133(0) & \\bfseries 1.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "name Mode\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Precision & Recall & Subset$0/1$Accuracy & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.809(5) & 0.742(3) & 0.962(9) & 0.311(32) & 0.981(6)\\\\\n",
      "\\fatenet & \\bfseries 0.976(1) & \\bfseries 0.980(2) & 0.979(4) & \\bfseries 0.883(10) & \\bfseries 0.992(1)\\\\\n",
      "\\ranknet & 0.597(0) & 0.442(0) & \\bfseries 1.000(0) & 0.003(0) & 0.503(2)\\\\\n",
      "\\pairwisesvm & 0.597(0) & 0.442(0) & 0.999(2) & 0.003(0) & 0.509(6)\\\\\n",
      "\\glm & 0.597(0) & 0.442(0) & 0.999(1) & 0.003(0) & 0.497(4)\\\\\n",
      "\\random & 0.597(0) & 0.442(0) & \\bfseries 1.000(0) & 0.003(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "name Unique\n",
      "\\begin{tabular}{llllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Precision & Recall & Subset$0/1$Accuracy & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.963(3) & 0.962(6) & 0.975(4) & 0.814(20) & 0.992(1)\\\\\n",
      "\\fatenet & \\bfseries 0.973(4) & \\bfseries 0.975(2) & 0.977(7) & \\bfseries 0.848(21) & \\bfseries 0.995(1)\\\\\n",
      "\\ranknet & 0.562(0) & 0.405(0) & \\bfseries 1.000(0) & 0.000(0) & 0.504(1)\\\\\n",
      "\\pairwisesvm & 0.562(1) & 0.405(0) & 0.998(2) & 0.000(0) & 0.511(6)\\\\\n",
      "\\glm & 0.562(0) & 0.405(0) & \\bfseries 1.000(0) & 0.000(0) & 0.508(4)\\\\\n",
      "\\random & 0.562(0) & 0.405(0) & \\bfseries 1.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def create_latex(df):\n",
    "    grouped = df.groupby(['Dataset'])\n",
    "    for name, group in grouped:\n",
    "        custom_dict = dict()\n",
    "        for i, m in enumerate(models):\n",
    "            custom_dict[m] = i\n",
    "        group['rank'] = group['ChoiceModel'].map(custom_dict)\n",
    "        group.sort_values(by='rank', inplace=True)\n",
    "        del group[\"Dataset\"]\n",
    "        del group['rank']\n",
    "        group = mark_best(group)\n",
    "        group['ChoiceModel'].replace(to_replace=['GeneralizedLinearModel'], value='glm',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['FATE-Net'], value='fatenet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['FETA-Net'], value='fetanet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['RankNet-Choice'], value='ranknet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['PairwiseSVM'], value='pairwisesvm',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['RandomGuessing'], value='random',inplace=True)\n",
    "        group.rename(columns={'F1Score': '$F_1$-measure', 'Subset01Accuracy': 'Subset $0/1$ Accuracy', 'Aucscore':'Auc-Score'}, inplace=True)\n",
    "        del group['Hammingaccuracy']\n",
    "        del group['Informedness']\n",
    "        del group['Averageprecisionscore']\n",
    "        print(\"name {}\".format(name))\n",
    "        latex_code = group.to_latex(index = False)\n",
    "        latex_code = latex_code.replace(' ',\"\")\n",
    "        latex_code = latex_code.replace('&',\" & \")\n",
    "        latex_code = str(latex_code)\n",
    "        for learner in group['ChoiceModel']:\n",
    "            latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "        latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "        latex_code = latex_code.replace(\"\\\\$\", \"$\")\n",
    "        latex_code = latex_code.replace(\"\\\\_\", \"_\")\n",
    "        print(latex_code)\n",
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset, latex_row=True)\n",
    "    df.sort_values(by='Dataset')\n",
    "    create_latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
