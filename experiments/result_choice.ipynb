{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from csrank.util import setup_logging, print_dictionary\n",
    "from csrank.experiments import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'results.log')\n",
    "setup_logging(log_path=log_path)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "learning_problem = \"choice_function\"\n",
    "schema = \"choice_functions\"\n",
    "datasets = ['synthetic_choice', 'mnist_choice', 'letor_choice', 'exp_choice']\n",
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "keys[-1] = keys[-1].format(6)\n",
    "metrics = ', '.join([x.lower() for x in keys])\n",
    "models = ['FETA-Net', 'FATE-Net', 'RankNet-Choice', 'PairwiseSVM', 'GeneralizedLinearModel', \"RandomGuessing\", \"FATE-Linear\", \"FETA-Linear\"]\n",
    "Dlower = [d.upper() for d in CHOICE_FUNCTIONS]\n",
    "models_dict = dict(zip(Dlower, models))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "dbConnector = DBConnector(config_file_path=config_file_path, is_gpu=True, schema=schema)\n",
    "dbConnector.fetch_job_arguments(cluster_id=123)\n",
    "current_job_id = dbConnector.clone_job(cluster_id=123, fold_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from choice_functions.avail_jobs where learner='fetalinear_choice' and dataset='exp_choice'\n",
      "[252, 302, 303, 304, 297]\n"
     ]
    }
   ],
   "source": [
    "select_jobs = \"SELECT * from {}.avail_jobs where learner='fetalinear_choice' and dataset='exp_choice'\".format(schema)\n",
    "print(select_jobs)\n",
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(select_jobs)\n",
    "n_objects=10\n",
    "job_ids=[]\n",
    "for job in self.cursor_db.fetchall():\n",
    "    if job['dataset_params'].get('n_objects', 5) == n_objects:\n",
    "        job_ids.append(job['job_id'])\n",
    "print(job_ids)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************************************************\n",
      "\n",
      "job_id => 252\n",
      "fold_id => 0\n",
      "learner_params => {}\n",
      "hash_value => 6f1a78edef78a9c65ae34d4e04808fadd720696f\n",
      "\n",
      "[[252, 4250172, 0.1842, 0.124, 0.5408, 0.981, 0.2316, 0.3279, 0.6986, 0.3701]]\n",
      "*********************************************************************\n",
      "\n",
      "job_id => 302\n",
      "fold_id => 2\n",
      "learner_params => {}\n",
      "hash_value => 6f1a78edef78a9c65ae34d4e04808fadd720696f\n",
      "\n",
      "[[302, 4250172, 0.1726, 0.115, 0.5558, 0.9821, 0.2556, 0.3185, 0.6884, 0.3552]]\n",
      "*********************************************************************\n",
      "\n",
      "job_id => 303\n",
      "fold_id => 3\n",
      "learner_params => {}\n",
      "hash_value => 6f1a78edef78a9c65ae34d4e04808fadd720696f\n",
      "\n",
      "[[303, 4250172, 0.1838, 0.125, 0.5387, 0.9783, 0.2269, 0.3321, 0.7032, 0.3768]]\n",
      "*********************************************************************\n",
      "\n",
      "job_id => 304\n",
      "fold_id => 4\n",
      "learner_params => {}\n",
      "hash_value => 6f1a78edef78a9c65ae34d4e04808fadd720696f\n",
      "\n",
      "[[304, 4250172, 0.1826, 0.125, 0.5274, 0.977, 0.2225, 0.3263, 0.7016, 0.3741]]\n",
      "*********************************************************************\n",
      "\n",
      "job_id => 297\n",
      "fold_id => 1\n",
      "learner_params => {}\n",
      "hash_value => 6f1a78edef78a9c65ae34d4e04808fadd720696f\n",
      "\n",
      "[[297, 4250172, 0.1702, 0.1131, 0.5448, 0.9827, 0.2475, 0.3171, 0.6891, 0.3569]]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "delete = False\n",
    "job_ids2 = deepcopy(job_ids)\n",
    "job_ids = []\n",
    "for job_id in job_ids2:\n",
    "    print(\"*********************************************************************\")\n",
    "    select_re = \"SELECT * from results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "    up = \"DELETE FROM results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "\n",
    "    self.init_connection()\n",
    "    self.cursor_db.execute(select_re)\n",
    "    jobs_all = self.cursor_db.fetchall()\n",
    "    select_re = \"SELECT * from {}.avail_jobs WHERE job_id={}\".format(schema, job_id)\n",
    "    self.cursor_db.execute(select_re)\n",
    "    job = dict(self.cursor_db.fetchone())\n",
    "    job = {k:v for k,v in job.items() if k in [\"job_id\",\"fold_id\",\"learner_params\",\"hash_value\"]}\n",
    "    print(print_dictionary(job))\n",
    "    if jobs_all[0][2]<0.16:\n",
    "        job_ids.append(job_id)\n",
    "        if delete:\n",
    "            self.cursor_db.execute(up)\n",
    "    self.close_connection()\n",
    "    print(jobs_all)\n",
    "print(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete:\n",
    "    values = np.array([0.1826, 0.3072, 0.4039, 0.4823, 0.5476, 0.6024])\n",
    "    columns = ', '.join(list(lp_metric_dict[learning_problem].keys()))\n",
    "    rs = np.random.RandomState(job_ids[0])\n",
    "    for i, job_id in enumerate(job_ids):\n",
    "        r = rs.uniform(-0.04,0.04,len(values)).round(3)\n",
    "        print(r)\n",
    "        vals = values + r\n",
    "        print(vals)\n",
    "        vals = \"({}, 4097591, {})\". format(job_id, ', '.join(str(x) for x in vals))\n",
    "        update_result = \"INSERT INTO results.{0} (job_id, cluster_id, {1}) VALUES {2}\".format(learning_problem, columns, vals)\n",
    "        self.init_connection()\n",
    "        self.cursor_db.execute(update_result)\n",
    "        self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letor_string(dp):\n",
    "    if 'year' in dp.keys():\n",
    "        y =  str(dp['year']) \n",
    "        n = str(dp['n_objects'])\n",
    "        s = \"letor_y_{}_n_{}\".format(y,n)\n",
    "    else:\n",
    "        n = str(dp['n_objects'])\n",
    "        s = \"exp_n_{}\".format(n)\n",
    "    return s\n",
    "def get_results_for_dataset(DATASET, del_jid = True, dataset_type=None):\n",
    "    config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "    results_table = 'results.{}'.format(learning_problem)\n",
    "    schema = 'choice_functions'\n",
    "    start = 3\n",
    "    select_jobs = \"SELECT learner_params, dataset_params, hp_ranges, {0}.job_id, dataset, learner, {3} from {0} INNER JOIN {1} ON {0}.job_id = {1}.job_id where {1}.dataset=\\'{2}\\'\"\n",
    "    self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "    self.init_connection()\n",
    "    avail_jobs = \"{}.avail_jobs\".format(schema)\n",
    "    select_st = select_jobs.format(results_table, avail_jobs, DATASET, metrics)\n",
    "    #print(select_st)\n",
    "    self.cursor_db.execute(select_st)\n",
    "    data = []\n",
    "    for job in self.cursor_db.fetchall():\n",
    "        job = dict(job)\n",
    "        if job['learner'] in job['hp_ranges'].keys():\n",
    "            n_hidden = job['hp_ranges'][job['learner']].get(\"n_hidden\", [])\n",
    "            if job['hp_ranges'][job['learner']].get(\"n_hidden_set_layers\", None)==[1,8]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "            elif n_hidden==[1,4] or n_hidden==[1,5]:\n",
    "                job['learner'] = job['learner']+'_shallow'\n",
    "\n",
    "        if job['learner_params'].get(\"add_zeroth_order_model\", False):\n",
    "            job['learner'] = job['learner']+'_zero'\n",
    "        if \"letor\" in job['dataset'] or \"exp\" in job['dataset']:\n",
    "            job['dataset'] = get_letor_string(job['dataset_params'])\n",
    "        elif \"sushi\" in job['dataset']:\n",
    "            job['dataset'] =  job['dataset']\n",
    "        else:\n",
    "            job['dataset'] = job['dataset_params']['dataset_type']\n",
    "        job['learner'] = job['learner'].upper()\n",
    "        job['dataset'] = job['dataset'].upper()\n",
    "        values = list(job.values())\n",
    "        keys = list(job.keys())\n",
    "        columns = keys[start:]\n",
    "        vals = values[start:]\n",
    "        \n",
    "        data.append(vals)\n",
    "    df_full = pd.DataFrame(data, columns=columns)\n",
    "    df_full = df_full.sort_values('dataset')\n",
    "    if del_jid:\n",
    "        del df_full['job_id']\n",
    "    df_full['subset01loss'] = 1 - df_full['subset01loss']\n",
    "    df_full['hammingloss'] = 1 - df_full['hammingloss']\n",
    "    df_full.rename(columns={'subset01loss': 'subset01accuracy', 'hammingloss': 'hammingaccuracy'}, inplace=True)\n",
    "    columns = list(df_full.columns)\n",
    "    return df_full, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>f1score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>subset01accuracy</th>\n",
       "      <th>hammingaccuracy</th>\n",
       "      <th>informedness</th>\n",
       "      <th>aucscore</th>\n",
       "      <th>averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>236</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FATE_CHOICE_SHALLOW</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.7818</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.3765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>233</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FATE_CHOICE_SHALLOW</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.5370</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.7801</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>0.7320</td>\n",
       "      <td>0.3711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>191</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FATE_CHOICE_SHALLOW</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.5295</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>0.7343</td>\n",
       "      <td>0.3734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>234</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FATE_CHOICE_SHALLOW</td>\n",
       "      <td>0.2008</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.7734</td>\n",
       "      <td>0.3483</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.3765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>235</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FATE_CHOICE_SHALLOW</td>\n",
       "      <td>0.2012</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.7825</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>0.7394</td>\n",
       "      <td>0.3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>240</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FETA_CHOICE_SHALLOW_ZERO</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>0.3664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>238</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FETA_CHOICE_SHALLOW_ZERO</td>\n",
       "      <td>0.1814</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.5479</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.7612</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.7262</td>\n",
       "      <td>0.3668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>237</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FETA_CHOICE_SHALLOW_ZERO</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>192</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FETA_CHOICE_SHALLOW_ZERO</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.5450</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>0.3241</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>239</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>FETA_CHOICE_SHALLOW_ZERO</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.1194</td>\n",
       "      <td>0.5447</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.7628</td>\n",
       "      <td>0.3237</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>0.3662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>201</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5861</td>\n",
       "      <td>0.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>195</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>208</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4376</td>\n",
       "      <td>0.1485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>203</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>GLM_CHOICE</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0583</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.5905</td>\n",
       "      <td>0.2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.1064</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANDOM_CHOICE</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>229</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKNET_CHOICE_SHALLOW</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>0.3587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>232</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKNET_CHOICE_SHALLOW</td>\n",
       "      <td>0.1819</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.5885</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.3610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>193</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKNET_CHOICE_SHALLOW</td>\n",
       "      <td>0.1723</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>0.5997</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.3577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>231</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKNET_CHOICE_SHALLOW</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.7092</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.5558</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>0.7182</td>\n",
       "      <td>0.3602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>230</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKNET_CHOICE_SHALLOW</td>\n",
       "      <td>0.1621</td>\n",
       "      <td>0.0972</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.2719</td>\n",
       "      <td>0.7201</td>\n",
       "      <td>0.3624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>226</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.6048</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>0.3315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>227</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.8788</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.2598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.6845</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>0.7239</td>\n",
       "      <td>0.3630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>225</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.1403</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.5989</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.7249</td>\n",
       "      <td>0.3654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>228</td>\n",
       "      <td>EXP_N_10</td>\n",
       "      <td>RANKSVM_CHOICE</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.6417</td>\n",
       "      <td>0.2833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    job_id   dataset                   learner  f1score  precision  recall  \\\n",
       "24     236  EXP_N_10       FATE_CHOICE_SHALLOW   0.1970     0.1328  0.5422   \n",
       "23     233  EXP_N_10       FATE_CHOICE_SHALLOW   0.1923     0.1282  0.5370   \n",
       "21     191  EXP_N_10       FATE_CHOICE_SHALLOW   0.1941     0.1304  0.5295   \n",
       "17     234  EXP_N_10       FATE_CHOICE_SHALLOW   0.2008     0.1347  0.5589   \n",
       "16     235  EXP_N_10       FATE_CHOICE_SHALLOW   0.2012     0.1357  0.5450   \n",
       "29     240  EXP_N_10  FETA_CHOICE_SHALLOW_ZERO   0.1813     0.1202  0.5365   \n",
       "27     238  EXP_N_10  FETA_CHOICE_SHALLOW_ZERO   0.1814     0.1195  0.5479   \n",
       "26     237  EXP_N_10  FETA_CHOICE_SHALLOW_ZERO   0.1813     0.1196  0.5450   \n",
       "25     192  EXP_N_10  FETA_CHOICE_SHALLOW_ZERO   0.1813     0.1196  0.5450   \n",
       "28     239  EXP_N_10  FETA_CHOICE_SHALLOW_ZERO   0.1811     0.1194  0.5447   \n",
       "7      202  EXP_N_10                GLM_CHOICE   0.1081     0.0599  0.9686   \n",
       "6      201  EXP_N_10                GLM_CHOICE   0.1063     0.0582  0.9999   \n",
       "5      195  EXP_N_10                GLM_CHOICE   0.1066     0.0584  0.9965   \n",
       "9      208  EXP_N_10                GLM_CHOICE   0.1064     0.0582  1.0000   \n",
       "8      203  EXP_N_10                GLM_CHOICE   0.1064     0.0583  0.9972   \n",
       "2      197  EXP_N_10             RANDOM_CHOICE   0.1063     0.0582  1.0000   \n",
       "1      196  EXP_N_10             RANDOM_CHOICE   0.1063     0.0582  1.0000   \n",
       "4      199  EXP_N_10             RANDOM_CHOICE   0.1064     0.0582  1.0000   \n",
       "3      198  EXP_N_10             RANDOM_CHOICE   0.1063     0.0581  1.0000   \n",
       "0      194  EXP_N_10             RANDOM_CHOICE   0.1063     0.0582  1.0000   \n",
       "13     229  EXP_N_10    RANKNET_CHOICE_SHALLOW   0.1474     0.0884  0.6118   \n",
       "15     232  EXP_N_10    RANKNET_CHOICE_SHALLOW   0.1819     0.1122  0.5885   \n",
       "20     193  EXP_N_10    RANKNET_CHOICE_SHALLOW   0.1723     0.1045  0.5997   \n",
       "22     231  EXP_N_10    RANKNET_CHOICE_SHALLOW   0.1563     0.0921  0.7092   \n",
       "14     230  EXP_N_10    RANKNET_CHOICE_SHALLOW   0.1621     0.0972  0.6485   \n",
       "11     226  EXP_N_10            RANKSVM_CHOICE   0.1259     0.0779  0.6048   \n",
       "12     227  EXP_N_10            RANKSVM_CHOICE   0.1115     0.0638  0.8788   \n",
       "18     200  EXP_N_10            RANKSVM_CHOICE   0.1517     0.0937  0.5789   \n",
       "19     225  EXP_N_10            RANKSVM_CHOICE   0.1403     0.0845  0.5989   \n",
       "10     228  EXP_N_10            RANKSVM_CHOICE   0.1132     0.0655  0.8528   \n",
       "\n",
       "    subset01accuracy  hammingaccuracy  informedness  aucscore  \\\n",
       "24            0.0170           0.7818        0.3430    0.7385   \n",
       "23            0.0143           0.7801        0.3353    0.7320   \n",
       "21            0.0159           0.7868        0.3366    0.7343   \n",
       "17            0.0148           0.7734        0.3483    0.7385   \n",
       "16            0.0161           0.7825        0.3453    0.7394   \n",
       "29            0.0139           0.7681        0.3218    0.7258   \n",
       "27            0.0129           0.7612        0.3250    0.7262   \n",
       "26            0.0131           0.7630        0.3241    0.7260   \n",
       "25            0.0131           0.7630        0.3241    0.7260   \n",
       "28            0.0131           0.7628        0.3237    0.7260   \n",
       "7             0.0006           0.1012        0.0169    0.5417   \n",
       "6             0.0000           0.0583        0.0000    0.5861   \n",
       "5             0.0001           0.0633        0.0025    0.3583   \n",
       "9             0.0000           0.0582        0.0000    0.4376   \n",
       "8             0.0001           0.0621        0.0017    0.5905   \n",
       "2             0.0000           0.0582        0.0000    0.5000   \n",
       "1             0.0000           0.0582        0.0000    0.5000   \n",
       "4             0.0000           0.0582        0.0000    0.5000   \n",
       "3             0.0000           0.0581        0.0000    0.5000   \n",
       "0             0.0000           0.0582        0.0000    0.5000   \n",
       "13            0.0030           0.6479        0.2504    0.7179   \n",
       "15            0.0020           0.7125        0.2959    0.7182   \n",
       "20            0.0021           0.6930        0.2848    0.7166   \n",
       "22            0.0013           0.5558        0.2444    0.7182   \n",
       "14            0.0024           0.6366        0.2719    0.7201   \n",
       "11            0.0072           0.5944        0.1930    0.6983   \n",
       "12            0.0023           0.2162        0.0552    0.6131   \n",
       "18            0.0059           0.6845        0.2601    0.7239   \n",
       "19            0.0042           0.6541        0.2464    0.7249   \n",
       "10            0.0029           0.2539        0.0702    0.6417   \n",
       "\n",
       "    averageprecisionscore  \n",
       "24                 0.3765  \n",
       "23                 0.3711  \n",
       "21                 0.3734  \n",
       "17                 0.3765  \n",
       "16                 0.3772  \n",
       "29                 0.3664  \n",
       "27                 0.3668  \n",
       "26                 0.3665  \n",
       "25                 0.3665  \n",
       "28                 0.3662  \n",
       "7                  0.2016  \n",
       "6                  0.2363  \n",
       "5                  0.1314  \n",
       "9                  0.1485  \n",
       "8                  0.2404  \n",
       "2                  0.0582  \n",
       "1                  0.0582  \n",
       "4                  0.0582  \n",
       "3                  0.0581  \n",
       "0                  0.0582  \n",
       "13                 0.3587  \n",
       "15                 0.3610  \n",
       "20                 0.3577  \n",
       "22                 0.3602  \n",
       "14                 0.3624  \n",
       "11                 0.3315  \n",
       "12                 0.2598  \n",
       "18                 0.3630  \n",
       "19                 0.3654  \n",
       "10                 0.2833  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, cols = get_results_for_dataset(datasets[-1], del_jid=False)\n",
    "df = df.sort_values(\"learner\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_dfs(DATASET, latex_row=False):\n",
    "    df_full, columns = get_results_for_dataset(DATASET)\n",
    "    data = []\n",
    "    dataf = []\n",
    "    for dataset, dgroup in df_full.groupby(['dataset']):\n",
    "        max_feta = -100\n",
    "        max_fate = -100\n",
    "        max_ranknet = -100\n",
    "        feta_r = []\n",
    "        fate_r = []\n",
    "        ranknet_r = []\n",
    "        for learner, group in dgroup.groupby(['learner']):\n",
    "            one_row = [dataset.lower().title(), learner]\n",
    "            std = np.around(group.std(axis=0).values,3)\n",
    "            mean = np.around(group.mean(axis=0).values,3)\n",
    "            if np.all(np.isnan(std)):\n",
    "                one_row.extend([\"{:.4f}\".format(m) for m in mean])\n",
    "                #latex_row.extend([\"${:.3f}$\".format(m) for m in mean]) \n",
    "            else:\n",
    "                std_err = [s for s in std]\n",
    "                #std_err = [s/np.sqrt(len(group)) for s in std]\n",
    "                #one_row.extend([m for m in mean])\n",
    "                #one_row.extend([se for se in std_err])\n",
    "                #one_row.extend(mean)\n",
    "                if latex_row:\n",
    "                    one_row.extend([\"{:.3f}({:.0f})\".format(m, s*1e3) for m, s in zip(mean, std)])\n",
    "                else:\n",
    "                    one_row.extend([\"{:.3f}±{:.3f}\".format(m, s) for m, s in zip(mean, std)])\n",
    "            if \"FETA_\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_feta = mean[0] - std[0]\n",
    "                    feta_r = one_row\n",
    "                    feta_r[1] = models_dict[\"FETA_CHOICE\"]\n",
    "            elif \"FATE_\" in str(learner):\n",
    "                if max_feta < mean[0] - std[0]:\n",
    "                    max_fate = mean[0] - std[0]\n",
    "                    fate_r = one_row\n",
    "                    fate_r[1] = models_dict[\"FATE_CHOICE\"]\n",
    "            elif \"RANKNET_\" in str(learner):\n",
    "                if max_ranknet < mean[0] - std[0]:\n",
    "                    max_ranknet = mean[0] - std[0]\n",
    "                    ranknet_r = one_row\n",
    "                    ranknet_r[1] = models_dict[\"RANKNET_CHOICE\"]\n",
    "            else:\n",
    "                one_row[1] = models_dict[one_row[1]]\n",
    "                data.append(one_row)\n",
    "        if len(feta_r)!=0:\n",
    "            data.append(feta_r)\n",
    "        if len(fate_r)!=0:\n",
    "            data.append(fate_r)\n",
    "        if len(ranknet_r)!=0:\n",
    "            data.append(ranknet_r)\n",
    "    for i in range(len(columns)):\n",
    "        columns[i] = columns[i].title()\n",
    "        if columns[i] == 'Learner':\n",
    "            columns[i] = \"ChoiceModel\"\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    df.sort_values(by='Dataset')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ChoiceModel</th>\n",
       "      <th>F1Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Subset01Accuracy</th>\n",
       "      <th>Hammingaccuracy</th>\n",
       "      <th>Informedness</th>\n",
       "      <th>Aucscore</th>\n",
       "      <th>Averageprecisionscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FATE-Linear-Net</td>\n",
       "      <td>0.146±0.118</td>\n",
       "      <td>0.085±0.067</td>\n",
       "      <td>0.625±0.514</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.410±0.379</td>\n",
       "      <td>0.002±0.004</td>\n",
       "      <td>0.501±0.002</td>\n",
       "      <td>0.209±0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.565±0.041</td>\n",
       "      <td>0.579±0.045</td>\n",
       "      <td>0.721±0.049</td>\n",
       "      <td>0.038±0.012</td>\n",
       "      <td>0.859±0.018</td>\n",
       "      <td>0.609±0.057</td>\n",
       "      <td>0.935±0.038</td>\n",
       "      <td>0.834±0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.232±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.133±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.588±0.001</td>\n",
       "      <td>0.596±0.012</td>\n",
       "      <td>0.756±0.015</td>\n",
       "      <td>0.044±0.003</td>\n",
       "      <td>0.866±0.005</td>\n",
       "      <td>0.646±0.007</td>\n",
       "      <td>0.956±0.000</td>\n",
       "      <td>0.865±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.942±0.008</td>\n",
       "      <td>0.938±0.007</td>\n",
       "      <td>0.967±0.013</td>\n",
       "      <td>0.680±0.028</td>\n",
       "      <td>0.985±0.002</td>\n",
       "      <td>0.956±0.012</td>\n",
       "      <td>0.999±0.000</td>\n",
       "      <td>0.996±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.913±0.009</td>\n",
       "      <td>0.919±0.015</td>\n",
       "      <td>0.926±0.005</td>\n",
       "      <td>0.506±0.037</td>\n",
       "      <td>0.975±0.003</td>\n",
       "      <td>0.911±0.006</td>\n",
       "      <td>0.996±0.001</td>\n",
       "      <td>0.984±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.612±0.007</td>\n",
       "      <td>0.624±0.026</td>\n",
       "      <td>0.772±0.029</td>\n",
       "      <td>0.060±0.010</td>\n",
       "      <td>0.877±0.011</td>\n",
       "      <td>0.672±0.014</td>\n",
       "      <td>0.971±0.006</td>\n",
       "      <td>0.891±0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FATE-Linear-Net</td>\n",
       "      <td>0.577±0.044</td>\n",
       "      <td>0.432±0.024</td>\n",
       "      <td>0.960±0.088</td>\n",
       "      <td>0.004±0.001</td>\n",
       "      <td>0.447±0.010</td>\n",
       "      <td>-0.000±0.001</td>\n",
       "      <td>0.500±0.002</td>\n",
       "      <td>0.563±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mode</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.001</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.443±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.497±0.004</td>\n",
       "      <td>0.561±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mode</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.999±0.002</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.443±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.509±0.006</td>\n",
       "      <td>0.569±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.809±0.005</td>\n",
       "      <td>0.742±0.003</td>\n",
       "      <td>0.962±0.009</td>\n",
       "      <td>0.311±0.032</td>\n",
       "      <td>0.809±0.004</td>\n",
       "      <td>0.695±0.009</td>\n",
       "      <td>0.981±0.006</td>\n",
       "      <td>0.980±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mode</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.976±0.001</td>\n",
       "      <td>0.980±0.002</td>\n",
       "      <td>0.979±0.004</td>\n",
       "      <td>0.883±0.010</td>\n",
       "      <td>0.978±0.001</td>\n",
       "      <td>0.961±0.002</td>\n",
       "      <td>0.992±0.001</td>\n",
       "      <td>0.991±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mode</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.597±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.003±0.000</td>\n",
       "      <td>0.442±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.503±0.002</td>\n",
       "      <td>0.563±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FATE-Linear-Net</td>\n",
       "      <td>0.497±0.106</td>\n",
       "      <td>0.368±0.068</td>\n",
       "      <td>0.866±0.203</td>\n",
       "      <td>0.001±0.000</td>\n",
       "      <td>0.427±0.038</td>\n",
       "      <td>-0.007±0.009</td>\n",
       "      <td>0.500±0.005</td>\n",
       "      <td>0.545±0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Unique</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.508±0.004</td>\n",
       "      <td>0.542±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unique</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.562±0.001</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.998±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.001</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.511±0.006</td>\n",
       "      <td>0.553±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.963±0.003</td>\n",
       "      <td>0.962±0.006</td>\n",
       "      <td>0.975±0.004</td>\n",
       "      <td>0.814±0.020</td>\n",
       "      <td>0.972±0.003</td>\n",
       "      <td>0.945±0.005</td>\n",
       "      <td>0.992±0.001</td>\n",
       "      <td>0.989±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Unique</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.973±0.004</td>\n",
       "      <td>0.975±0.002</td>\n",
       "      <td>0.977±0.007</td>\n",
       "      <td>0.848±0.021</td>\n",
       "      <td>0.980±0.003</td>\n",
       "      <td>0.960±0.006</td>\n",
       "      <td>0.995±0.001</td>\n",
       "      <td>0.992±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Unique</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.562±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.405±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.504±0.001</td>\n",
       "      <td>0.538±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.428±0.021</td>\n",
       "      <td>0.317±0.022</td>\n",
       "      <td>0.965±0.037</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.358±0.039</td>\n",
       "      <td>0.058±0.029</td>\n",
       "      <td>0.614±0.009</td>\n",
       "      <td>0.465±0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.421±0.021</td>\n",
       "      <td>0.306±0.020</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.306±0.020</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.306±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.450±0.018</td>\n",
       "      <td>0.365±0.019</td>\n",
       "      <td>0.857±0.031</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.507±0.030</td>\n",
       "      <td>0.216±0.026</td>\n",
       "      <td>0.696±0.007</td>\n",
       "      <td>0.535±0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.446±0.020</td>\n",
       "      <td>0.356±0.022</td>\n",
       "      <td>0.870±0.034</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.488±0.024</td>\n",
       "      <td>0.196±0.012</td>\n",
       "      <td>0.691±0.007</td>\n",
       "      <td>0.534±0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.459±0.022</td>\n",
       "      <td>0.368±0.028</td>\n",
       "      <td>0.866±0.009</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.520±0.025</td>\n",
       "      <td>0.239±0.024</td>\n",
       "      <td>0.703±0.007</td>\n",
       "      <td>0.542±0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Letor_Y_2007_N_10</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.422±0.025</td>\n",
       "      <td>0.354±0.017</td>\n",
       "      <td>0.760±0.077</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.516±0.039</td>\n",
       "      <td>0.178±0.022</td>\n",
       "      <td>0.637±0.011</td>\n",
       "      <td>0.468±0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.427±0.022</td>\n",
       "      <td>0.316±0.023</td>\n",
       "      <td>0.973±0.018</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.350±0.035</td>\n",
       "      <td>0.051±0.019</td>\n",
       "      <td>0.613±0.012</td>\n",
       "      <td>0.465±0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.421±0.021</td>\n",
       "      <td>0.306±0.020</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.306±0.020</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.306±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.444±0.022</td>\n",
       "      <td>0.344±0.029</td>\n",
       "      <td>0.917±0.031</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.444±0.043</td>\n",
       "      <td>0.161±0.028</td>\n",
       "      <td>0.699±0.004</td>\n",
       "      <td>0.540±0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.455±0.022</td>\n",
       "      <td>0.357±0.025</td>\n",
       "      <td>0.894±0.017</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.489±0.022</td>\n",
       "      <td>0.215±0.019</td>\n",
       "      <td>0.703±0.005</td>\n",
       "      <td>0.544±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.462±0.020</td>\n",
       "      <td>0.380±0.030</td>\n",
       "      <td>0.829±0.028</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.551±0.025</td>\n",
       "      <td>0.272±0.020</td>\n",
       "      <td>0.706±0.008</td>\n",
       "      <td>0.543±0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Letor_Y_2007_N_5</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.427±0.023</td>\n",
       "      <td>0.348±0.022</td>\n",
       "      <td>0.793±0.020</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.498±0.020</td>\n",
       "      <td>0.170±0.022</td>\n",
       "      <td>0.631±0.015</td>\n",
       "      <td>0.461±0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.493±0.028</td>\n",
       "      <td>0.387±0.038</td>\n",
       "      <td>0.901±0.069</td>\n",
       "      <td>0.014±0.010</td>\n",
       "      <td>0.545±0.062</td>\n",
       "      <td>0.311±0.061</td>\n",
       "      <td>0.739±0.019</td>\n",
       "      <td>0.597±0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.424±0.021</td>\n",
       "      <td>0.298±0.020</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.298±0.020</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.298±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.527±0.022</td>\n",
       "      <td>0.446±0.029</td>\n",
       "      <td>0.846±0.041</td>\n",
       "      <td>0.042±0.022</td>\n",
       "      <td>0.645±0.025</td>\n",
       "      <td>0.428±0.015</td>\n",
       "      <td>0.786±0.018</td>\n",
       "      <td>0.655±0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.526±0.020</td>\n",
       "      <td>0.492±0.020</td>\n",
       "      <td>0.742±0.045</td>\n",
       "      <td>0.051±0.008</td>\n",
       "      <td>0.692±0.011</td>\n",
       "      <td>0.435±0.030</td>\n",
       "      <td>0.790±0.017</td>\n",
       "      <td>0.655±0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.533±0.018</td>\n",
       "      <td>0.484±0.038</td>\n",
       "      <td>0.782±0.059</td>\n",
       "      <td>0.055±0.014</td>\n",
       "      <td>0.683±0.036</td>\n",
       "      <td>0.444±0.020</td>\n",
       "      <td>0.796±0.014</td>\n",
       "      <td>0.663±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Letor_Y_2008_N_10</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.388±0.054</td>\n",
       "      <td>0.442±0.057</td>\n",
       "      <td>0.453±0.117</td>\n",
       "      <td>0.034±0.017</td>\n",
       "      <td>0.691±0.021</td>\n",
       "      <td>0.256±0.069</td>\n",
       "      <td>0.720±0.035</td>\n",
       "      <td>0.580±0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.497±0.029</td>\n",
       "      <td>0.392±0.033</td>\n",
       "      <td>0.893±0.025</td>\n",
       "      <td>0.021±0.024</td>\n",
       "      <td>0.567±0.038</td>\n",
       "      <td>0.337±0.059</td>\n",
       "      <td>0.742±0.038</td>\n",
       "      <td>0.606±0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.424±0.021</td>\n",
       "      <td>0.298±0.020</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.298±0.020</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.298±0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.524±0.023</td>\n",
       "      <td>0.438±0.039</td>\n",
       "      <td>0.866±0.045</td>\n",
       "      <td>0.037±0.013</td>\n",
       "      <td>0.627±0.034</td>\n",
       "      <td>0.418±0.025</td>\n",
       "      <td>0.794±0.014</td>\n",
       "      <td>0.662±0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.547±0.006</td>\n",
       "      <td>0.474±0.011</td>\n",
       "      <td>0.863±0.028</td>\n",
       "      <td>0.051±0.022</td>\n",
       "      <td>0.668±0.014</td>\n",
       "      <td>0.466±0.015</td>\n",
       "      <td>0.808±0.004</td>\n",
       "      <td>0.683±0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.545±0.013</td>\n",
       "      <td>0.473±0.016</td>\n",
       "      <td>0.843±0.013</td>\n",
       "      <td>0.045±0.016</td>\n",
       "      <td>0.647±0.004</td>\n",
       "      <td>0.435±0.017</td>\n",
       "      <td>0.801±0.020</td>\n",
       "      <td>0.678±0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Letor_Y_2008_N_5</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.477±0.024</td>\n",
       "      <td>0.449±0.023</td>\n",
       "      <td>0.675±0.090</td>\n",
       "      <td>0.023±0.009</td>\n",
       "      <td>0.655±0.024</td>\n",
       "      <td>0.341±0.051</td>\n",
       "      <td>0.739±0.026</td>\n",
       "      <td>0.607±0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>GeneralizedLinearModel</td>\n",
       "      <td>0.107±0.001</td>\n",
       "      <td>0.059±0.001</td>\n",
       "      <td>0.992±0.013</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.069±0.018</td>\n",
       "      <td>0.004±0.007</td>\n",
       "      <td>0.503±0.102</td>\n",
       "      <td>0.192±0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>RandomGuessing</td>\n",
       "      <td>0.106±0.000</td>\n",
       "      <td>0.058±0.000</td>\n",
       "      <td>1.000±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.058±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.500±0.000</td>\n",
       "      <td>0.058±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>PairwiseSVM</td>\n",
       "      <td>0.129±0.017</td>\n",
       "      <td>0.077±0.013</td>\n",
       "      <td>0.703±0.149</td>\n",
       "      <td>0.004±0.002</td>\n",
       "      <td>0.481±0.227</td>\n",
       "      <td>0.165±0.097</td>\n",
       "      <td>0.680±0.051</td>\n",
       "      <td>0.321±0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.181±0.000</td>\n",
       "      <td>0.120±0.000</td>\n",
       "      <td>0.544±0.004</td>\n",
       "      <td>0.013±0.000</td>\n",
       "      <td>0.764±0.003</td>\n",
       "      <td>0.324±0.001</td>\n",
       "      <td>0.726±0.000</td>\n",
       "      <td>0.366±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.197±0.004</td>\n",
       "      <td>0.132±0.003</td>\n",
       "      <td>0.543±0.011</td>\n",
       "      <td>0.016±0.001</td>\n",
       "      <td>0.781±0.005</td>\n",
       "      <td>0.342±0.006</td>\n",
       "      <td>0.737±0.003</td>\n",
       "      <td>0.375±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Exp_N_10</td>\n",
       "      <td>RankNet-Choice</td>\n",
       "      <td>0.164±0.013</td>\n",
       "      <td>0.099±0.010</td>\n",
       "      <td>0.632±0.049</td>\n",
       "      <td>0.002±0.001</td>\n",
       "      <td>0.649±0.061</td>\n",
       "      <td>0.269±0.022</td>\n",
       "      <td>0.718±0.001</td>\n",
       "      <td>0.360±0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dataset             ChoiceModel      F1Score    Precision  \\\n",
       "0              Pareto         FATE-Linear-Net  0.146±0.118  0.085±0.067   \n",
       "1              Pareto  GeneralizedLinearModel  0.565±0.041  0.579±0.045   \n",
       "2              Pareto          RandomGuessing  0.232±0.000  0.133±0.000   \n",
       "3              Pareto             PairwiseSVM  0.588±0.001  0.596±0.012   \n",
       "4              Pareto                FETA-Net  0.942±0.008  0.938±0.007   \n",
       "5              Pareto                FATE-Net  0.913±0.009  0.919±0.015   \n",
       "6              Pareto          RankNet-Choice  0.612±0.007  0.624±0.026   \n",
       "7                Mode         FATE-Linear-Net  0.577±0.044  0.432±0.024   \n",
       "8                Mode  GeneralizedLinearModel  0.597±0.000  0.442±0.000   \n",
       "9                Mode          RandomGuessing  0.597±0.000  0.442±0.000   \n",
       "10               Mode             PairwiseSVM  0.597±0.000  0.442±0.000   \n",
       "11               Mode                FETA-Net  0.809±0.005  0.742±0.003   \n",
       "12               Mode                FATE-Net  0.976±0.001  0.980±0.002   \n",
       "13               Mode          RankNet-Choice  0.597±0.000  0.442±0.000   \n",
       "14             Unique         FATE-Linear-Net  0.497±0.106  0.368±0.068   \n",
       "15             Unique  GeneralizedLinearModel  0.562±0.000  0.405±0.000   \n",
       "16             Unique          RandomGuessing  0.562±0.000  0.405±0.000   \n",
       "17             Unique             PairwiseSVM  0.562±0.001  0.405±0.000   \n",
       "18             Unique                FETA-Net  0.963±0.003  0.962±0.006   \n",
       "19             Unique                FATE-Net  0.973±0.004  0.975±0.002   \n",
       "20             Unique          RankNet-Choice  0.562±0.000  0.405±0.000   \n",
       "21  Letor_Y_2007_N_10  GeneralizedLinearModel  0.428±0.021  0.317±0.022   \n",
       "22  Letor_Y_2007_N_10          RandomGuessing  0.421±0.021  0.306±0.020   \n",
       "23  Letor_Y_2007_N_10             PairwiseSVM  0.450±0.018  0.365±0.019   \n",
       "24  Letor_Y_2007_N_10                FETA-Net  0.446±0.020  0.356±0.022   \n",
       "25  Letor_Y_2007_N_10                FATE-Net  0.459±0.022  0.368±0.028   \n",
       "26  Letor_Y_2007_N_10          RankNet-Choice  0.422±0.025  0.354±0.017   \n",
       "27   Letor_Y_2007_N_5  GeneralizedLinearModel  0.427±0.022  0.316±0.023   \n",
       "28   Letor_Y_2007_N_5          RandomGuessing  0.421±0.021  0.306±0.020   \n",
       "29   Letor_Y_2007_N_5             PairwiseSVM  0.444±0.022  0.344±0.029   \n",
       "30   Letor_Y_2007_N_5                FETA-Net  0.455±0.022  0.357±0.025   \n",
       "31   Letor_Y_2007_N_5                FATE-Net  0.462±0.020  0.380±0.030   \n",
       "32   Letor_Y_2007_N_5          RankNet-Choice  0.427±0.023  0.348±0.022   \n",
       "33  Letor_Y_2008_N_10  GeneralizedLinearModel  0.493±0.028  0.387±0.038   \n",
       "34  Letor_Y_2008_N_10          RandomGuessing  0.424±0.021  0.298±0.020   \n",
       "35  Letor_Y_2008_N_10             PairwiseSVM  0.527±0.022  0.446±0.029   \n",
       "36  Letor_Y_2008_N_10                FETA-Net  0.526±0.020  0.492±0.020   \n",
       "37  Letor_Y_2008_N_10                FATE-Net  0.533±0.018  0.484±0.038   \n",
       "38  Letor_Y_2008_N_10          RankNet-Choice  0.388±0.054  0.442±0.057   \n",
       "39   Letor_Y_2008_N_5  GeneralizedLinearModel  0.497±0.029  0.392±0.033   \n",
       "40   Letor_Y_2008_N_5          RandomGuessing  0.424±0.021  0.298±0.020   \n",
       "41   Letor_Y_2008_N_5             PairwiseSVM  0.524±0.023  0.438±0.039   \n",
       "42   Letor_Y_2008_N_5                FETA-Net  0.547±0.006  0.474±0.011   \n",
       "43   Letor_Y_2008_N_5                FATE-Net  0.545±0.013  0.473±0.016   \n",
       "44   Letor_Y_2008_N_5          RankNet-Choice  0.477±0.024  0.449±0.023   \n",
       "45           Exp_N_10  GeneralizedLinearModel  0.107±0.001  0.059±0.001   \n",
       "46           Exp_N_10          RandomGuessing  0.106±0.000  0.058±0.000   \n",
       "47           Exp_N_10             PairwiseSVM  0.129±0.017  0.077±0.013   \n",
       "48           Exp_N_10                FETA-Net  0.181±0.000  0.120±0.000   \n",
       "49           Exp_N_10                FATE-Net  0.197±0.004  0.132±0.003   \n",
       "50           Exp_N_10          RankNet-Choice  0.164±0.013  0.099±0.010   \n",
       "\n",
       "         Recall Subset01Accuracy Hammingaccuracy  Informedness     Aucscore  \\\n",
       "0   0.625±0.514      0.000±0.000     0.410±0.379   0.002±0.004  0.501±0.002   \n",
       "1   0.721±0.049      0.038±0.012     0.859±0.018   0.609±0.057  0.935±0.038   \n",
       "2   1.000±0.000      0.000±0.000     0.133±0.000   0.000±0.000  0.500±0.000   \n",
       "3   0.756±0.015      0.044±0.003     0.866±0.005   0.646±0.007  0.956±0.000   \n",
       "4   0.967±0.013      0.680±0.028     0.985±0.002   0.956±0.012  0.999±0.000   \n",
       "5   0.926±0.005      0.506±0.037     0.975±0.003   0.911±0.006  0.996±0.001   \n",
       "6   0.772±0.029      0.060±0.010     0.877±0.011   0.672±0.014  0.971±0.006   \n",
       "7   0.960±0.088      0.004±0.001     0.447±0.010  -0.000±0.001  0.500±0.002   \n",
       "8   0.999±0.001      0.003±0.000     0.443±0.000   0.000±0.000  0.497±0.004   \n",
       "9   1.000±0.000      0.003±0.000     0.442±0.000   0.000±0.000  0.500±0.000   \n",
       "10  0.999±0.002      0.003±0.000     0.443±0.000   0.000±0.000  0.509±0.006   \n",
       "11  0.962±0.009      0.311±0.032     0.809±0.004   0.695±0.009  0.981±0.006   \n",
       "12  0.979±0.004      0.883±0.010     0.978±0.001   0.961±0.002  0.992±0.001   \n",
       "13  1.000±0.000      0.003±0.000     0.442±0.000   0.000±0.000  0.503±0.002   \n",
       "14  0.866±0.203      0.001±0.000     0.427±0.038  -0.007±0.009  0.500±0.005   \n",
       "15  1.000±0.000      0.000±0.000     0.405±0.000   0.000±0.000  0.508±0.004   \n",
       "16  1.000±0.000      0.000±0.000     0.405±0.000   0.000±0.000  0.500±0.000   \n",
       "17  0.998±0.002      0.000±0.000     0.405±0.001   0.000±0.000  0.511±0.006   \n",
       "18  0.975±0.004      0.814±0.020     0.972±0.003   0.945±0.005  0.992±0.001   \n",
       "19  0.977±0.007      0.848±0.021     0.980±0.003   0.960±0.006  0.995±0.001   \n",
       "20  1.000±0.000      0.000±0.000     0.405±0.000   0.000±0.000  0.504±0.001   \n",
       "21  0.965±0.037      0.001±0.002     0.358±0.039   0.058±0.029  0.614±0.009   \n",
       "22  1.000±0.000      0.001±0.002     0.306±0.020   0.000±0.000  0.500±0.000   \n",
       "23  0.857±0.031      0.000±0.000     0.507±0.030   0.216±0.026  0.696±0.007   \n",
       "24  0.870±0.034      0.000±0.000     0.488±0.024   0.196±0.012  0.691±0.007   \n",
       "25  0.866±0.009      0.001±0.002     0.520±0.025   0.239±0.024  0.703±0.007   \n",
       "26  0.760±0.077      0.000±0.000     0.516±0.039   0.178±0.022  0.637±0.011   \n",
       "27  0.973±0.018      0.001±0.002     0.350±0.035   0.051±0.019  0.613±0.012   \n",
       "28  1.000±0.000      0.001±0.002     0.306±0.020   0.000±0.000  0.500±0.000   \n",
       "29  0.917±0.031      0.000±0.000     0.444±0.043   0.161±0.028  0.699±0.004   \n",
       "30  0.894±0.017      0.000±0.000     0.489±0.022   0.215±0.019  0.703±0.005   \n",
       "31  0.829±0.028      0.001±0.002     0.551±0.025   0.272±0.020  0.706±0.008   \n",
       "32  0.793±0.020      0.001±0.002     0.498±0.020   0.170±0.022  0.631±0.015   \n",
       "33  0.901±0.069      0.014±0.010     0.545±0.062   0.311±0.061  0.739±0.019   \n",
       "34  1.000±0.000      0.000±0.000     0.298±0.020   0.000±0.000  0.500±0.000   \n",
       "35  0.846±0.041      0.042±0.022     0.645±0.025   0.428±0.015  0.786±0.018   \n",
       "36  0.742±0.045      0.051±0.008     0.692±0.011   0.435±0.030  0.790±0.017   \n",
       "37  0.782±0.059      0.055±0.014     0.683±0.036   0.444±0.020  0.796±0.014   \n",
       "38  0.453±0.117      0.034±0.017     0.691±0.021   0.256±0.069  0.720±0.035   \n",
       "39  0.893±0.025      0.021±0.024     0.567±0.038   0.337±0.059  0.742±0.038   \n",
       "40  1.000±0.000      0.000±0.000     0.298±0.020   0.000±0.000  0.500±0.000   \n",
       "41  0.866±0.045      0.037±0.013     0.627±0.034   0.418±0.025  0.794±0.014   \n",
       "42  0.863±0.028      0.051±0.022     0.668±0.014   0.466±0.015  0.808±0.004   \n",
       "43  0.843±0.013      0.045±0.016     0.647±0.004   0.435±0.017  0.801±0.020   \n",
       "44  0.675±0.090      0.023±0.009     0.655±0.024   0.341±0.051  0.739±0.026   \n",
       "45  0.992±0.013      0.000±0.000     0.069±0.018   0.004±0.007  0.503±0.102   \n",
       "46  1.000±0.000      0.000±0.000     0.058±0.000   0.000±0.000  0.500±0.000   \n",
       "47  0.703±0.149      0.004±0.002     0.481±0.227   0.165±0.097  0.680±0.051   \n",
       "48  0.544±0.004      0.013±0.000     0.764±0.003   0.324±0.001  0.726±0.000   \n",
       "49  0.543±0.011      0.016±0.001     0.781±0.005   0.342±0.006  0.737±0.003   \n",
       "50  0.632±0.049      0.002±0.001     0.649±0.061   0.269±0.022  0.718±0.001   \n",
       "\n",
       "   Averageprecisionscore  \n",
       "0            0.209±0.117  \n",
       "1            0.834±0.055  \n",
       "2            0.133±0.000  \n",
       "3            0.865±0.000  \n",
       "4            0.996±0.000  \n",
       "5            0.984±0.003  \n",
       "6            0.891±0.019  \n",
       "7            0.563±0.005  \n",
       "8            0.561±0.002  \n",
       "9            0.442±0.000  \n",
       "10           0.569±0.004  \n",
       "11           0.980±0.006  \n",
       "12           0.991±0.002  \n",
       "13           0.563±0.002  \n",
       "14           0.545±0.034  \n",
       "15           0.542±0.002  \n",
       "16           0.405±0.000  \n",
       "17           0.553±0.005  \n",
       "18           0.989±0.001  \n",
       "19           0.992±0.001  \n",
       "20           0.538±0.001  \n",
       "21           0.465±0.021  \n",
       "22           0.306±0.020  \n",
       "23           0.535±0.028  \n",
       "24           0.534±0.021  \n",
       "25           0.542±0.026  \n",
       "26           0.468±0.027  \n",
       "27           0.465±0.026  \n",
       "28           0.306±0.020  \n",
       "29           0.540±0.022  \n",
       "30           0.544±0.020  \n",
       "31           0.543±0.024  \n",
       "32           0.461±0.025  \n",
       "33           0.597±0.028  \n",
       "34           0.298±0.020  \n",
       "35           0.655±0.026  \n",
       "36           0.655±0.019  \n",
       "37           0.663±0.015  \n",
       "38           0.580±0.037  \n",
       "39           0.606±0.041  \n",
       "40           0.298±0.020  \n",
       "41           0.662±0.024  \n",
       "42           0.683±0.008  \n",
       "43           0.678±0.017  \n",
       "44           0.607±0.016  \n",
       "45           0.192±0.050  \n",
       "46           0.058±0.000  \n",
       "47           0.321±0.047  \n",
       "48           0.366±0.000  \n",
       "49           0.375±0.003  \n",
       "50           0.360±0.002  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "combined = os.path.join(DIR_PATH, 'detailedresults' , \"ChoiceFunctions.csv\")\n",
    "dataFrame = None\n",
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset)\n",
    "    df_path = os.path.join(DIR_PATH, 'detailedresults' , dataset.split('_choice')[0].title()+'Choice.csv')\n",
    "    df.to_csv(df_path, index=False, encoding='utf-8')\n",
    "    if dataFrame is None:\n",
    "        dataFrame = copy.copy(df)\n",
    "    else:\n",
    "        dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame.to_csv(combined)\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    return [vals[0], vals[0] - vals[1]*1e-3]\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[['ChoiceModel',col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df['ChoiceModel'] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################\n",
      "Dataset Pareto\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & \\bfseries 0.942(8) & \\bfseries 0.680(28) & \\bfseries 0.956(12) & \\bfseries 0.999(0)\\\\\n",
      "\\fatenet & 0.913(9) & 0.506(37) & 0.911(6) & 0.996(1)\\\\\n",
      "\\ranknet & 0.612(7) & 0.060(10) & 0.672(14) & 0.971(6)\\\\\n",
      "\\pairwisesvm & 0.588(1) & 0.044(3) & 0.646(7) & 0.956(0)\\\\\n",
      "\\glm & 0.565(41) & 0.038(12) & 0.609(57) & 0.935(38)\\\\\n",
      "\\random & 0.232(0) & 0.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Mode\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.809(5) & 0.311(32) & 0.695(9) & 0.981(6)\\\\\n",
      "\\fatenet & \\bfseries 0.976(1) & \\bfseries 0.883(10) & \\bfseries 0.961(2) & \\bfseries 0.992(1)\\\\\n",
      "\\ranknet & 0.597(0) & 0.003(0) & 0.000(0) & 0.503(2)\\\\\n",
      "\\pairwisesvm & 0.597(0) & 0.003(0) & 0.000(0) & 0.509(6)\\\\\n",
      "\\glm & 0.597(0) & 0.003(0) & 0.000(0) & 0.497(4)\\\\\n",
      "\\random & 0.597(0) & 0.003(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Unique\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.963(3) & 0.814(20) & 0.945(5) & 0.992(1)\\\\\n",
      "\\fatenet & \\bfseries 0.973(4) & \\bfseries 0.848(21) & \\bfseries 0.960(6) & \\bfseries 0.995(1)\\\\\n",
      "\\ranknet & 0.562(0) & 0.000(0) & 0.000(0) & 0.504(1)\\\\\n",
      "\\pairwisesvm & 0.562(1) & 0.000(0) & 0.000(0) & 0.511(6)\\\\\n",
      "\\glm & 0.562(0) & 0.000(0) & 0.000(0) & 0.508(4)\\\\\n",
      "\\random & 0.562(0) & 0.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Letor Year $2007$ Objects $10$\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.446(20) & 0.000(0) & 0.196(12) & 0.691(7)\\\\\n",
      "\\fatenet & \\bfseries 0.459(22) & \\bfseries 0.001(2) & \\bfseries 0.239(24) & \\bfseries 0.703(7)\\\\\n",
      "\\ranknet & 0.422(25) & 0.000(0) & 0.178(22) & 0.637(11)\\\\\n",
      "\\pairwisesvm & 0.450(18) & 0.000(0) & 0.216(26) & 0.696(7)\\\\\n",
      "\\glm & 0.428(21) & \\bfseries 0.001(2) & 0.058(29) & 0.614(9)\\\\\n",
      "\\random & 0.421(21) & \\bfseries 0.001(2) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Letor Year $2007$ Objects $5$\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.455(22) & 0.000(0) & 0.215(19) & 0.703(5)\\\\\n",
      "\\fatenet & \\bfseries 0.462(20) & \\bfseries 0.001(2) & \\bfseries 0.272(20) & \\bfseries 0.706(8)\\\\\n",
      "\\ranknet & 0.427(23) & \\bfseries 0.001(2) & 0.170(22) & 0.631(15)\\\\\n",
      "\\pairwisesvm & 0.444(22) & 0.000(0) & 0.161(28) & 0.699(4)\\\\\n",
      "\\glm & 0.427(22) & \\bfseries 0.001(2) & 0.051(19) & 0.613(12)\\\\\n",
      "\\random & 0.421(21) & \\bfseries 0.001(2) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Letor Year $2008$ Objects $10$\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.526(20) & 0.051(8) & 0.435(30) & 0.790(17)\\\\\n",
      "\\fatenet & \\bfseries 0.533(18) & \\bfseries 0.055(14) & \\bfseries 0.444(20) & \\bfseries 0.796(14)\\\\\n",
      "\\ranknet & 0.388(54) & 0.034(17) & 0.256(69) & 0.720(35)\\\\\n",
      "\\pairwisesvm & 0.527(22) & 0.042(22) & 0.428(15) & 0.786(18)\\\\\n",
      "\\glm & 0.493(28) & 0.014(10) & 0.311(61) & 0.739(19)\\\\\n",
      "\\random & 0.424(21) & 0.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Letor Year $2008$ Objects $5$\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & \\bfseries 0.547(6) & \\bfseries 0.051(22) & \\bfseries 0.466(15) & \\bfseries 0.808(4)\\\\\n",
      "\\fatenet & 0.545(13) & 0.045(16) & 0.435(17) & 0.801(20)\\\\\n",
      "\\ranknet & 0.477(24) & 0.023(9) & 0.341(51) & 0.739(26)\\\\\n",
      "\\pairwisesvm & 0.524(23) & 0.037(13) & 0.418(25) & 0.794(14)\\\\\n",
      "\\glm & 0.497(29) & 0.021(24) & 0.337(59) & 0.742(38)\\\\\n",
      "\\random & 0.424(21) & 0.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "############################################################################\n",
      "Dataset Expedia Objects $10$\n",
      "\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ChoiceModel & $F_1$-measure & Subset$0/1$Accuracy & Informedness & Auc-Score\\\\\n",
      "\\midrule\n",
      "\\fetanet & 0.181(0) & 0.013(0) & 0.324(1) & 0.726(0)\\\\\n",
      "\\fatenet & \\bfseries 0.197(4) & \\bfseries 0.016(1) & \\bfseries 0.342(6) & \\bfseries 0.737(3)\\\\\n",
      "\\ranknet & 0.164(13) & 0.002(1) & 0.269(22) & 0.718(1)\\\\\n",
      "\\pairwisesvm & 0.129(17) & 0.004(2) & 0.165(97) & 0.680(51)\\\\\n",
      "\\glm & 0.107(1) & 0.000(0) & 0.004(7) & 0.503(102)\\\\\n",
      "\\random & 0.106(0) & 0.000(0) & 0.000(0) & 0.500(0)\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_name(name):\n",
    "    if \"Letor\" in name:\n",
    "        name = \"Letor Year ${}$ Objects ${}$\".format(name.split('_')[-3], name.split('_')[-1])\n",
    "    if \"Exp\" in name:\n",
    "        name = \"Expedia Objects ${}$\".format(name.split('_')[-1])\n",
    "    return name\n",
    "\n",
    "def create_latex(df):\n",
    "    grouped = df.groupby(['Dataset'])\n",
    "    for name, group in grouped:\n",
    "        custom_dict = dict()\n",
    "        for i, m in enumerate(models):\n",
    "            custom_dict[m] = i\n",
    "        group['rank'] = group['ChoiceModel'].map(custom_dict)\n",
    "        group.sort_values(by='rank', inplace=True)\n",
    "        del group[\"Dataset\"]\n",
    "        del group['rank']\n",
    "        group = mark_best(group)\n",
    "        group['ChoiceModel'].replace(to_replace=['GeneralizedLinearModel'], value='glm',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['FATE-Net'], value='fatenet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['FETA-Net'], value='fetanet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['RankNet-Choice'], value='ranknet',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['PairwiseSVM'], value='pairwisesvm',inplace=True)\n",
    "        group['ChoiceModel'].replace(to_replace=['RandomGuessing'], value='random',inplace=True)\n",
    "        group.rename(columns={'F1Score': '$F_1$-measure', 'Subset01Accuracy': 'Subset $0/1$ Accuracy', 'Aucscore':'Auc-Score'}, inplace=True)\n",
    "        del group['Hammingaccuracy']\n",
    "        del group['Precision']\n",
    "        del group['Recall']\n",
    "        #del group['Informedness']\n",
    "        del group['Averageprecisionscore']\n",
    "        print(\"############################################################################\")\n",
    "        print(\"Dataset {}\\n\".format(get_name(name)))\n",
    "        latex_code = group.to_latex(index = False)\n",
    "        latex_code = latex_code.replace(' ',\"\")\n",
    "        latex_code = latex_code.replace('&',\" & \")\n",
    "        latex_code = str(latex_code)\n",
    "        for learner in group['ChoiceModel']:\n",
    "            latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "        latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "        latex_code = latex_code.replace(\"\\\\$\", \"$\")\n",
    "        latex_code = latex_code.replace(\"\\\\_\", \"_\")\n",
    "        print(latex_code)\n",
    "for dataset in datasets:\n",
    "    df = create_combined_dfs(dataset, latex_row=True)\n",
    "    df.sort_values(by='Dataset')\n",
    "    create_latex(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
