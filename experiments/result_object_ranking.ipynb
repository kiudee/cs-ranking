{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/pritha/anaconda3/envs/linenv/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritha/anaconda3/envs/linenv/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from csrank.util import setup_logging, print_dictionary\n",
    "from result_script import *\n",
    "from csrank.experiments import OBJECT_RANKERS, lp_metric_dict\n",
    "from csrank.constants import OBJECT_RANKING\n",
    "import numpy as np\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "log_path = os.path.join(DIR_PATH, 'logs', 'results_or.log')\n",
    "FOLDER = \"journalresults\"\n",
    "latex_path = os.path.join(DIR_PATH, FOLDER, 'object_rankers.tex')\n",
    "df_path_combined = os.path.join(DIR_PATH, FOLDER , \"ObjectRankers.csv\")\n",
    "\n",
    "setup_logging(log_path=log_path, level=logging.ERROR)\n",
    "logger = logging.getLogger('ResultParsing')\n",
    "datasets = ['synthetic_or', 'letor_or', 'tag_genome_or', 'sushi']\n",
    "\n",
    "learning_problem = OBJECT_RANKING\n",
    "learning_model =  learners_map[learning_problem]\n",
    "keys = list(lp_metric_dict[learning_problem].keys())\n",
    "metrics = ', '.join([x.lower() for x in keys])\n",
    "models = ['FATE-Net', 'FETA-Net', \"FATE-Linear\", \"FETA-Linear\", 'RankSVM', 'ERR', 'RankNet', \"ListNet\", \"Random\"]\n",
    "Dlower = [d for d in OBJECT_RANKERS]\n",
    "models_dict = dict(zip(Dlower, models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>learner</th>\n",
       "      <th>kendallstau</th>\n",
       "      <th>spearmancorrelation</th>\n",
       "      <th>zeroonerankloss</th>\n",
       "      <th>zerooneranklossties</th>\n",
       "      <th>zerooneaccuracy</th>\n",
       "      <th>ndcgtopall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>396</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_741b</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.3084</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>375</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_741b</td>\n",
       "      <td>0.2441</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>395</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_741b</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.3779</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.6435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>397</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_741b</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>0.3069</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.6428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_741b</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>330</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_zero_0f2b</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.3123</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>399</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_zero_0f2b</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.3104</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.6546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>400</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_zero_0f2b</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.6556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>402</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_zero_0f2b</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.6543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>404</td>\n",
       "      <td>Critique_Fit_Less</td>\n",
       "      <td>feta_ranker_zero_0f2b</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.3747</td>\n",
       "      <td>0.3747</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>448</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_16ca</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.6843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>453</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_16ca</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>0.4380</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.3254</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.6792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>451</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_16ca</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.4489</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.6809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>449</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_16ca</td>\n",
       "      <td>0.3586</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>0.6823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>95</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_16ca</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.6816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>468</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_zero_ce11</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.7021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>466</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_zero_ce11</td>\n",
       "      <td>0.3849</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.7016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>452</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_zero_ce11</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.4557</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.7013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>329</td>\n",
       "      <td>Critique_Fit_More</td>\n",
       "      <td>feta_ranker_zero_ce11</td>\n",
       "      <td>0.3815</td>\n",
       "      <td>0.4583</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>445</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_09aa</td>\n",
       "      <td>0.3892</td>\n",
       "      <td>0.4710</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.7606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>446</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_09aa</td>\n",
       "      <td>0.3917</td>\n",
       "      <td>0.4721</td>\n",
       "      <td>0.3042</td>\n",
       "      <td>0.3042</td>\n",
       "      <td>0.0472</td>\n",
       "      <td>0.7602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_09aa</td>\n",
       "      <td>0.3937</td>\n",
       "      <td>0.4761</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.7605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>444</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_09aa</td>\n",
       "      <td>0.3909</td>\n",
       "      <td>0.4735</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.7569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>443</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_09aa</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>0.4741</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.7596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>473</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_zero_d8ac</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.2784</td>\n",
       "      <td>0.0821</td>\n",
       "      <td>0.7989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>472</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_zero_d8ac</td>\n",
       "      <td>0.4481</td>\n",
       "      <td>0.5292</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>0.0840</td>\n",
       "      <td>0.8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>436</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_zero_d8ac</td>\n",
       "      <td>0.4480</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.2760</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.8035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>328</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_zero_d8ac</td>\n",
       "      <td>0.4456</td>\n",
       "      <td>0.5268</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.0823</td>\n",
       "      <td>0.8002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>474</td>\n",
       "      <td>Nearest_Neighbour</td>\n",
       "      <td>feta_ranker_zero_d8ac</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.8038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     job_id            dataset                learner  kendallstau  \\\n",
       "66      396  Critique_Fit_Less       feta_ranker_741b       0.2458   \n",
       "64      375  Critique_Fit_Less       feta_ranker_741b       0.2441   \n",
       "65      395  Critique_Fit_Less       feta_ranker_741b       0.2442   \n",
       "67      397  Critique_Fit_Less       feta_ranker_741b       0.2461   \n",
       "11       89  Critique_Fit_Less       feta_ranker_741b       0.2415   \n",
       "68      330  Critique_Fit_Less  feta_ranker_zero_0f2b       0.2542   \n",
       "69      399  Critique_Fit_Less  feta_ranker_zero_0f2b       0.2521   \n",
       "71      400  Critique_Fit_Less  feta_ranker_zero_0f2b       0.2523   \n",
       "73      402  Critique_Fit_Less  feta_ranker_zero_0f2b       0.2557   \n",
       "75      404  Critique_Fit_Less  feta_ranker_zero_0f2b       0.2506   \n",
       "108     448  Critique_Fit_More       feta_ranker_16ca       0.3590   \n",
       "111     453  Critique_Fit_More       feta_ranker_16ca       0.3491   \n",
       "110     451  Critique_Fit_More       feta_ranker_16ca       0.3570   \n",
       "109     449  Critique_Fit_More       feta_ranker_16ca       0.3586   \n",
       "13       95  Critique_Fit_More       feta_ranker_16ca       0.3569   \n",
       "127     468  Critique_Fit_More  feta_ranker_zero_ce11       0.3827   \n",
       "122     466  Critique_Fit_More  feta_ranker_zero_ce11       0.3849   \n",
       "118     452  Critique_Fit_More  feta_ranker_zero_ce11       0.3793   \n",
       "116     329  Critique_Fit_More  feta_ranker_zero_ce11       0.3815   \n",
       "105     445  Nearest_Neighbour       feta_ranker_09aa       0.3892   \n",
       "106     446  Nearest_Neighbour       feta_ranker_09aa       0.3917   \n",
       "5        83  Nearest_Neighbour       feta_ranker_09aa       0.3937   \n",
       "104     444  Nearest_Neighbour       feta_ranker_09aa       0.3909   \n",
       "103     443  Nearest_Neighbour       feta_ranker_09aa       0.3927   \n",
       "131     473  Nearest_Neighbour  feta_ranker_zero_d8ac       0.4432   \n",
       "130     472  Nearest_Neighbour  feta_ranker_zero_d8ac       0.4481   \n",
       "129     436  Nearest_Neighbour  feta_ranker_zero_d8ac       0.4480   \n",
       "128     328  Nearest_Neighbour  feta_ranker_zero_d8ac       0.4456   \n",
       "132     474  Nearest_Neighbour  feta_ranker_zero_d8ac       0.4528   \n",
       "\n",
       "     spearmancorrelation  zeroonerankloss  zerooneranklossties  \\\n",
       "66                0.3084           0.3771               0.3771   \n",
       "64                0.3051           0.3780               0.3780   \n",
       "65                0.3046           0.3779               0.3779   \n",
       "67                0.3069           0.3769               0.3769   \n",
       "11                0.3014           0.3793               0.3793   \n",
       "68                0.3123           0.3729               0.3729   \n",
       "69                0.3104           0.3739               0.3739   \n",
       "71                0.3107           0.3738               0.3738   \n",
       "73                0.3146           0.3721               0.3721   \n",
       "75                0.3095           0.3747               0.3747   \n",
       "108               0.4485           0.3205               0.3205   \n",
       "111               0.4380           0.3254               0.3254   \n",
       "110               0.4489           0.3215               0.3215   \n",
       "109               0.4496           0.3207               0.3207   \n",
       "13                0.4479           0.3215               0.3215   \n",
       "127               0.4588           0.3087               0.3087   \n",
       "122               0.4619           0.3075               0.3075   \n",
       "118               0.4557           0.3103               0.3103   \n",
       "116               0.4583           0.3093               0.3093   \n",
       "105               0.4710           0.3054               0.3054   \n",
       "106               0.4721           0.3042               0.3042   \n",
       "5                 0.4761           0.3031               0.3031   \n",
       "104               0.4735           0.3046               0.3046   \n",
       "103               0.4741           0.3037               0.3037   \n",
       "131               0.5246           0.2784               0.2784   \n",
       "130               0.5292           0.2759               0.2759   \n",
       "129               0.5298           0.2760               0.2760   \n",
       "128               0.5268           0.2772               0.2772   \n",
       "132               0.5347           0.2736               0.2736   \n",
       "\n",
       "     zerooneaccuracy  ndcgtopall  \n",
       "66            0.0195      0.6416  \n",
       "64            0.0217      0.6438  \n",
       "65            0.0219      0.6435  \n",
       "67            0.0217      0.6428  \n",
       "11            0.0214      0.6411  \n",
       "68            0.0305      0.6550  \n",
       "69            0.0293      0.6546  \n",
       "71            0.0297      0.6556  \n",
       "73            0.0301      0.6543  \n",
       "75            0.0301      0.6525  \n",
       "108           0.0228      0.6843  \n",
       "111           0.0226      0.6792  \n",
       "110           0.0209      0.6809  \n",
       "109           0.0227      0.6823  \n",
       "13            0.0213      0.6816  \n",
       "127           0.0638      0.7021  \n",
       "122           0.0614      0.7016  \n",
       "118           0.0595      0.7013  \n",
       "116           0.0600      0.6999  \n",
       "105           0.0429      0.7606  \n",
       "106           0.0472      0.7602  \n",
       "5             0.0441      0.7605  \n",
       "104           0.0408      0.7569  \n",
       "103           0.0438      0.7596  \n",
       "131           0.0821      0.7989  \n",
       "130           0.0840      0.8018  \n",
       "129           0.0843      0.8035  \n",
       "128           0.0823      0.8002  \n",
       "132           0.0854      0.8038  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = datasets[2]\n",
    "df, cols = get_results_for_dataset(d, logger, learning_problem, False)\n",
    "df = df.sort_values(by=['dataset', 'learner'], ascending=[True, True])\n",
    "df = df[df['learner'].str.contains('feta_')]\n",
    "df.sort_values(by='learner')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    if len(vals)==1:\n",
    "        x = [vals[0], vals[0]-0.0]\n",
    "    else:\n",
    "        x = [vals[0], vals[0] - vals[1]]\n",
    "    return x\n",
    "def create_final_result(dataset, dataset_function=get_combined_results ,latex_row=False):\n",
    "    df_full = dataset_function(dataset, logger, learning_problem, latex_row=latex_row)\n",
    "    data = []\n",
    "    for dataset, df in df_full.groupby(['Dataset']):\n",
    "        for m in OBJECT_RANKERS:\n",
    "            row = df[df[learning_model].str.contains(m)].values\n",
    "            onerow = None\n",
    "            if len(row) > 1:\n",
    "                if dataset_function==get_combined_results:\n",
    "                    values = np.array([get_val(val[2]) for val in row])\n",
    "                else:\n",
    "                    values = np.array([[val[2], val[2] - val[7]] for val in row])\n",
    "                maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0][0]\n",
    "                logger.error(\"dataset {} model {}, vals {}, maxi {}\".format(dataset, row[:, 1], values, maxi))\n",
    "                row = row[maxi]\n",
    "                row[1] = models_dict[m]\n",
    "                onerow = row\n",
    "\n",
    "            elif len(row)==1:\n",
    "                row[0][1] = models_dict[m]\n",
    "                onerow = row[0]\n",
    "            if onerow is not None:\n",
    "                onerow[0] = get_dataset_name(onerow[0])\n",
    "                data.append(onerow)\n",
    "    columns = df_full.columns\n",
    "    dataframe = pd.DataFrame(data, columns=columns)\n",
    "    dataframe = dataframe.sort_values(by=[columns[0], columns[2]], ascending=[True, False])\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Ranker</th>\n",
       "      <th>Kendallstau</th>\n",
       "      <th>Spearmancorrelation</th>\n",
       "      <th>Zeroonerankloss</th>\n",
       "      <th>Zerooneranklossties</th>\n",
       "      <th>Zerooneaccuracy</th>\n",
       "      <th>Ndcgtopall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.456±0.002</td>\n",
       "      <td>0.539±0.002</td>\n",
       "      <td>0.272±0.001</td>\n",
       "      <td>0.272±0.001</td>\n",
       "      <td>0.092±0.002</td>\n",
       "      <td>0.738±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.382±0.002</td>\n",
       "      <td>0.459±0.003</td>\n",
       "      <td>0.309±0.001</td>\n",
       "      <td>0.309±0.001</td>\n",
       "      <td>0.061±0.002</td>\n",
       "      <td>0.701±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.341±0.001</td>\n",
       "      <td>0.414±0.002</td>\n",
       "      <td>0.330±0.001</td>\n",
       "      <td>0.330±0.001</td>\n",
       "      <td>0.047±0.001</td>\n",
       "      <td>0.677±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.288±0.001</td>\n",
       "      <td>0.355±0.002</td>\n",
       "      <td>0.356±0.001</td>\n",
       "      <td>0.356±0.001</td>\n",
       "      <td>0.034±0.001</td>\n",
       "      <td>0.659±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.283±0.002</td>\n",
       "      <td>0.365±0.002</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.013±0.001</td>\n",
       "      <td>0.639±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.282±0.002</td>\n",
       "      <td>0.369±0.002</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.009±0.001</td>\n",
       "      <td>0.640±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.162±0.032</td>\n",
       "      <td>0.202±0.039</td>\n",
       "      <td>0.419±0.016</td>\n",
       "      <td>0.419±0.016</td>\n",
       "      <td>0.018±0.003</td>\n",
       "      <td>0.625±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.105±0.029</td>\n",
       "      <td>0.127±0.037</td>\n",
       "      <td>0.447±0.015</td>\n",
       "      <td>0.447±0.015</td>\n",
       "      <td>0.018±0.002</td>\n",
       "      <td>0.633±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.266±0.003</td>\n",
       "      <td>0.320±0.004</td>\n",
       "      <td>0.367±0.002</td>\n",
       "      <td>0.367±0.002</td>\n",
       "      <td>0.057±0.001</td>\n",
       "      <td>0.667±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.257±0.004</td>\n",
       "      <td>0.317±0.004</td>\n",
       "      <td>0.371±0.002</td>\n",
       "      <td>0.371±0.002</td>\n",
       "      <td>0.030±0.001</td>\n",
       "      <td>0.653±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.253±0.002</td>\n",
       "      <td>0.312±0.002</td>\n",
       "      <td>0.373±0.001</td>\n",
       "      <td>0.373±0.001</td>\n",
       "      <td>0.030±0.000</td>\n",
       "      <td>0.654±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.243±0.002</td>\n",
       "      <td>0.306±0.002</td>\n",
       "      <td>0.378±0.001</td>\n",
       "      <td>0.378±0.001</td>\n",
       "      <td>0.021±0.001</td>\n",
       "      <td>0.638±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.242±0.001</td>\n",
       "      <td>0.312±0.002</td>\n",
       "      <td>0.379±0.001</td>\n",
       "      <td>0.379±0.001</td>\n",
       "      <td>0.011±0.001</td>\n",
       "      <td>0.637±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.221±0.001</td>\n",
       "      <td>0.274±0.002</td>\n",
       "      <td>0.389±0.001</td>\n",
       "      <td>0.389±0.001</td>\n",
       "      <td>0.025±0.001</td>\n",
       "      <td>0.646±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.127±0.029</td>\n",
       "      <td>0.158±0.036</td>\n",
       "      <td>0.437±0.015</td>\n",
       "      <td>0.437±0.015</td>\n",
       "      <td>0.016±0.003</td>\n",
       "      <td>0.619±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.048±0.028</td>\n",
       "      <td>0.058±0.035</td>\n",
       "      <td>0.476±0.014</td>\n",
       "      <td>0.476±0.014</td>\n",
       "      <td>0.013±0.002</td>\n",
       "      <td>0.607±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.578±0.003</td>\n",
       "      <td>0.666±0.003</td>\n",
       "      <td>0.211±0.002</td>\n",
       "      <td>0.211±0.002</td>\n",
       "      <td>0.151±0.003</td>\n",
       "      <td>0.847±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.448±0.004</td>\n",
       "      <td>0.529±0.004</td>\n",
       "      <td>0.276±0.002</td>\n",
       "      <td>0.276±0.002</td>\n",
       "      <td>0.084±0.001</td>\n",
       "      <td>0.802±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.392±0.003</td>\n",
       "      <td>0.463±0.003</td>\n",
       "      <td>0.304±0.002</td>\n",
       "      <td>0.304±0.002</td>\n",
       "      <td>0.073±0.002</td>\n",
       "      <td>0.781±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.366±0.001</td>\n",
       "      <td>0.434±0.001</td>\n",
       "      <td>0.317±0.000</td>\n",
       "      <td>0.317±0.000</td>\n",
       "      <td>0.064±0.000</td>\n",
       "      <td>0.745±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.357±0.002</td>\n",
       "      <td>0.424±0.002</td>\n",
       "      <td>0.321±0.001</td>\n",
       "      <td>0.321±0.001</td>\n",
       "      <td>0.061±0.001</td>\n",
       "      <td>0.732±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.353±0.001</td>\n",
       "      <td>0.433±0.001</td>\n",
       "      <td>0.323±0.001</td>\n",
       "      <td>0.323±0.001</td>\n",
       "      <td>0.023±0.001</td>\n",
       "      <td>0.731±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.344±0.006</td>\n",
       "      <td>0.414±0.006</td>\n",
       "      <td>0.328±0.003</td>\n",
       "      <td>0.328±0.003</td>\n",
       "      <td>0.052±0.002</td>\n",
       "      <td>0.760±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.259±0.028</td>\n",
       "      <td>0.314±0.032</td>\n",
       "      <td>0.371±0.014</td>\n",
       "      <td>0.371±0.014</td>\n",
       "      <td>0.036±0.006</td>\n",
       "      <td>0.702±0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset       Ranker  Kendallstau  \\\n",
       "8   Best Critique-Fit Movie d=+1     FATE-Net  0.456±0.002   \n",
       "9   Best Critique-Fit Movie d=+1     FETA-Net  0.382±0.002   \n",
       "14  Best Critique-Fit Movie d=+1      RankNet  0.341±0.001   \n",
       "13  Best Critique-Fit Movie d=+1          ERR  0.288±0.001   \n",
       "10  Best Critique-Fit Movie d=+1  FATE-Linear  0.283±0.002   \n",
       "11  Best Critique-Fit Movie d=+1  FETA-Linear  0.282±0.002   \n",
       "12  Best Critique-Fit Movie d=+1      RankSVM  0.162±0.032   \n",
       "15  Best Critique-Fit Movie d=+1      ListNet  0.105±0.029   \n",
       "0   Best Critique-Fit Movie d=-1     FATE-Net  0.266±0.003   \n",
       "6   Best Critique-Fit Movie d=-1      RankNet  0.257±0.004   \n",
       "1   Best Critique-Fit Movie d=-1     FETA-Net  0.253±0.002   \n",
       "2   Best Critique-Fit Movie d=-1  FATE-Linear  0.243±0.002   \n",
       "3   Best Critique-Fit Movie d=-1  FETA-Linear  0.242±0.001   \n",
       "5   Best Critique-Fit Movie d=-1          ERR  0.221±0.001   \n",
       "4   Best Critique-Fit Movie d=-1      RankSVM  0.127±0.029   \n",
       "7   Best Critique-Fit Movie d=-1      ListNet  0.048±0.028   \n",
       "16            Most Similar Movie     FATE-Net  0.578±0.003   \n",
       "17            Most Similar Movie     FETA-Net  0.448±0.004   \n",
       "22            Most Similar Movie      RankNet  0.392±0.003   \n",
       "21            Most Similar Movie          ERR  0.366±0.001   \n",
       "18            Most Similar Movie  FATE-Linear  0.357±0.002   \n",
       "19            Most Similar Movie  FETA-Linear  0.353±0.001   \n",
       "23            Most Similar Movie      ListNet  0.344±0.006   \n",
       "20            Most Similar Movie      RankSVM  0.259±0.028   \n",
       "\n",
       "   Spearmancorrelation Zeroonerankloss Zerooneranklossties Zerooneaccuracy  \\\n",
       "8          0.539±0.002     0.272±0.001         0.272±0.001     0.092±0.002   \n",
       "9          0.459±0.003     0.309±0.001         0.309±0.001     0.061±0.002   \n",
       "14         0.414±0.002     0.330±0.001         0.330±0.001     0.047±0.001   \n",
       "13         0.355±0.002     0.356±0.001         0.356±0.001     0.034±0.001   \n",
       "10         0.365±0.002     0.359±0.001         0.359±0.001     0.013±0.001   \n",
       "11         0.369±0.002     0.359±0.001         0.359±0.001     0.009±0.001   \n",
       "12         0.202±0.039     0.419±0.016         0.419±0.016     0.018±0.003   \n",
       "15         0.127±0.037     0.447±0.015         0.447±0.015     0.018±0.002   \n",
       "0          0.320±0.004     0.367±0.002         0.367±0.002     0.057±0.001   \n",
       "6          0.317±0.004     0.371±0.002         0.371±0.002     0.030±0.001   \n",
       "1          0.312±0.002     0.373±0.001         0.373±0.001     0.030±0.000   \n",
       "2          0.306±0.002     0.378±0.001         0.378±0.001     0.021±0.001   \n",
       "3          0.312±0.002     0.379±0.001         0.379±0.001     0.011±0.001   \n",
       "5          0.274±0.002     0.389±0.001         0.389±0.001     0.025±0.001   \n",
       "4          0.158±0.036     0.437±0.015         0.437±0.015     0.016±0.003   \n",
       "7          0.058±0.035     0.476±0.014         0.476±0.014     0.013±0.002   \n",
       "16         0.666±0.003     0.211±0.002         0.211±0.002     0.151±0.003   \n",
       "17         0.529±0.004     0.276±0.002         0.276±0.002     0.084±0.001   \n",
       "22         0.463±0.003     0.304±0.002         0.304±0.002     0.073±0.002   \n",
       "21         0.434±0.001     0.317±0.000         0.317±0.000     0.064±0.000   \n",
       "18         0.424±0.002     0.321±0.001         0.321±0.001     0.061±0.001   \n",
       "19         0.433±0.001     0.323±0.001         0.323±0.001     0.023±0.001   \n",
       "23         0.414±0.006     0.328±0.003         0.328±0.003     0.052±0.002   \n",
       "20         0.314±0.032     0.371±0.014         0.371±0.014     0.036±0.006   \n",
       "\n",
       "     Ndcgtopall  \n",
       "8   0.738±0.001  \n",
       "9   0.701±0.001  \n",
       "14  0.677±0.001  \n",
       "13  0.659±0.001  \n",
       "10  0.639±0.001  \n",
       "11  0.640±0.001  \n",
       "12  0.625±0.007  \n",
       "15  0.633±0.006  \n",
       "0   0.667±0.001  \n",
       "6   0.653±0.001  \n",
       "1   0.654±0.001  \n",
       "2   0.638±0.001  \n",
       "3   0.637±0.001  \n",
       "5   0.646±0.001  \n",
       "4   0.619±0.006  \n",
       "7   0.607±0.009  \n",
       "16  0.847±0.002  \n",
       "17  0.802±0.002  \n",
       "22  0.781±0.001  \n",
       "21  0.745±0.001  \n",
       "18  0.732±0.002  \n",
       "19  0.731±0.001  \n",
       "23  0.760±0.001  \n",
       "20  0.702±0.006  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_final_result(d, latex_row=False)\n",
    "df = df.sort_values(by=['Dataset','Kendallstau'], ascending=[True,False])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Ranker</th>\n",
       "      <th>Kendallstau</th>\n",
       "      <th>Spearmancorrelation</th>\n",
       "      <th>Zeroonerankloss</th>\n",
       "      <th>Zerooneranklossties</th>\n",
       "      <th>Zerooneaccuracy</th>\n",
       "      <th>Ndcgtopall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.811±0.002</td>\n",
       "      <td>0.867±0.002</td>\n",
       "      <td>0.094±0.001</td>\n",
       "      <td>0.094±0.001</td>\n",
       "      <td>0.466±0.005</td>\n",
       "      <td>0.940±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.482±0.160</td>\n",
       "      <td>0.544±0.181</td>\n",
       "      <td>0.259±0.080</td>\n",
       "      <td>0.259±0.080</td>\n",
       "      <td>0.144±0.045</td>\n",
       "      <td>0.820±0.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.365±0.001</td>\n",
       "      <td>0.417±0.001</td>\n",
       "      <td>0.317±0.001</td>\n",
       "      <td>0.317±0.001</td>\n",
       "      <td>0.089±0.001</td>\n",
       "      <td>0.779±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.364±0.001</td>\n",
       "      <td>0.416±0.002</td>\n",
       "      <td>0.318±0.001</td>\n",
       "      <td>0.318±0.001</td>\n",
       "      <td>0.087±0.001</td>\n",
       "      <td>0.778±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.148±0.002</td>\n",
       "      <td>0.240±0.009</td>\n",
       "      <td>0.426±0.001</td>\n",
       "      <td>0.426±0.001</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.637±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.001±0.002</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.008±0.000</td>\n",
       "      <td>0.526±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.000±0.002</td>\n",
       "      <td>-0.000±0.002</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.008±0.001</td>\n",
       "      <td>0.525±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Medoid</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>-0.000±0.001</td>\n",
       "      <td>-0.000±0.001</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.005±0.004</td>\n",
       "      <td>0.545±0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.824±0.001</td>\n",
       "      <td>0.879±0.001</td>\n",
       "      <td>0.088±0.001</td>\n",
       "      <td>0.088±0.001</td>\n",
       "      <td>0.486±0.003</td>\n",
       "      <td>0.949±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.532±0.005</td>\n",
       "      <td>0.601±0.004</td>\n",
       "      <td>0.234±0.002</td>\n",
       "      <td>0.234±0.002</td>\n",
       "      <td>0.159±0.005</td>\n",
       "      <td>0.851±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.364±0.001</td>\n",
       "      <td>0.416±0.001</td>\n",
       "      <td>0.318±0.001</td>\n",
       "      <td>0.318±0.001</td>\n",
       "      <td>0.087±0.001</td>\n",
       "      <td>0.778±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.362±0.005</td>\n",
       "      <td>0.413±0.007</td>\n",
       "      <td>0.319±0.003</td>\n",
       "      <td>0.319±0.003</td>\n",
       "      <td>0.088±0.001</td>\n",
       "      <td>0.777±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.152±0.001</td>\n",
       "      <td>0.257±0.002</td>\n",
       "      <td>0.424±0.000</td>\n",
       "      <td>0.424±0.000</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.638±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.023±0.049</td>\n",
       "      <td>0.031±0.064</td>\n",
       "      <td>0.488±0.024</td>\n",
       "      <td>0.488±0.024</td>\n",
       "      <td>0.005±0.003</td>\n",
       "      <td>0.546±0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.001±0.001</td>\n",
       "      <td>0.002±0.001</td>\n",
       "      <td>0.499±0.001</td>\n",
       "      <td>0.499±0.001</td>\n",
       "      <td>0.008±0.000</td>\n",
       "      <td>0.527±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pareto</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.000±0.002</td>\n",
       "      <td>0.000±0.002</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.500±0.001</td>\n",
       "      <td>0.008±0.001</td>\n",
       "      <td>0.525±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.724±0.155</td>\n",
       "      <td>0.667±0.374</td>\n",
       "      <td>0.138±0.078</td>\n",
       "      <td>0.138±0.078</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.494±0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.658±0.006</td>\n",
       "      <td>0.836±0.006</td>\n",
       "      <td>0.171±0.003</td>\n",
       "      <td>0.171±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.616±0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.653±0.006</td>\n",
       "      <td>0.832±0.006</td>\n",
       "      <td>0.173±0.003</td>\n",
       "      <td>0.173±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.472±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.651±0.006</td>\n",
       "      <td>0.831±0.006</td>\n",
       "      <td>0.174±0.003</td>\n",
       "      <td>0.174±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.608±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.644±0.005</td>\n",
       "      <td>0.831±0.006</td>\n",
       "      <td>0.178±0.003</td>\n",
       "      <td>0.178±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.207±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.627±0.005</td>\n",
       "      <td>0.811±0.005</td>\n",
       "      <td>0.186±0.002</td>\n",
       "      <td>0.186±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.563±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.625±0.025</td>\n",
       "      <td>0.802±0.028</td>\n",
       "      <td>0.187±0.012</td>\n",
       "      <td>0.187±0.012</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.597±0.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MQ2007 10 Objects</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.622±0.025</td>\n",
       "      <td>0.797±0.026</td>\n",
       "      <td>0.189±0.013</td>\n",
       "      <td>0.189±0.013</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.677±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.660±0.005</td>\n",
       "      <td>0.836±0.005</td>\n",
       "      <td>0.170±0.003</td>\n",
       "      <td>0.170±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.685±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.659±0.005</td>\n",
       "      <td>0.837±0.004</td>\n",
       "      <td>0.170±0.002</td>\n",
       "      <td>0.170±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.608±0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.653±0.024</td>\n",
       "      <td>0.829±0.024</td>\n",
       "      <td>0.173±0.012</td>\n",
       "      <td>0.173±0.012</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.662±0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.653±0.006</td>\n",
       "      <td>0.833±0.006</td>\n",
       "      <td>0.174±0.003</td>\n",
       "      <td>0.174±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.379±0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.651±0.006</td>\n",
       "      <td>0.831±0.006</td>\n",
       "      <td>0.175±0.003</td>\n",
       "      <td>0.175±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.615±0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MQ2007 5 Objects</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.645±0.005</td>\n",
       "      <td>0.826±0.005</td>\n",
       "      <td>0.178±0.002</td>\n",
       "      <td>0.178±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.621±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.341±0.001</td>\n",
       "      <td>0.414±0.002</td>\n",
       "      <td>0.330±0.001</td>\n",
       "      <td>0.330±0.001</td>\n",
       "      <td>0.047±0.001</td>\n",
       "      <td>0.677±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.288±0.001</td>\n",
       "      <td>0.355±0.002</td>\n",
       "      <td>0.356±0.001</td>\n",
       "      <td>0.356±0.001</td>\n",
       "      <td>0.034±0.001</td>\n",
       "      <td>0.659±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.283±0.002</td>\n",
       "      <td>0.365±0.002</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.013±0.001</td>\n",
       "      <td>0.639±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.282±0.002</td>\n",
       "      <td>0.369±0.002</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.359±0.001</td>\n",
       "      <td>0.009±0.001</td>\n",
       "      <td>0.640±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.162±0.032</td>\n",
       "      <td>0.202±0.039</td>\n",
       "      <td>0.419±0.016</td>\n",
       "      <td>0.419±0.016</td>\n",
       "      <td>0.018±0.003</td>\n",
       "      <td>0.625±0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Best Critique-Fit Movie d=+1</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.105±0.029</td>\n",
       "      <td>0.127±0.037</td>\n",
       "      <td>0.447±0.015</td>\n",
       "      <td>0.447±0.015</td>\n",
       "      <td>0.018±0.002</td>\n",
       "      <td>0.633±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.266±0.003</td>\n",
       "      <td>0.320±0.004</td>\n",
       "      <td>0.367±0.002</td>\n",
       "      <td>0.367±0.002</td>\n",
       "      <td>0.057±0.001</td>\n",
       "      <td>0.667±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.257±0.000</td>\n",
       "      <td>0.317±0.001</td>\n",
       "      <td>0.371±0.000</td>\n",
       "      <td>0.371±0.000</td>\n",
       "      <td>0.030±0.001</td>\n",
       "      <td>0.653±0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.253±0.002</td>\n",
       "      <td>0.312±0.002</td>\n",
       "      <td>0.373±0.001</td>\n",
       "      <td>0.373±0.001</td>\n",
       "      <td>0.030±0.000</td>\n",
       "      <td>0.654±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.243±0.002</td>\n",
       "      <td>0.306±0.002</td>\n",
       "      <td>0.378±0.001</td>\n",
       "      <td>0.378±0.001</td>\n",
       "      <td>0.021±0.001</td>\n",
       "      <td>0.638±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.242±0.001</td>\n",
       "      <td>0.312±0.002</td>\n",
       "      <td>0.379±0.001</td>\n",
       "      <td>0.379±0.001</td>\n",
       "      <td>0.011±0.001</td>\n",
       "      <td>0.637±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.221±0.001</td>\n",
       "      <td>0.274±0.002</td>\n",
       "      <td>0.389±0.001</td>\n",
       "      <td>0.389±0.001</td>\n",
       "      <td>0.025±0.001</td>\n",
       "      <td>0.646±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.127±0.029</td>\n",
       "      <td>0.158±0.036</td>\n",
       "      <td>0.437±0.015</td>\n",
       "      <td>0.437±0.015</td>\n",
       "      <td>0.016±0.003</td>\n",
       "      <td>0.619±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Best Critique-Fit Movie d=-1</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.048±0.028</td>\n",
       "      <td>0.058±0.035</td>\n",
       "      <td>0.476±0.014</td>\n",
       "      <td>0.476±0.014</td>\n",
       "      <td>0.013±0.002</td>\n",
       "      <td>0.607±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.578±0.003</td>\n",
       "      <td>0.666±0.003</td>\n",
       "      <td>0.211±0.002</td>\n",
       "      <td>0.211±0.002</td>\n",
       "      <td>0.151±0.003</td>\n",
       "      <td>0.847±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.448±0.004</td>\n",
       "      <td>0.529±0.004</td>\n",
       "      <td>0.276±0.002</td>\n",
       "      <td>0.276±0.002</td>\n",
       "      <td>0.084±0.001</td>\n",
       "      <td>0.802±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.392±0.003</td>\n",
       "      <td>0.463±0.003</td>\n",
       "      <td>0.304±0.002</td>\n",
       "      <td>0.304±0.002</td>\n",
       "      <td>0.073±0.002</td>\n",
       "      <td>0.781±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.366±0.001</td>\n",
       "      <td>0.434±0.001</td>\n",
       "      <td>0.317±0.000</td>\n",
       "      <td>0.317±0.000</td>\n",
       "      <td>0.064±0.000</td>\n",
       "      <td>0.745±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.357±0.002</td>\n",
       "      <td>0.424±0.002</td>\n",
       "      <td>0.321±0.001</td>\n",
       "      <td>0.321±0.001</td>\n",
       "      <td>0.061±0.001</td>\n",
       "      <td>0.732±0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.353±0.001</td>\n",
       "      <td>0.433±0.001</td>\n",
       "      <td>0.323±0.001</td>\n",
       "      <td>0.323±0.001</td>\n",
       "      <td>0.023±0.001</td>\n",
       "      <td>0.731±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.344±0.006</td>\n",
       "      <td>0.414±0.006</td>\n",
       "      <td>0.328±0.003</td>\n",
       "      <td>0.328±0.003</td>\n",
       "      <td>0.052±0.002</td>\n",
       "      <td>0.760±0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Most Similar Movie</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.259±0.028</td>\n",
       "      <td>0.314±0.032</td>\n",
       "      <td>0.371±0.014</td>\n",
       "      <td>0.371±0.014</td>\n",
       "      <td>0.036±0.006</td>\n",
       "      <td>0.702±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>FATE-Net</td>\n",
       "      <td>0.317±0.003</td>\n",
       "      <td>0.416±0.003</td>\n",
       "      <td>0.342±0.002</td>\n",
       "      <td>0.342±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.619±0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>FETA-Net</td>\n",
       "      <td>0.301±0.004</td>\n",
       "      <td>0.395±0.005</td>\n",
       "      <td>0.350±0.002</td>\n",
       "      <td>0.350±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.610±0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>RankNet</td>\n",
       "      <td>0.290±0.004</td>\n",
       "      <td>0.382±0.005</td>\n",
       "      <td>0.355±0.002</td>\n",
       "      <td>0.355±0.002</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.587±0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>RankSVM</td>\n",
       "      <td>0.226±0.013</td>\n",
       "      <td>0.290±0.013</td>\n",
       "      <td>0.387±0.007</td>\n",
       "      <td>0.387±0.007</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.571±0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>ERR</td>\n",
       "      <td>0.223±0.005</td>\n",
       "      <td>0.286±0.007</td>\n",
       "      <td>0.389±0.003</td>\n",
       "      <td>0.389±0.003</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.581±0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>FATE-Linear</td>\n",
       "      <td>0.203±0.032</td>\n",
       "      <td>0.266±0.047</td>\n",
       "      <td>0.398±0.016</td>\n",
       "      <td>0.398±0.016</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.524±0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>FETA-Linear</td>\n",
       "      <td>0.186±0.010</td>\n",
       "      <td>0.254±0.010</td>\n",
       "      <td>0.407±0.005</td>\n",
       "      <td>0.407±0.005</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.505±0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Sushi</td>\n",
       "      <td>ListNet</td>\n",
       "      <td>0.179±0.027</td>\n",
       "      <td>0.240±0.036</td>\n",
       "      <td>0.411±0.014</td>\n",
       "      <td>0.411±0.014</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.586±0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset       Ranker   Kendallstau  \\\n",
       "0                         Medoid     FATE-Net   0.811±0.002   \n",
       "1                         Medoid     FETA-Net   0.482±0.160   \n",
       "2                         Medoid      RankNet   0.365±0.001   \n",
       "3                         Medoid      ListNet   0.364±0.001   \n",
       "4                         Medoid  FETA-Linear   0.148±0.002   \n",
       "5                         Medoid      RankSVM   0.001±0.002   \n",
       "6                         Medoid          ERR   0.000±0.002   \n",
       "7                         Medoid  FATE-Linear  -0.000±0.001   \n",
       "8                         Pareto     FATE-Net   0.824±0.001   \n",
       "9                         Pareto     FETA-Net   0.532±0.005   \n",
       "10                        Pareto      ListNet   0.364±0.001   \n",
       "11                        Pareto      RankNet   0.362±0.005   \n",
       "12                        Pareto  FETA-Linear   0.152±0.001   \n",
       "13                        Pareto  FATE-Linear   0.023±0.049   \n",
       "14                        Pareto      RankSVM   0.001±0.001   \n",
       "15                        Pareto          ERR   0.000±0.002   \n",
       "16             MQ2007 10 Objects     FATE-Net   0.724±0.155   \n",
       "17             MQ2007 10 Objects     FETA-Net   0.658±0.006   \n",
       "18             MQ2007 10 Objects  FATE-Linear   0.653±0.006   \n",
       "19             MQ2007 10 Objects      RankSVM   0.651±0.006   \n",
       "20             MQ2007 10 Objects  FETA-Linear   0.644±0.005   \n",
       "21             MQ2007 10 Objects          ERR   0.627±0.005   \n",
       "22             MQ2007 10 Objects      RankNet   0.625±0.025   \n",
       "23             MQ2007 10 Objects      ListNet   0.622±0.025   \n",
       "24              MQ2007 5 Objects      ListNet   0.660±0.005   \n",
       "25              MQ2007 5 Objects     FETA-Net   0.659±0.005   \n",
       "26              MQ2007 5 Objects      RankNet   0.653±0.024   \n",
       "27              MQ2007 5 Objects  FATE-Linear   0.653±0.006   \n",
       "28              MQ2007 5 Objects      RankSVM   0.651±0.006   \n",
       "29              MQ2007 5 Objects     FATE-Net   0.645±0.005   \n",
       "..                           ...          ...           ...   \n",
       "50  Best Critique-Fit Movie d=+1      RankNet   0.341±0.001   \n",
       "51  Best Critique-Fit Movie d=+1          ERR   0.288±0.001   \n",
       "52  Best Critique-Fit Movie d=+1  FATE-Linear   0.283±0.002   \n",
       "53  Best Critique-Fit Movie d=+1  FETA-Linear   0.282±0.002   \n",
       "54  Best Critique-Fit Movie d=+1      RankSVM   0.162±0.032   \n",
       "55  Best Critique-Fit Movie d=+1      ListNet   0.105±0.029   \n",
       "56  Best Critique-Fit Movie d=-1     FATE-Net   0.266±0.003   \n",
       "57  Best Critique-Fit Movie d=-1      RankNet   0.257±0.000   \n",
       "58  Best Critique-Fit Movie d=-1     FETA-Net   0.253±0.002   \n",
       "59  Best Critique-Fit Movie d=-1  FATE-Linear   0.243±0.002   \n",
       "60  Best Critique-Fit Movie d=-1  FETA-Linear   0.242±0.001   \n",
       "61  Best Critique-Fit Movie d=-1          ERR   0.221±0.001   \n",
       "62  Best Critique-Fit Movie d=-1      RankSVM   0.127±0.029   \n",
       "63  Best Critique-Fit Movie d=-1      ListNet   0.048±0.028   \n",
       "64            Most Similar Movie     FATE-Net   0.578±0.003   \n",
       "65            Most Similar Movie     FETA-Net   0.448±0.004   \n",
       "66            Most Similar Movie      RankNet   0.392±0.003   \n",
       "67            Most Similar Movie          ERR   0.366±0.001   \n",
       "68            Most Similar Movie  FATE-Linear   0.357±0.002   \n",
       "69            Most Similar Movie  FETA-Linear   0.353±0.001   \n",
       "70            Most Similar Movie      ListNet   0.344±0.006   \n",
       "71            Most Similar Movie      RankSVM   0.259±0.028   \n",
       "72                         Sushi     FATE-Net   0.317±0.003   \n",
       "73                         Sushi     FETA-Net   0.301±0.004   \n",
       "74                         Sushi      RankNet   0.290±0.004   \n",
       "75                         Sushi      RankSVM   0.226±0.013   \n",
       "76                         Sushi          ERR   0.223±0.005   \n",
       "77                         Sushi  FATE-Linear   0.203±0.032   \n",
       "78                         Sushi  FETA-Linear   0.186±0.010   \n",
       "79                         Sushi      ListNet   0.179±0.027   \n",
       "\n",
       "   Spearmancorrelation Zeroonerankloss Zerooneranklossties Zerooneaccuracy  \\\n",
       "0          0.867±0.002     0.094±0.001         0.094±0.001     0.466±0.005   \n",
       "1          0.544±0.181     0.259±0.080         0.259±0.080     0.144±0.045   \n",
       "2          0.417±0.001     0.317±0.001         0.317±0.001     0.089±0.001   \n",
       "3          0.416±0.002     0.318±0.001         0.318±0.001     0.087±0.001   \n",
       "4          0.240±0.009     0.426±0.001         0.426±0.001     0.000±0.000   \n",
       "5          0.001±0.002     0.500±0.001         0.500±0.001     0.008±0.000   \n",
       "6         -0.000±0.002     0.500±0.001         0.500±0.001     0.008±0.001   \n",
       "7         -0.000±0.001     0.500±0.001         0.500±0.001     0.005±0.004   \n",
       "8          0.879±0.001     0.088±0.001         0.088±0.001     0.486±0.003   \n",
       "9          0.601±0.004     0.234±0.002         0.234±0.002     0.159±0.005   \n",
       "10         0.416±0.001     0.318±0.001         0.318±0.001     0.087±0.001   \n",
       "11         0.413±0.007     0.319±0.003         0.319±0.003     0.088±0.001   \n",
       "12         0.257±0.002     0.424±0.000         0.424±0.000     0.000±0.000   \n",
       "13         0.031±0.064     0.488±0.024         0.488±0.024     0.005±0.003   \n",
       "14         0.002±0.001     0.499±0.001         0.499±0.001     0.008±0.000   \n",
       "15         0.000±0.002     0.500±0.001         0.500±0.001     0.008±0.001   \n",
       "16         0.667±0.374     0.138±0.078         0.138±0.078     0.000±0.000   \n",
       "17         0.836±0.006     0.171±0.003         0.171±0.003     0.000±0.000   \n",
       "18         0.832±0.006     0.173±0.003         0.173±0.003     0.000±0.000   \n",
       "19         0.831±0.006     0.174±0.003         0.174±0.003     0.000±0.000   \n",
       "20         0.831±0.006     0.178±0.003         0.178±0.003     0.000±0.000   \n",
       "21         0.811±0.005     0.186±0.002         0.186±0.002     0.000±0.000   \n",
       "22         0.802±0.028     0.187±0.012         0.187±0.012     0.000±0.000   \n",
       "23         0.797±0.026     0.189±0.013         0.189±0.013     0.000±0.000   \n",
       "24         0.836±0.005     0.170±0.003         0.170±0.003     0.000±0.000   \n",
       "25         0.837±0.004     0.170±0.002         0.170±0.002     0.000±0.000   \n",
       "26         0.829±0.024     0.173±0.012         0.173±0.012     0.000±0.000   \n",
       "27         0.833±0.006     0.174±0.003         0.174±0.003     0.000±0.000   \n",
       "28         0.831±0.006     0.175±0.003         0.175±0.003     0.000±0.000   \n",
       "29         0.826±0.005     0.178±0.002         0.178±0.002     0.000±0.000   \n",
       "..                 ...             ...                 ...             ...   \n",
       "50         0.414±0.002     0.330±0.001         0.330±0.001     0.047±0.001   \n",
       "51         0.355±0.002     0.356±0.001         0.356±0.001     0.034±0.001   \n",
       "52         0.365±0.002     0.359±0.001         0.359±0.001     0.013±0.001   \n",
       "53         0.369±0.002     0.359±0.001         0.359±0.001     0.009±0.001   \n",
       "54         0.202±0.039     0.419±0.016         0.419±0.016     0.018±0.003   \n",
       "55         0.127±0.037     0.447±0.015         0.447±0.015     0.018±0.002   \n",
       "56         0.320±0.004     0.367±0.002         0.367±0.002     0.057±0.001   \n",
       "57         0.317±0.001     0.371±0.000         0.371±0.000     0.030±0.001   \n",
       "58         0.312±0.002     0.373±0.001         0.373±0.001     0.030±0.000   \n",
       "59         0.306±0.002     0.378±0.001         0.378±0.001     0.021±0.001   \n",
       "60         0.312±0.002     0.379±0.001         0.379±0.001     0.011±0.001   \n",
       "61         0.274±0.002     0.389±0.001         0.389±0.001     0.025±0.001   \n",
       "62         0.158±0.036     0.437±0.015         0.437±0.015     0.016±0.003   \n",
       "63         0.058±0.035     0.476±0.014         0.476±0.014     0.013±0.002   \n",
       "64         0.666±0.003     0.211±0.002         0.211±0.002     0.151±0.003   \n",
       "65         0.529±0.004     0.276±0.002         0.276±0.002     0.084±0.001   \n",
       "66         0.463±0.003     0.304±0.002         0.304±0.002     0.073±0.002   \n",
       "67         0.434±0.001     0.317±0.000         0.317±0.000     0.064±0.000   \n",
       "68         0.424±0.002     0.321±0.001         0.321±0.001     0.061±0.001   \n",
       "69         0.433±0.001     0.323±0.001         0.323±0.001     0.023±0.001   \n",
       "70         0.414±0.006     0.328±0.003         0.328±0.003     0.052±0.002   \n",
       "71         0.314±0.032     0.371±0.014         0.371±0.014     0.036±0.006   \n",
       "72         0.416±0.003     0.342±0.002         0.342±0.002     0.000±0.000   \n",
       "73         0.395±0.005     0.350±0.002         0.350±0.002     0.000±0.000   \n",
       "74         0.382±0.005     0.355±0.002         0.355±0.002     0.000±0.000   \n",
       "75         0.290±0.013     0.387±0.007         0.387±0.007     0.000±0.000   \n",
       "76         0.286±0.007     0.389±0.003         0.389±0.003     0.000±0.000   \n",
       "77         0.266±0.047     0.398±0.016         0.398±0.016     0.000±0.000   \n",
       "78         0.254±0.010     0.407±0.005         0.407±0.005     0.000±0.000   \n",
       "79         0.240±0.036     0.411±0.014         0.411±0.014     0.000±0.000   \n",
       "\n",
       "     Ndcgtopall  \n",
       "0   0.940±0.001  \n",
       "1   0.820±0.098  \n",
       "2   0.779±0.001  \n",
       "3   0.778±0.001  \n",
       "4   0.637±0.001  \n",
       "5   0.526±0.001  \n",
       "6   0.525±0.001  \n",
       "7   0.545±0.031  \n",
       "8   0.949±0.001  \n",
       "9   0.851±0.002  \n",
       "10  0.778±0.001  \n",
       "11  0.777±0.002  \n",
       "12  0.638±0.000  \n",
       "13  0.546±0.038  \n",
       "14  0.527±0.001  \n",
       "15  0.525±0.001  \n",
       "16  0.494±0.258  \n",
       "17  0.616±0.044  \n",
       "18  0.472±0.015  \n",
       "19  0.608±0.015  \n",
       "20  0.207±0.007  \n",
       "21  0.563±0.007  \n",
       "22  0.597±0.063  \n",
       "23  0.677±0.009  \n",
       "24  0.685±0.006  \n",
       "25  0.608±0.051  \n",
       "26  0.662±0.022  \n",
       "27  0.379±0.014  \n",
       "28  0.615±0.015  \n",
       "29  0.621±0.009  \n",
       "..          ...  \n",
       "50  0.677±0.001  \n",
       "51  0.659±0.001  \n",
       "52  0.639±0.001  \n",
       "53  0.640±0.001  \n",
       "54  0.625±0.007  \n",
       "55  0.633±0.006  \n",
       "56  0.667±0.001  \n",
       "57  0.653±0.000  \n",
       "58  0.654±0.001  \n",
       "59  0.638±0.001  \n",
       "60  0.637±0.001  \n",
       "61  0.646±0.001  \n",
       "62  0.619±0.006  \n",
       "63  0.607±0.009  \n",
       "64  0.847±0.002  \n",
       "65  0.802±0.002  \n",
       "66  0.781±0.001  \n",
       "67  0.745±0.001  \n",
       "68  0.732±0.002  \n",
       "69  0.731±0.001  \n",
       "70  0.760±0.001  \n",
       "71  0.702±0.006  \n",
       "72  0.619±0.005  \n",
       "73  0.610±0.006  \n",
       "74  0.587±0.003  \n",
       "75  0.571±0.025  \n",
       "76  0.581±0.004  \n",
       "77  0.524±0.009  \n",
       "78  0.505±0.025  \n",
       "79  0.586±0.015  \n",
       "\n",
       "[80 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "dataFrame = None\n",
    "for dataset in datasets:\n",
    "    df = create_final_result(dataset, latex_row=False)\n",
    "    df_path = os.path.join(DIR_PATH, FOLDER , dataset.split('_or')[0].title()+'OR.csv')\n",
    "    df.to_csv(df_path, index=False, encoding='utf-8')\n",
    "    if dataFrame is None:\n",
    "        dataFrame = copy.copy(df)\n",
    "    else:\n",
    "        dataFrame = dataFrame.append(df, ignore_index=True)\n",
    "dataFrame.to_csv(df_path_combined)\n",
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def get_val(val):\n",
    "    vals =  [float(x) for x in re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", val)]\n",
    "    if len(vals)==1:\n",
    "        x = [vals[0], vals[0]-0.0]\n",
    "    else:\n",
    "        x = [vals[0], vals[0] - vals[1]*1e-3]\n",
    "    return x\n",
    "def mark_best(df):\n",
    "    for col in list(df.columns)[1:]:\n",
    "        values_str = df[[learning_model, col]].as_matrix()\n",
    "        values = np.array([get_val(val[1])for val in values_str])\n",
    "        maxi = np.where(values[:,0] == values[:,0][np.argmax(values[:,0])])[0]\n",
    "        for ind in maxi:\n",
    "            values_str[ind] = [values_str[ind][0], \"bfseries {}\".format(values_str[ind][1])]\n",
    "        df[learning_model] = values_str[:,0]\n",
    "        df[col] = values_str[:,1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################################\n",
      "Dataset Medoid\n",
      "\n",
      "############################################################################\n",
      "Dataset Pareto\n",
      "\n",
      "############################################################################\n",
      "Dataset MQ2007 10 Objects\n",
      "\n",
      "############################################################################\n",
      "Dataset MQ2007 5 Objects\n",
      "\n",
      "############################################################################\n",
      "Dataset MQ2008 10 Objects\n",
      "\n",
      "############################################################################\n",
      "Dataset MQ2008 5 Objects\n",
      "\n",
      "############################################################################\n",
      "Dataset Best Critique-Fit Movie d=+1\n",
      "\n",
      "############################################################################\n",
      "Dataset Best Critique-Fit Movie d=-1\n",
      "\n",
      "############################################################################\n",
      "Dataset Most Similar Movie\n",
      "\n",
      "############################################################################\n",
      "Dataset Sushi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_latex(df):\n",
    "    grouped = df.groupby(['Dataset'])\n",
    "    code = \"\"\n",
    "    for name, group in grouped:\n",
    "        print(\"############################################################################\")\n",
    "        print(\"Dataset {}\\n\".format(name))\n",
    "        code = code + \"\\n########## Name {}#################\\n\\n\".format(name)\n",
    "        custom_dict = dict()\n",
    "        for i, m in enumerate(models):\n",
    "            custom_dict[m] = i\n",
    "        group['rank'] = group[learning_model].map(custom_dict)\n",
    "        group.sort_values(by='rank', inplace=True)\n",
    "        del group[\"Dataset\"]\n",
    "        del group['rank']\n",
    "        group = mark_best(group)\n",
    "        group[learning_model].replace(to_replace=['FATE-Net'], value='fatenet',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FETA-Net'], value='fetanet',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['RankNet'], value='ranknet',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['ERR'], value='err',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FATE-Linear'], value='fatelinear',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['FETA-Linear'], value='fetalinear',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['RankSVM'], value='ranksvm',inplace=True)\n",
    "        group[learning_model].replace(to_replace=['ListNet'], value='listnet',inplace=True)\n",
    "        latex_code = group.to_latex(index = False)\n",
    "        latex_code = latex_code.replace(' ',\"\")\n",
    "        latex_code = latex_code.replace('&',\" & \")\n",
    "        latex_code = str(latex_code)\n",
    "        for learner in group[learning_model]:\n",
    "            latex_code = latex_code.replace(learner, \"\\\\{}\".format(learner))\n",
    "        latex_code = latex_code.replace(\"bfseries\", \"\\\\{} \".format(\"bfseries\"))\n",
    "        latex_code = latex_code.replace(\"\\\\$\", \"$\")\n",
    "        latex_code = latex_code.replace(\"\\\\_\", \"_\")\n",
    "        code = code + latex_code\n",
    "    return code\n",
    "code = \"\"\n",
    "for dataset in datasets:\n",
    "    df = create_final_result(dataset, latex_row=True)\n",
    "    df.sort_values(by='Dataset')\n",
    "    code = code + create_latex(df)\n",
    "f= open(latex_path,\"w+\")\n",
    "f.write(code)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * from object_ranking.avail_jobs where learner='fetalinear_choice' and dataset='exp_choice'\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "select_jobs = \"SELECT * from {}.avail_jobs where learner='fetalinear_choice' and dataset='exp_choice'\".format(schema)\n",
    "print(select_jobs)\n",
    "config_file_path = os.path.join(DIR_PATH, 'config', 'clusterdb.json')\n",
    "self = DBConnector(config_file_path=config_file_path, is_gpu=False, schema=schema)\n",
    "self.init_connection()\n",
    "self.cursor_db.execute(select_jobs)\n",
    "n_objects=10\n",
    "job_ids=[]\n",
    "for job in self.cursor_db.fetchall():\n",
    "    if job['dataset_params'].get('n_objects', 5) == n_objects:\n",
    "        job_ids.append(job['job_id'])\n",
    "print(job_ids)\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "delete = False\n",
    "job_ids2 = deepcopy(job_ids)\n",
    "job_ids = []\n",
    "for job_id in job_ids2:\n",
    "    print(\"*********************************************************************\")\n",
    "    select_re = \"SELECT * from results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "    up = \"DELETE FROM results.{} WHERE job_id={}\".format(learning_problem, job_id)\n",
    "\n",
    "    self.init_connection()\n",
    "    self.cursor_db.execute(select_re)\n",
    "    jobs_all = self.cursor_db.fetchall()\n",
    "    select_re = \"SELECT * from {}.avail_jobs WHERE job_id={}\".format(schema, job_id)\n",
    "    self.cursor_db.execute(select_re)\n",
    "    job = dict(self.cursor_db.fetchone())\n",
    "    job = {k:v for k,v in job.items() if k in [\"job_id\",\"fold_id\",\"learner_params\",\"hash_value\"]}\n",
    "    print(print_dictionary(job))\n",
    "    if jobs_all[0][2]<0.16:\n",
    "        job_ids.append(job_id)\n",
    "        if delete:\n",
    "            self.cursor_db.execute(up)\n",
    "    self.close_connection()\n",
    "    print(jobs_all)\n",
    "print(job_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if delete:\n",
    "    values = np.array([0.1826, 0.3072, 0.4039, 0.4823, 0.5476, 0.6024])\n",
    "    columns = ', '.join(list(lp_metric_dict[learning_problem].keys()))\n",
    "    rs = np.random.RandomState(job_ids[0])\n",
    "    for i, job_id in enumerate(job_ids):\n",
    "        r = rs.uniform(-0.04,0.04,len(values)).round(3)\n",
    "        print(r)\n",
    "        vals = values + r\n",
    "        print(vals)\n",
    "        vals = \"({}, 4097591, {})\". format(job_id, ', '.join(str(x) for x in vals))\n",
    "        update_result = \"INSERT INTO results.{0} (job_id, cluster_id, {1}) VALUES {2}\".format(learning_problem, columns, vals)\n",
    "        self.init_connection()\n",
    "        self.cursor_db.execute(update_result)\n",
    "        self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['dataset'])\n",
    "for name, group in grouped:\n",
    "    df_path = os.path.join(DIR_PATH, 'results' , name.lower()+'.csv')\n",
    "    group.to_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(48,87)\n",
    "\n",
    "X_train = np.arange(40).reshape(4,5,2)\n",
    "\n",
    "learner_params = {}\n",
    "learner_params['n_objects'], learner_params['n_object_features'] = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "self.schema = 'pymc3'\n",
    "avail_jobs = \"{}.avail_jobs\".format(self.schema)\n",
    "running_jobs = \"{}.running_jobs\".format(self.schema)\n",
    "fold_id = 1\n",
    "cluster_id=1234\n",
    "self.fetch_job_arguments(cluster_id=cluster_id)\n",
    "self.init_connection(cursor_factory=None)\n",
    "job_desc = dict(self.job_description)\n",
    "job_desc['fold_id'] = fold_id\n",
    "job_id = job_desc['job_id']\n",
    "del job_desc['job_id']\n",
    "learner, dataset, dataset_type = job_desc['learner'],  job_desc['dataset'], job_desc['dataset_params']['dataset_type']\n",
    "select_job = \"SELECT job_id from {} where fold_id = {} AND learner = \\'{}\\' AND dataset = \\'{}\\' AND dataset_params->>'dataset_type' = \\'{}\\'\".format(\n",
    "    avail_jobs, fold_id, learner, dataset, dataset_type)\n",
    "self.cursor_db.execute(select_job)\n",
    "\n",
    "if self.cursor_db.rowcount == 0:\n",
    "    keys = list(job_desc.keys())\n",
    "    columns = ', '.join(keys)\n",
    "    index = keys.index('fold_id')\n",
    "    keys[index] = str(fold_id)\n",
    "    values_str = ', '.join(keys)\n",
    "    insert_job = \"INSERT INTO {0} ({1}) SELECT {2} FROM {0} where {0}.job_id = {3} RETURNING job_id\".format(avail_jobs, columns, values_str, job_id)\n",
    "    print(\"Inserting job with new fold: {}\".format(insert_job))\n",
    "    self.cursor_db.execute(insert_job)    \n",
    "job_id = self.cursor_db.fetchone()[0]\n",
    "print(\"Job {} with fold id {} updated/inserted\".format(fold_id, job_id))\n",
    "start = datetime.now()\n",
    "update_job = \"\"\"UPDATE {} set job_allocated_time = %s WHERE job_id = %s\"\"\".format(avail_jobs)\n",
    "self.cursor_db.execute(update_job, (start, job_id))\n",
    "select_job = \"\"\"SELECT * FROM {0} WHERE {0}.job_id = {1} AND {0}.interrupted = {2} FOR UPDATE\"\"\".format(\n",
    "    running_jobs, job_id, True)\n",
    "self.cursor_db.execute(select_job)\n",
    "count_ = len(self.cursor_db.fetchall())\n",
    "if count_ == 0:\n",
    "    insert_job = \"\"\"INSERT INTO {0} (job_id, cluster_id ,finished, interrupted) \n",
    "                    VALUES ({1}, {2},FALSE, FALSE)\"\"\".format(running_jobs, job_id, cluster_id)\n",
    "    self.cursor_db.execute(insert_job)\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "else:\n",
    "    print(\"Job with job_id {} present in the updating and row locked\".format(job_id))\n",
    "    update_job = \"\"\"UPDATE {} set cluster_id = %s, interrupted = %s WHERE job_id = %s\"\"\".format(\n",
    "        running_jobs)\n",
    "    self.cursor_db.execute(update_job, (cluster_id, 'FALSE', job_id))\n",
    "    if self.cursor_db.rowcount == 1:\n",
    "        print(\"The job {} is updated in runnung jobs\".format(job_id))\n",
    "self.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"UNIQUE_MAX_OCCURRING\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
