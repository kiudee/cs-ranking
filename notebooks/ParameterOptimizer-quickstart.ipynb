{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from csrank.dataset_reader import SyntheticDatasetGenerator\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from csrank.fate_ranking import FATEObjectRanker\n",
    "from csrank.callbacks import DebugOutput\n",
    "from csrank.tuning import ParameterOptimizer\n",
    "import logging\n",
    "from csrank.util import configure_logging_numpy_keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import os\n",
    "from skopt import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(logger, optimizer_path, n_iter):\n",
    "    logger.info('Retrieving model stored at: {}'.format(optimizer_path))\n",
    "    try:\n",
    "        optimizer = load(optimizer_path)\n",
    "        logger.info('Loading model stored at: {}'.format(optimizer_path))\n",
    "\n",
    "    except KeyError:\n",
    "        logger.error('Cannot open the file {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "\n",
    "    except ValueError:\n",
    "        logger.error('Cannot open the file {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "    except FileNotFoundError:\n",
    "        logger.error('No such file or directory: {}'.format(optimizer_path))\n",
    "        optimizer = None\n",
    "    if optimizer is not None:\n",
    "        finished_iterations = np.array(optimizer.yi).shape[0]\n",
    "        if finished_iterations == 0:\n",
    "            optimizer = None\n",
    "            logger.info('Optimizer did not finish any iterations so setting optimizer to null')\n",
    "        else:\n",
    "            n_iter = n_iter - finished_iterations\n",
    "            if n_iter < 0:\n",
    "                n_iter = 0\n",
    "            logger.info('Iterations already done: {} and running iterations {}'.format(finished_iterations, n_iter))\n",
    "    return optimizer, n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert the duration in string to the time required in microseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def get_duration_microsecond(duration):\n",
    "    time = int(re.findall(r'\\d+', duration)[0])\n",
    "    d = duration.split(str(time))[1].upper()\n",
    "    options = {\"D\": 24 * 60 * 60 * 1e6, \"H\": 60 * 60 * 1e6, \"M\": 60 * 1e6}\n",
    "    return options[d] * time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring the keras and tensorflow. Defining the parameters for dataset reader. Defining the splits for the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = configure_logging_numpy_keras(log_path=os.path.join(os.getcwd(), 'logs' ,\"test_models.log\"), name='Experiment')\n",
    "n_features = 2\n",
    "n_instances = 10000\n",
    "n_objects = 5\n",
    "random_state = check_random_state(42)\n",
    "skf = ShuffleSplit(n_splits=2, test_size=0.5, random_state=random_state)\n",
    "epochs = 100\n",
    "optimizer_path = os.path.join(os.getcwd(), 'logs',\"optimizer\")\n",
    "n_iter = 5\n",
    "optimizer, n_iter = get_optimizer(logger, optimizer_path, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Ranker init and fitting parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranker_params = {'n_objects': n_objects,\n",
    "                 'n_features':n_features, \n",
    "                 'n_object_features':n_features}\n",
    "\n",
    "fit_params = {'epochs': epochs,\n",
    "              'log_callbacks':[DebugOutput()]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Parameter optimizer init and fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer_fit_params = {'n_iter': n_iter, \n",
    "                        'cv_iter': skf, \n",
    "                        'optimizer': optimizer, \n",
    "                        \"total_duration\":get_duration_microsecond(\"10h\")}\n",
    "\n",
    "optimizer_params = {'ranker_class': FATEObjectRanker, \n",
    "                    'fit_params': fit_params,\n",
    "                    'ranker_params': ranker_params,\n",
    "                    'random_state': random_state, \n",
    "                    \"optimizer_path\":optimizer_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the medoid test and train dataset with defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medoids_params = {'dataset_type':\"medoid\",\n",
    "                  'n_test_instances': n_instances,\n",
    "                  'n_train_instances': n_instances,\n",
    "                  'n_features': n_features,\n",
    "                  'n_objects': n_objects,\n",
    "                  'random_state': random_state}\n",
    "dr = SyntheticDatasetGenerator(**medoids_params)\n",
    "X,Y,X_test,Y_test = dr.get_single_train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer_model = ParameterOptimizer(**optimizer_params)\n",
    "optimizer_model.fit(X, Y, **optimizer_fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Ranker with best parameters found by the optimizer on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if optimizer_model.model is None:\n",
    "    optimizer_model.model = optimizer_model._ranker_class(random_state=optimizer_model.random_state,\n",
    "                                                          **optimizer_model._ranker_params)\n",
    "    best_point = optimizer_model.optimizer.Xi[np.argmin(optimizer_model.optimizer.yi)]\n",
    "    optimizer_model.model.set_tunable_parameters(best_point)\n",
    "    logger.info(optimizer_model.model.__dict__)\n",
    "    optimizer_model.model.fit(X, Y, **optimizer_model._fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Scores for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60119748, -3.00899553, -1.15418839, -1.89158905,  3.21277809],\n",
       "       [-2.29909468, -2.76785064, -3.73014832, -0.86105549, -4.87870646],\n",
       "       [-1.33258545, -3.09852505, -3.92024136, -0.89974248, -3.95369244],\n",
       "       ..., \n",
       "       [-3.43628454, -0.66553152, -2.91205454, -1.99111378, -1.79274499],\n",
       "       [ 2.20938802,  1.50373054, -0.01428777, -1.63791025,  3.09338284],\n",
       "       [-2.47337866, -4.68289852, -0.53654063, -1.74233592, -6.30659676]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = optimizer_model.predict_scores(X_test)\n",
    "predicted"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
